import express from 'express'
import cors from 'cors'
import sharp from 'sharp'
import { createClient } from '@supabase/supabase-js'
import { spawn } from 'child_process'
import path from 'path'
import fs from 'fs'
import { fileURLToPath } from 'url'
import dotenv from 'dotenv'
import net from 'net'

// í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv.config()

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

const app = express()

// ì¸ì½”ë”© ì„¤ì •
app.use(express.json({ limit: '50mb' }))
app.use(express.urlencoded({ extended: true, limit: '50mb' }))

// Health check ì—”ë“œí¬ì¸íŠ¸
app.get('/health', (req, res) => {
  res.status(200).json({
    status: 'healthy',
    service: 'Synthetic API',
    port: process.env.SYNTHETIC_API_PORT || 3011,
    timestamp: new Date().toISOString()
  })
})

// CORS ì„¤ì • (localhost:3000ì—ì„œì˜ ìš”ì²­ í—ˆìš©)
app.use(cors({
  origin: 'http://localhost:3000',
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization', 'Cache-Control'],
  credentials: true
}))
// ìºì‹œ ë¹„í™œì„±í™” (ETagë¡œ 304 ë°˜í™˜ ë°©ì§€)
app.set('etag', false)
// ì •ì  íŒŒì¼ ì œê³µ: ìƒì„±ëœ í•©ì„± ì´ë¯¸ì§€ ì œê³µ (í”„ë¡ì‹œ ê²½ë¡œ í•˜ìœ„ë¡œ ì œê³µ)
app.use('/api/synthetic/static', express.static(path.join(__dirname, '..', 'output')))

// ê²€ì¦ ë¼ìš°í„° ì¶”ê°€ëŠ” startServer í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬

// Health check ì—”ë“œí¬ì¸íŠ¸
app.get('/api/synthetic/health', (req, res) => {
  res.json({ 
    status: 'ok', 
    service: 'synthetic-api',
    timestamp: new Date().toISOString(),
    port: process.env.PORT || 3011
  })
})

// í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ë¡œë“œ
dotenv.config({ path: path.join(__dirname, '..', 'config', 'synthetic_dataset.env') })

// Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (Service Role Key ì‚¬ìš©)
const supabaseUrl = process.env.VITE_SUPABASE_URL || 'https://npferbxuxocbfnfbpcnz.supabase.co'
const supabaseKey = process.env.VITE_SUPABASE_SERVICE_ROLE || 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1OTQ3NDk4NSwiZXhwIjoyMDc1MDUwOTg1fQ.pPWhWrb4QBC-DT4dd6Y1p-LlHNd9UTKef3SHEXUDp00'

console.log('âœ… Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì™„ë£Œ')
console.log('SUPABASE_URL:', supabaseUrl)
console.log('SUPABASE_SERVICE_ROLE_KEY:', supabaseKey ? 'ì„¤ì •ë¨' : 'ì„¤ì •ë˜ì§€ ì•ŠìŒ')

const supabase = createClient(supabaseUrl, supabaseKey)

// ì‘ì—… ìƒíƒœ ì €ì¥ ê²½ë¡œ
const RECOVERY_STATE_DIR = path.join(__dirname, '..', 'output', 'recovery')
const ACTIVE_JOBS_STATE_FILE = path.join(RECOVERY_STATE_DIR, 'active-jobs.json')

// ë³µêµ¬ ìƒíƒœ ë””ë ‰í† ë¦¬ ìƒì„±
if (!fs.existsSync(RECOVERY_STATE_DIR)) {
  fs.mkdirSync(RECOVERY_STATE_DIR, { recursive: true })
}

// ë Œë”ë§ ì‘ì—… ê´€ë¦¬ (ìƒíƒœ ì €ì¥ í•¨ìˆ˜ë³´ë‹¤ ë¨¼ì € ì„ ì–¸)
const activeJobs = new Map()

// ì‘ì—… ìƒíƒœ ì €ì¥ í•¨ìˆ˜
const saveActiveJobsState = () => {
  try {
    if (!activeJobs || activeJobs.size === 0) {
      // ì‘ì—…ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ì €ì¥
      fs.writeFileSync(ACTIVE_JOBS_STATE_FILE, JSON.stringify([], null, 2))
      return
    }
    
    const jobsData = Array.from(activeJobs.entries()).map(([id, job]) => ({
      id: job.id,
      status: job.status,
      progress: job.progress,
      config: job.config,
      startTime: job.startTime,
      logs: (job.logs || []).slice(-50), // ìµœê·¼ 50ê°œ ë¡œê·¸ë§Œ ì €ì¥
      lastUpdate: new Date().toISOString()
    }))
    
    fs.writeFileSync(ACTIVE_JOBS_STATE_FILE, JSON.stringify(jobsData, null, 2))
    console.log(`ğŸ’¾ ì‘ì—… ìƒíƒœ ì €ì¥ ì™„ë£Œ: ${jobsData.length}ê°œ ì‘ì—…`)
  } catch (error) {
    console.error('âŒ ì‘ì—… ìƒíƒœ ì €ì¥ ì‹¤íŒ¨:', error.message)
  }
}

// ì •ê¸°ì ìœ¼ë¡œ ì‘ì—… ìƒíƒœ ì €ì¥ (5ë¶„ë§ˆë‹¤)
setInterval(saveActiveJobsState, 5 * 60 * 1000)

// ğŸ”§ ìˆ˜ì •ë¨: ì „ì—­ ì—ëŸ¬ í•¸ë“¤ëŸ¬ë¥¼ ì„œë²„ ì‹œì‘ ì „ì— ë“±ë¡ (ì„œë²„ í¬ë˜ì‹œ ë°©ì§€)
process.on('uncaughtException', (error) => {
  console.error('âŒ [Uncaught Exception]:', error.message)
  console.error('ìŠ¤íƒ:', error.stack)
  
  // ì‘ì—… ìƒíƒœ ì €ì¥
  saveActiveJobsState()
  
  // ì„œë²„ ì¢…ë£Œí•˜ì§€ ì•Šê³  ê³„ì† ì‹¤í–‰ (ë Œë”ë§ ì‘ì—… ìœ ì§€)
  // ë‹¨, ì—ëŸ¬ ë¡œê·¸ë§Œ ê¸°ë¡
})

process.on('unhandledRejection', (reason, promise) => {
  console.error('âŒ [Unhandled Rejection]:', reason)
  console.error('Promise:', promise)
  
  // ì‘ì—… ìƒíƒœ ì €ì¥
  saveActiveJobsState()
  
  // ì„œë²„ ì¢…ë£Œí•˜ì§€ ì•Šê³  ê³„ì† ì‹¤í–‰
})

// ì„œë²„ ì¢…ë£Œ ì‹œ ì‘ì—… ìƒíƒœ ì €ì¥
process.on('SIGTERM', () => {
  console.log('âš ï¸ SIGTERM ì‹ í˜¸ ìˆ˜ì‹  - ì‘ì—… ìƒíƒœ ì €ì¥ ì¤‘...')
  saveActiveJobsState()
  process.exit(0)
})

process.on('SIGINT', () => {
  console.log('âš ï¸ SIGINT ì‹ í˜¸ ìˆ˜ì‹  - ì‘ì—… ìƒíƒœ ì €ì¥ ì¤‘...')
  saveActiveJobsState()
  process.exit(0)
})

process.on('exit', (code) => {
  console.log(`âš ï¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ (ì½”ë“œ: ${code}) - ì‘ì—… ìƒíƒœ ì €ì¥ ì¤‘...`)
  saveActiveJobsState()
})

// ê²€ì¦ í•¨ìˆ˜ë“¤
const validateFileIntegrity = async (filePath) => {
  try {
    const stats = await fs.promises.stat(filePath)
    return {
      exists: true,
      size: stats.size,
      isFile: stats.isFile(),
      isValid: stats.size > 0
    }
  } catch (error) {
    return {
      exists: false,
      size: 0,
      isFile: false,
      isValid: false,
      error: error.message
    }
  }
}

const validateImageFile = async (filePath) => {
  const integrity = await validateFileIntegrity(filePath)
  if (!integrity.isValid) {
    return { valid: false, error: 'íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤' }
  }
  
  const validExtensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
  const ext = path.extname(filePath).toLowerCase()
  
  if (!validExtensions.includes(ext)) {
    return { valid: false, error: `ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹: ${ext}` }
  }
  
  return { valid: true, size: integrity.size }
}

const validateLabelFile = async (filePath) => {
  const integrity = await validateFileIntegrity(filePath)
  if (!integrity.isValid) {
    return { valid: false, error: 'ë¼ë²¨ íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤' }
  }
  
  try {
    const content = await fs.promises.readFile(filePath, 'utf8')
    const lines = content.trim().split('\n')
    
    for (const line of lines) {
      if (line.trim()) {
        const parts = line.trim().split(' ')
        if (parts.length < 5) {
          return { valid: false, error: `ì˜ëª»ëœ YOLO í˜•ì‹ (ìµœì†Œ 5ê°œ ê°’ í•„ìš”): ${line}` }
        }
        
        const [classId, x, y, w, h] = parts
        const classIdNum = parseFloat(classId)
        const xNum = parseFloat(x)
        const yNum = parseFloat(y)
        const wNum = parseFloat(w)
        const hNum = parseFloat(h)
        
        if (isNaN(classIdNum) || isNaN(xNum) || isNaN(yNum) || isNaN(wNum) || isNaN(hNum)) {
          return { valid: false, error: `ì˜ëª»ëœ ìˆ«ì í˜•ì‹: ${line}` }
        }
        
        // ì¢Œí‘œ ë²”ìœ„ ê²€ì¦ (0-1 ë²”ìœ„ë¡œ í´ë¦¬í•‘)
        if (classIdNum < 0 || xNum < 0 || xNum > 1 || yNum < 0 || yNum > 1 || wNum < 0 || wNum > 1 || hNum < 0 || hNum > 1) {
          // ì¢Œí‘œê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ê²½ìš° ê²½ê³ ë§Œ í‘œì‹œí•˜ê³  ìœ íš¨í•œ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
          console.log(`âš ï¸ ì¢Œí‘œ ë²”ìœ„ ì´ˆê³¼ (ìë™ ìˆ˜ì •ë¨): ${line}`)
          return { valid: true, lineCount: lines.length, warning: `ì¢Œí‘œ ë²”ìœ„ ì´ˆê³¼ (ìë™ ìˆ˜ì •ë¨): ${line}` }
        }
      }
    }
    
    return { valid: true, lineCount: lines.length }
  } catch (error) {
    return { valid: false, error: `ë¼ë²¨ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: ${error.message}` }
  }
}

const validateMetadataFile = async (filePath) => {
  const integrity = await validateFileIntegrity(filePath)
  if (!integrity.isValid) {
    return { valid: false, error: 'ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤' }
  }
  
  try {
    const content = await fs.promises.readFile(filePath, 'utf8')
    const metadata = JSON.parse(content)
    
    // ê¸°ë³¸ í•„ìˆ˜ í•„ë“œ
    const requiredFields = ['part_id']
    for (const field of requiredFields) {
      if (!metadata[field]) {
        return { valid: false, error: `í•„ìˆ˜ í•„ë“œ ëˆ„ë½: ${field}` }
      }
    }
    
    // íŒŒì¼ íƒ€ì…ë³„ ì¶”ê°€ í•„ë“œ ê²€ì¦
    const filename = path.basename(filePath)
    if (filename.includes('_e2.json')) {
      // E2 JSON íŒŒì¼ì€ element_id í•„ìˆ˜
      if (!metadata.element_id) {
        return { valid: false, error: `E2 JSON í•„ìˆ˜ í•„ë“œ ëˆ„ë½: element_id` }
      }
    } else {
      // ì¼ë°˜ JSON íŒŒì¼ì€ part_name í•„ìˆ˜
      if (!metadata.part_name) {
        return { valid: false, error: `ì¼ë°˜ JSON í•„ìˆ˜ í•„ë“œ ëˆ„ë½: part_name` }
      }
    }
    
    return { valid: true, fields: Object.keys(metadata) }
  } catch (error) {
    return { valid: false, error: `JSON íŒŒì‹± ì˜¤ë¥˜: ${error.message}` }
  }
}

const performValidation = async (sourcePath, options) => {
  const results = {
    totalParts: 0,
    validParts: 0,
    invalidParts: 0,
    totalImages: 0,
    totalLabels: 0,
    totalMetadata: 0,
    errors: [],
    warnings: [],
    fileIntegrity: {
      valid: 0,
      invalid: 0,
      errors: []
    },
    bucketSync: {
      totalFiles: 0,
      uploadedFiles: 0,
      missingFiles: 0,
      syncErrors: [],
      bucketStats: {
        totalObjects: 0,
        totalSize: 0
      }
    }
  }
  
  try {
    console.log(`ğŸ” ê²€ì¦ ì‹œì‘: ${sourcePath}`)
    
    // í´ë” ì¡´ì¬ í™•ì¸
    try {
      const stats = await fs.promises.stat(sourcePath)
      if (!stats.isDirectory()) {
        results.errors.push(`ê²½ë¡œê°€ í´ë”ê°€ ì•„ë‹™ë‹ˆë‹¤: ${sourcePath}`)
        return results
      }
    } catch (error) {
      results.errors.push(`í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ${sourcePath} (${error.message})`)
      return results
    }
    
    // ë¶€í’ˆë³„ ê²€ì¦
    const items = await fs.promises.readdir(sourcePath)
    console.log(`ğŸ“ ë°œê²¬ëœ í•­ëª©: ${items.length}ê°œ`)
    
    // ì œì™¸í•  í´ë”ë“¤ (ì‹¤ì œ ë¶€í’ˆì´ ì•„ë‹Œ ì‹œìŠ¤í…œ í´ë”)
    const excludeFolders = ['dataset_synthetic', 'logs', 'temp', 'cache']
    
    for (const item of items) {
      const itemPath = path.join(sourcePath, item)
      const stats = await fs.promises.stat(itemPath)
      
      if (stats.isDirectory()) {
        // ì‹œìŠ¤í…œ í´ë”ëŠ” ì œì™¸
        if (excludeFolders.includes(item)) {
          console.log(`â­ï¸ ì‹œìŠ¤í…œ í´ë” ì œì™¸: ${item}`)
          continue
        }
        
        results.totalParts++
        console.log(`ğŸ” ë¶€í’ˆ ê²€ì¦: ${item}`)
        
        const partItems = await fs.promises.readdir(itemPath)
        let partValid = true
        let partErrors = []
        
        // ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦
        const imageFiles = partItems.filter(file => /\.(jpg|jpeg|png|bmp|tiff|webp)$/i.test(file))
        results.totalImages += imageFiles.length
        
        for (const imageFile of imageFiles) {
          const imagePath = path.join(itemPath, imageFile)
          const imageValidation = await validateImageFile(imagePath)
          
          if (!imageValidation.valid) {
            partValid = false
            partErrors.push(`ì´ë¯¸ì§€ ${imageFile}: ${imageValidation.error}`)
            results.fileIntegrity.invalid++
          } else {
            results.fileIntegrity.valid++
          }
        }
        
        // ë¼ë²¨ íŒŒì¼ ê²€ì¦
        const labelFiles = partItems.filter(file => file.endsWith('.txt'))
        results.totalLabels += labelFiles.length
        
        for (const labelFile of labelFiles) {
          const labelPath = path.join(itemPath, labelFile)
          const labelValidation = await validateLabelFile(labelPath)
          
          if (!labelValidation.valid) {
            partValid = false
            partErrors.push(`ë¼ë²¨ ${labelFile}: ${labelValidation.error}`)
          }
        }
        
        // ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²€ì¦
        const metadataFiles = partItems.filter(file => file.endsWith('.json'))
        results.totalMetadata += metadataFiles.length
        
        for (const metadataFile of metadataFiles) {
          const metadataPath = path.join(itemPath, metadataFile)
          const metadataValidation = await validateMetadataFile(metadataPath)
          
          if (!metadataValidation.valid) {
            partValid = false
            partErrors.push(`ë©”íƒ€ë°ì´í„° ${metadataFile}: ${metadataValidation.error}`)
          }
        }
        
        if (partValid) {
          results.validParts++
        } else {
          results.invalidParts++
          results.errors.push(`ë¶€í’ˆ ${item}: ${partErrors.join(', ')}`)
        }
      }
    }
    
    // ë²„í‚· ë™ê¸°í™” ê²€ì¦
    if (options.validateBucketSync && options.bucketName) {
      console.log(`ğŸ” ë²„í‚· ë™ê¸°í™” ê²€ì¦ ì‹œì‘: ${options.bucketName}`)
      try {
        const bucketSyncResult = await validateBucketSync(sourcePath, options.bucketName)
        results.bucketSync = bucketSyncResult
        console.log(`âœ… ë²„í‚· ë™ê¸°í™” ê²€ì¦ ì™„ë£Œ: ${bucketSyncResult.uploadedFiles}/${bucketSyncResult.totalFiles} íŒŒì¼ ì—…ë¡œë“œë¨`)
      } catch (error) {
        console.error('âŒ ë²„í‚· ë™ê¸°í™” ê²€ì¦ ì‹¤íŒ¨:', error)
        results.bucketSync = {
          totalFiles: 0,
          uploadedFiles: 0,
          missingFiles: 0,
          syncErrors: [`ë²„í‚· ë™ê¸°í™” ê²€ì¦ ì‹¤íŒ¨: ${error.message}`],
          bucketStats: { totalObjects: 0, totalSize: 0 }
        }
      }
    }
    
    console.log(`âœ… ê²€ì¦ ì™„ë£Œ: ì´ ${results.totalParts}ê°œ ë¶€í’ˆ, ìœ íš¨ ${results.validParts}ê°œ`)
    return results
    
  } catch (error) {
    console.error('âŒ ê²€ì¦ ì¤‘ ì˜¤ë¥˜:', error)
    results.errors.push(`ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ${error.message}`)
    return results
  }
}

// Supabase Storage í”„ë¡ì‹œ ì—”ë“œí¬ì¸íŠ¸ (CORS ë¬¸ì œ í•´ê²°)
app.get('/api/supabase/storage/list/:bucket/*', async (req, res) => {
  try {
    const { bucket } = req.params
    const folderPath = req.params[0] || ''
    
    console.log(`ğŸ” Supabase Storage í”„ë¡ì‹œ ìš”ì²­: ${bucket}/${folderPath}`)
    
    if (!supabaseUrl || !supabaseKey) {
      return res.status(500).json({ error: 'Supabase not configured' })
    }
    
    // Supabase JavaScript í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì‚¬ìš©
    const { data, error } = await supabase.storage
      .from(bucket)
      .list(folderPath, {
        limit: 1000,
        sortBy: { column: 'name', order: 'asc' }
      })
    
    if (error) {
      console.error(`âŒ Supabase Storage ì˜¤ë¥˜:`, error)
      return res.status(400).json({ 
        error: `Storage error: ${error.message}`,
        details: error
      })
    }
    
    console.log(`âœ… Storage ëª©ë¡ ì¡°íšŒ ì„±ê³µ: ${data.length}ê°œ íŒŒì¼`)
    res.status(200).json(data)
    
  } catch (error) {
    console.error('âŒ Supabase Storage í”„ë¡ì‹œ ì˜¤ë¥˜:', error)
    res.status(500).json({ 
      error: 'Internal server error',
      details: error.message 
    })
  }
})

// WebP ì´ë¯¸ì§€ APIëŠ” ë³„ë„ ì„œë²„ë¡œ ì´ë™ë¨ (í¬íŠ¸ 3004)
// ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ì œê±°ë¨ - server/webp-image-api.js ì‚¬ìš©

// activeJobsëŠ” ìœ„ì—ì„œ ì´ë¯¸ ì„ ì–¸ë¨

// ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ìƒíƒœ ê´€ë¦¬
const autoRecoveryStatus = {
  isActive: true,  // ì„œë²„ ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ í™œì„±í™”
  serverMonitor: {
    running: true,  // ì„œë²„ ëª¨ë‹ˆí„°ë§ ìë™ ì‹œì‘
    lastCheck: new Date().toISOString(),
    retryCount: 0,
    maxRetries: 5
  },
  autoRecovery: {
    running: true,  // ìë™ ë³µêµ¬ ìë™ ì‹œì‘
    lastStateCheck: new Date().toISOString(),
    renderingResumed: false
  },
  logs: [{
    timestamp: new Date().toISOString(),
    type: 'info',
    message: 'ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ìë™ ì‹œì‘ë¨'
  }]
}

// í¬íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ
const portManager = {
  currentPort: null,
  portHistory: [],
  portConflicts: [],
  autoRecoveryPort: null,
  isPortMonitoring: false
}

// ë°ì´í„°ì…‹ ë³€í™˜ ì‘ì—… ê´€ë¦¬
const conversionJobs = new Map()
const conversionProgress = new Map()

// ë Œë”ë§ ì‹œì‘ API
app.post('/api/synthetic/start-rendering', async (req, res) => {
  try {
    // ğŸ”§ ìˆ˜ì •ë¨: ì„¸íŠ¸ ë Œë”ë§ ì§€ì› (setNumber, renderType ë§¤í•‘)
    let { mode, partId, setNum, setNumber, renderType, imageCount } = req.body
    
    // setNumberì™€ renderTypeì´ ìˆìœ¼ë©´ modeì™€ setNumìœ¼ë¡œ ë³€í™˜
    if (setNumber && renderType === 'set') {
      mode = 'set'
      setNum = setNumber
      console.log(`ğŸ¯ ì„¸íŠ¸ ë Œë”ë§ ëª¨ë“œ ê°ì§€: setNum=${setNum}`)
    }
    
    // Blender ìŠ¤í¬ë¦½íŠ¸ ì¸ìˆ˜ í˜¸í™˜: medium -> normal ë§¤í•‘
    const qualityRaw = req.body.quality
    const quality = qualityRaw === 'medium' ? 'normal' : qualityRaw
    
    const jobId = `job_${Date.now()}`
    const job = {
      id: jobId,
      status: 'running',
      progress: 0,
      config: {
        ...req.body,
        mode,  // ğŸ”§ ìˆ˜ì •ë¨: ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
        setNum,  // ğŸ”§ ìˆ˜ì •ë¨: ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
        partId  // ğŸ”§ ìˆ˜ì •ë¨: ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
      },
      startTime: new Date(),
      logs: []
    }
    
    activeJobs.set(jobId, job)
    
    // ì‹¤ì œ Blender ë Œë”ë§ ì‹œì‘
    console.log('ğŸ¨ ì‹¤ì œ Blender ë Œë”ë§ ì‹œì‘:', { mode, partId, setNum, imageCount, quality })
    
    // Blender ë Œë”ë§ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    // ğŸ”§ ìˆ˜ì •ë¨: async í•¨ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ í˜¸ì¶œ (ì„œë²„ í¬ë˜ì‹œ ë°©ì§€)
    startBlenderRendering(job).catch(error => {
      console.error('âŒ [startBlenderRendering ì—ëŸ¬]:', error)
      job.status = 'failed'
      job.logs.push({
        timestamp: new Date(),
        message: `ë Œë”ë§ ì‹œì‘ ì‹¤íŒ¨: ${error.message}`,
        type: 'error'
      })
      // ì‘ì—… ìƒíƒœ ì €ì¥
      saveActiveJobsState()
    })
    
    // ì‘ì—… ì‹œì‘ ì‹œ ì¦‰ì‹œ ìƒíƒœ ì €ì¥
    saveActiveJobsState()
    
    res.json({
      success: true,
      jobId,
      message: 'ë Œë”ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤'
    })
    
  } catch (error) {
    console.error('ë Œë”ë§ ì‹œì‘ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// í—¬ìŠ¤ì²´í¬ API
app.get('/api/synthetic/health', (req, res) => {
  res.json({
    status: 'running',
    timestamp: new Date().toISOString(),
    activeJobs: activeJobs.size
  })
})

// ì„œë²„ ìƒíƒœ í™•ì¸ API
app.get('/api/synthetic/status', (req, res) => {
  res.json({
    success: true,
    status: 'running',
    timestamp: new Date().toISOString(),
    activeJobs: activeJobs.size,
    version: '1.0.0'
  })
})

// ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ìƒíƒœ API
app.get('/api/synthetic/auto-recovery/status', (req, res) => {
  try {
    res.json({
      success: true,
      autoRecovery: autoRecoveryStatus,
      timestamp: new Date().toISOString()
    })
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ì‹œì‘ API
app.post('/api/synthetic/auto-recovery/start', (req, res) => {
  try {
    autoRecoveryStatus.isActive = true
    autoRecoveryStatus.serverMonitor.running = true
    autoRecoveryStatus.serverMonitor.lastCheck = new Date().toISOString()
    autoRecoveryStatus.logs.push({
      timestamp: new Date().toISOString(),
      type: 'info',
      message: 'ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ì‹œì‘ë¨'
    })
    
    res.json({
      success: true,
      message: 'ìë™ ë³µêµ¬ ì‹œìŠ¤í…œì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤',
      status: autoRecoveryStatus
    })
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ì¤‘ë‹¨ API
app.post('/api/synthetic/auto-recovery/stop', (req, res) => {
  try {
    autoRecoveryStatus.isActive = false
    autoRecoveryStatus.serverMonitor.running = false
    autoRecoveryStatus.autoRecovery.running = false
    autoRecoveryStatus.logs.push({
      timestamp: new Date().toISOString(),
      type: 'info',
      message: 'ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ì¤‘ë‹¨ë¨'
    })
    
    res.json({
      success: true,
      message: 'ìë™ ë³µêµ¬ ì‹œìŠ¤í…œì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤',
      status: autoRecoveryStatus
    })
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ìë™ ë³µêµ¬ ë¡œê·¸ ì¶”ê°€ API (ë‚´ë¶€ìš©)
const addAutoRecoveryLog = (type, message) => {
  autoRecoveryStatus.logs.push({
    timestamp: new Date().toISOString(),
    type: type,
    message: message
  })
  
  // ë¡œê·¸ ê°œìˆ˜ ì œí•œ (ìµœê·¼ 100ê°œë§Œ ìœ ì§€)
  if (autoRecoveryStatus.logs.length > 100) {
    autoRecoveryStatus.logs = autoRecoveryStatus.logs.slice(-100)
  }
}

// í¬íŠ¸ ì¶©ëŒ ê°ì§€ ë° ìë™ ìˆ˜ì •
const detectPortConflicts = async () => {
  try {
    const usedPorts = []
    
    // í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ë“¤ í™•ì¸
    for (let port = 3000; port <= 3100; port++) {
      if (!(await isPortAvailable(port))) {
        usedPorts.push(port)
      }
    }
    
    portManager.portConflicts = usedPorts
    addAutoRecoveryLog('info', `í¬íŠ¸ ì¶©ëŒ ê°ì§€: ${usedPorts.length}ê°œ í¬íŠ¸ ì‚¬ìš© ì¤‘`)
    
    return usedPorts
  } catch (error) {
    addAutoRecoveryLog('error', `í¬íŠ¸ ì¶©ëŒ ê°ì§€ ì‹¤íŒ¨: ${error.message}`)
    return []
  }
}

// ë™ì  í¬íŠ¸ í• ë‹¹ (ì¶©ëŒ ë°©ì§€)
const allocatePortDynamically = async (preferredPort = 3002) => {
  try {
    // ì„ í˜¸ í¬íŠ¸ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
    if (await isPortAvailable(preferredPort)) {
      portManager.currentPort = preferredPort
      addAutoRecoveryLog('info', `ì„ í˜¸ í¬íŠ¸ ${preferredPort} ì‚¬ìš© ê°€ëŠ¥`)
      return preferredPort
    }
    
    // ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ ì°¾ê¸°
    for (let port = 3002; port <= 3100; port++) {
      if (await isPortAvailable(port)) {
        portManager.currentPort = port
        portManager.portHistory.push({
          port: port,
          timestamp: new Date().toISOString(),
          reason: 'auto-assignment'
        })
        addAutoRecoveryLog('info', `ë™ì  í¬íŠ¸ í• ë‹¹: ${port}`)
        return port
      }
    }
    
    throw new Error('ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (3002-3100)')
  } catch (error) {
    addAutoRecoveryLog('error', `ë™ì  í¬íŠ¸ í• ë‹¹ ì‹¤íŒ¨: ${error.message}`)
    return null
  }
}

// í¬íŠ¸ ìƒíƒœ ëª¨ë‹ˆí„°ë§
const startPortMonitoring = () => {
  if (portManager.isPortMonitoring) return
  
  portManager.isPortMonitoring = true
  
  const monitorInterval = setInterval(async () => {
    if (!portManager.isPortMonitoring) {
      clearInterval(monitorInterval)
      return
    }
    
    // í˜„ì¬ í¬íŠ¸ ìƒíƒœ í™•ì¸
    if (portManager.currentPort && !(await isPortAvailable(portManager.currentPort))) {
      addAutoRecoveryLog('warning', `í˜„ì¬ í¬íŠ¸ ${portManager.currentPort} ì‚¬ìš© ë¶ˆê°€ - ì¬í• ë‹¹ í•„ìš”`)
      
      // ìƒˆë¡œìš´ í¬íŠ¸ í• ë‹¹
      const newPort = await allocatePortDynamically()
      if (newPort) {
        addAutoRecoveryLog('info', `í¬íŠ¸ ì¬í• ë‹¹ ì™„ë£Œ: ${newPort}`)
      }
    }
  }, 10000) // 10ì´ˆë§ˆë‹¤ í™•ì¸
  
  addAutoRecoveryLog('info', 'í¬íŠ¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨')
}

// í¬íŠ¸ ìƒíƒœ ì¡°íšŒ API
app.get('/api/synthetic/ports/status', (req, res) => {
  try {
    res.json({
      success: true,
      portManager: {
        currentPort: portManager.currentPort,
        portHistory: portManager.portHistory.slice(-10), // ìµœê·¼ 10ê°œ
        portConflicts: portManager.portConflicts,
        isPortMonitoring: portManager.isPortMonitoring,
        autoRecoveryPort: portManager.autoRecoveryPort
      },
      timestamp: new Date().toISOString()
    })
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// í¬íŠ¸ ì¬í• ë‹¹ API
app.post('/api/synthetic/ports/reallocate', async (req, res) => {
  try {
    const { preferredPort } = req.body
    const newPort = await allocatePortDynamically(preferredPort)
    
    if (newPort) {
      res.json({
        success: true,
        message: `í¬íŠ¸ ì¬í• ë‹¹ ì™„ë£Œ: ${newPort}`,
        newPort: newPort
      })
    } else {
      res.status(500).json({
        success: false,
        error: 'í¬íŠ¸ ì¬í• ë‹¹ ì‹¤íŒ¨'
      })
    }
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// í¬íŠ¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘/ì¤‘ë‹¨ API
app.post('/api/synthetic/ports/monitoring/:action', (req, res) => {
  try {
    const { action } = req.params
    
    if (action === 'start') {
      startPortMonitoring()
      res.json({
        success: true,
        message: 'í¬íŠ¸ ëª¨ë‹ˆí„°ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤'
      })
    } else if (action === 'stop') {
      portManager.isPortMonitoring = false
      res.json({
        success: true,
        message: 'í¬íŠ¸ ëª¨ë‹ˆí„°ë§ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤'
      })
    } else {
      res.status(400).json({
        success: false,
        error: 'ì˜ëª»ëœ ì•¡ì…˜ì…ë‹ˆë‹¤ (start/stop)'
      })
    }
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ë Œë”ë§ ì¤‘ì§€ API
app.post('/api/synthetic/stop-rendering', async (req, res) => {
  try {
    const { jobId } = req.body
    
    if (activeJobs.has(jobId)) {
      const job = activeJobs.get(jobId)
      job.status = 'stopped'
      
      // Blender í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
      if (job.blenderProcess) {
        job.blenderProcess.kill()
      }
      
      activeJobs.delete(jobId)
    }
    
    res.json({
      success: true,
      message: 'ë Œë”ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤'
    })
    
  } catch (error) {
    console.error('ë Œë”ë§ ì¤‘ì§€ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ë Œë”ë§ ì§„í–‰ ìƒí™© API
app.get('/api/synthetic/progress/:jobId', (req, res) => {
  const { jobId } = req.params
  
  if (activeJobs.has(jobId)) {
    const job = activeJobs.get(jobId)
    res.set('Cache-Control', 'no-store, no-cache, must-revalidate, proxy-revalidate')
    res.set('Pragma', 'no-cache')
    res.set('Expires', '0')
    res.set('Surrogate-Control', 'no-store')
    res.json({
      success: true,
      progress: job.progress,
      status: job.status,
      logs: job.logs.slice(-10) // ìµœê·¼ 10ê°œ ë¡œê·¸ë§Œ
    })
  } else {
    res.set('Cache-Control', 'no-store, no-cache, must-revalidate, proxy-revalidate')
    res.set('Pragma', 'no-cache')
    res.set('Expires', '0')
    res.set('Surrogate-Control', 'no-store')
    res.json({
      success: false,
      message: 'ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
    })
  }
})

// ë Œë”ë§ ê²°ê³¼ ì¡°íšŒ API
app.get('/api/synthetic/results', async (req, res) => {
  try {
    const { data, error } = await supabase
      .from('synthetic_dataset')
      .select('*')
      .order('created_at', { ascending: false })
      .limit(50)
    
    if (error) throw error
    
    res.json({
      success: true,
      results: data
    })
    
  } catch (error) {
    console.error('ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// í†µê³„ ì¡°íšŒ API
app.get('/api/synthetic/stats', async (req, res) => {
  try {
    // ì´ ë¶€í’ˆ ìˆ˜
    const { count: totalParts } = await supabase
      .from('lego_parts')
      .select('*', { count: 'exact' })
    
    // ë Œë”ë§ëœ ì´ë¯¸ì§€ ìˆ˜
    const { count: renderedImages } = await supabase
      .from('synthetic_dataset')
      .select('*', { count: 'exact' })
    
    // ì €ì¥ì†Œ ì‚¬ìš©ëŸ‰ (ì¶”ì •)
    const { data: storageData } = await supabase
      .storage
      .from('lego-synthetic')
      .list('synthetic', { limit: 1000 })
    
    const storageUsed = storageData ? 
      `${(storageData.length * 0.5).toFixed(1)} GB` : '0 GB'
    
    res.json({
      success: true,
      stats: {
        totalParts: totalParts || 0,
        renderedImages: renderedImages || 0,
        storageUsed,
        renderingStatus: activeJobs.size > 0 ? 'ë Œë”ë§ ì¤‘' : 'ëŒ€ê¸° ì¤‘'
      }
    })
    
  } catch (error) {
    console.error('í†µê³„ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// WebP ë³€í™˜ í”„ë¡ì‹œëŠ” ë³„ë„ ì„œë²„ë¡œ ì´ë™ë¨ (í¬íŠ¸ 3004)
// ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ì œê±°ë¨ - server/webp-image-api.js ì‚¬ìš©

// ìº¡ì²˜ ì—…ë¡œë“œ API (lego-captures ë²„í‚·)
app.post('/api/captures/upload', async (req, res) => {
  try {
    const { setNum, partId, imageData } = req.body || {}
    if (!setNum || !partId || !imageData) {
      return res.status(400).json({ success: false, error: 'setNum, partId, imageData required' })
    }

    // dataURL -> Buffer
    const m = String(imageData).match(/^data:(.*?);base64,(.*)$/)
    if (!m) return res.status(400).json({ success: false, error: 'invalid imageData format' })
    const contentType = m[1] || 'image/webp'
    const buffer = Buffer.from(m[2], 'base64')

    // ê²½ë¡œ: captures/<setNum>/<partId>/<timestamp>.webp
    const ts = new Date().toISOString().replace(/[-:T.Z]/g, '').slice(0,14)
    const ext = contentType.includes('webp') ? 'webp' : (contentType.includes('png') ? 'png' : 'jpg')
    const filePath = `captures/${setNum}/${partId}/${ts}.${ext}`

    const { error: upErr } = await supabase
      .storage
      .from('lego-captures')
      .upload(filePath, buffer, { contentType, upsert: false })

    if (upErr) return res.status(500).json({ success: false, error: upErr.message || 'upload failed' })

    // ë¹„ê³µê°œ ë²„í‚·ì´ë¯€ë¡œ ì„œëª… URL ë°œê¸‰
    const { data: signed, error: signErr } = await supabase
      .storage
      .from('lego-captures')
      .createSignedUrl(filePath, 60 * 10) // 10ë¶„

    if (signErr) return res.status(500).json({ success: true, path: filePath })

    return res.json({ success: true, path: filePath, signedUrl: signed?.signedUrl })
  } catch (e) {
    console.error('ìº¡ì²˜ ì—…ë¡œë“œ ì‹¤íŒ¨:', e)
    res.status(500).json({ success: false, error: e.message })
  }
})

// ì„¸íŠ¸ë³„ ìº¡ì²˜ ë¦¬í¬íŠ¸ API: í™•ì¸/ëˆ„ë½ ì§‘ê³„
app.get('/api/captures/report/:setNum', async (req, res) => {
  try {
    const rawSet = String(req.params.setNum || '').trim()
    if (!rawSet) return res.status(400).json({ success: false, error: 'setNum required' })

    // ì„¸íŠ¸ ì‹ë³„: ì •í™• ì¼ì¹˜ â†’ base(-1 ì¶”ê°€) â†’ LIKE
    let setNum = rawSet
    if (!setNum.includes('-')) setNum = `${setNum}-1`

    // lego_sets ì¡°íšŒ
    let legoSet = null
    {
      const { data, error } = await supabase
        .from('lego_sets')
        .select('id, set_num, name')
        .eq('set_num', setNum)
        .limit(1)
        .maybeSingle()
      if (!error && data) legoSet = data
    }
    if (!legoSet && setNum.includes('-')) {
      const base = setNum.split('-')[0]
      const { data } = await supabase
        .from('lego_sets')
        .select('id, set_num, name')
        .eq('set_num', `${base}-1`)
        .limit(1)
        .maybeSingle()
      if (data) legoSet = data
    }
    if (!legoSet) {
      const { data } = await supabase
        .from('lego_sets')
        .select('id, set_num, name')
        .like('set_num', `${setNum.split('-')[0]}%`)
        .limit(1)
        .maybeSingle()
      if (data) legoSet = data
    }
    if (!legoSet) return res.status(404).json({ success: false, error: 'set not found' })

    // ê¸°ëŒ€ ë¶€í’ˆ ì§‘í•©
    const { data: setParts, error: spErr } = await supabase
      .from('set_parts')
      .select('lego_parts(part_num), quantity')
      .eq('set_id', legoSet.id)

    if (spErr) return res.status(500).json({ success: false, error: spErr.message })
    const expectedParts = new Set((setParts || []).map(r => r.lego_parts?.part_num).filter(Boolean))

    // ìº¡ì²˜ëœ íŒŒíŠ¸: í´ë”ëª… ê¸°ì¤€ captures/<set>/<partId>/...
    const capturedParts = new Set()
    const { data: level1 } = await supabase
      .storage
      .from('lego-captures')
      .list(`captures/${rawSet}`, { limit: 1000 })
    if (Array.isArray(level1)) {
      for (const entry of level1) {
        const name = entry?.name
        const isDir = entry?.id?.endsWith('/') || entry?.metadata?.is_directory === true || entry?.metadata?.mimetype === null
        if (name && (!entry?.metadata || isDir)) {
          capturedParts.add(name)
        }
      }
    }

    // êµì§‘í•©/ì°¨ì§‘í•©
    const confirmed = Array.from(expectedParts).filter(p => capturedParts.has(p))
    const missing = Array.from(expectedParts).filter(p => !capturedParts.has(p))

    return res.json({
      success: true,
      set: { id: legoSet.id, setNum: legoSet.set_num, name: legoSet.name },
      counts: { expected: expectedParts.size, confirmed: confirmed.length, missing: missing.length },
      confirmed,
      missing
    })
  } catch (e) {
    console.error('ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨:', e)
    res.status(500).json({ success: false, error: e.message })
  }
})

// ì—˜ë¦¬ë¨¼íŠ¸ â†’ ë¶€í’ˆ/ìƒ‰ìƒ í•´ì„ API
app.get('/api/synthetic/resolve-element/:elementId', async (req, res) => {
  try {
    const { elementId } = req.params
    if (!elementId) return res.status(400).json({ success: false, error: 'elementId required' })
    // part-color íŒ¨í„´ ìš°ì„ 
    const m = elementId.trim().match(/^([A-Za-z0-9]+)[-_](\d+)$/)
    if (m) {
      return res.json({ success: true, partId: m[1], colorId: parseInt(m[2], 10) })
    }
    // ìˆ«ìí˜• elementIdëŠ” Rebrickable ì¡°íšŒ
    if (/^\d+$/.test(elementId.trim())) {
      const resolved = await resolveElementToPartAndColor(elementId.trim())
      if (resolved) return res.json({ success: true, ...resolved })
      return res.status(404).json({ success: false, error: 'resolve failed' })
    }
    return res.status(400).json({ success: false, error: 'invalid elementId format' })
  } catch (e) {
    console.error(e)
    res.status(500).json({ success: false, error: e.message })
  }
})

// ì•ˆì „í•œ fetch ë³´ì¡° (Node <18 ëŒ€ì‘)
let safeFetch = globalThis.fetch
async function ensureFetch() {
  if (!safeFetch) {
    try {
      const mod = await import('node-fetch')
      safeFetch = mod.default
    } catch (e) {
      console.error('âŒ fetch ì‚¬ìš© ë¶ˆê°€: node-fetch ì„¤ì¹˜ í•„ìš”', e)
    }
  }
  return safeFetch
}

// elementId â†’ part/color í•´ì„ (ë°ì´í„°ë² ì´ìŠ¤ ìš°ì„ , Rebrickable API fallback)
async function resolveElementToPartAndColor(elementId) {
  try {
    console.log(`ğŸ” elementId í•´ì„ ì‹œì‘: ${elementId}`)
    
    // 1. ë¨¼ì € set_parts í…Œì´ë¸”ì—ì„œ ì¡°íšŒ (ì„±ê³µ ë¡œì§)
    console.log('ğŸ“Š set_parts í…Œì´ë¸”ì—ì„œ elementId ì¡°íšŒ ì¤‘...')
    try {
      const { data: setPartData, error: setPartError } = await supabase
        .from('set_parts')
        .select(`
          element_id,
          part_id,
          lego_parts(part_num, name),
          lego_colors(id, name, rgb)
        `)
        .eq('element_id', elementId)
        .limit(1)
      
      if (setPartError) {
        console.error('âŒ set_parts ì¡°íšŒ ì˜¤ë¥˜:', setPartError)
      } else if (setPartData && setPartData.length > 0) {
        const setPart = setPartData[0]
        console.log(`âœ… set_partsì—ì„œ ë°œê²¬: elementId ${elementId} â†’ partId ${setPart.part_id}`)
        
        // elementIdëŠ” ìƒ‰ìƒ ì •ë³´ê°€ í¬í•¨ëœ ê³ ìœ  ì‹ë³„ì
        // set_parts í…Œì´ë¸”ì—ì„œ ìƒ‰ìƒ ì •ë³´ ì¶”ì¶œ
        const colorId = setPart.lego_colors ? setPart.lego_colors.id : null
        const colorName = setPart.lego_colors ? setPart.lego_colors.name : 'unknown'
        const colorRgb = setPart.lego_colors ? setPart.lego_colors.rgb : null
        
        // RGB ê°’ì„ Blenderì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜ (# ì œê±° ì²˜ë¦¬)
        let blenderRgba = null
        if (colorRgb) {
          // # ì œê±°í•˜ê³  6ìë¦¬ HEX í™•ì¸
          const cleanRgb = colorRgb.replace(/^#/, '')
          if (cleanRgb.length === 6 && /^[0-9A-Fa-f]{6}$/.test(cleanRgb)) {
            const r = parseInt(cleanRgb.substring(0, 2), 16) / 255
            const g = parseInt(cleanRgb.substring(2, 4), 16) / 255
            const b = parseInt(cleanRgb.substring(4, 6), 16) / 255
          blenderRgba = [r, g, b, 1.0]
            console.log(`ğŸ¨ RGB ë³€í™˜ ì„±ê³µ: ${colorRgb} â†’ [${r.toFixed(3)}, ${g.toFixed(3)}, ${b.toFixed(3)}, 1.0]`)
          } else {
            console.log(`âš ï¸ RGB í˜•ì‹ ì˜¤ë¥˜: ${colorRgb} (ì˜ˆìƒ: 6ìë¦¬ HEX)`)
          }
        }
        
        console.log(`ğŸ¨ elementId ìƒ‰ìƒ ì •ë³´: colorId=${colorId}, colorName="${colorName}", rgb=${colorRgb}`)
        console.log(`ğŸ¨ Blender RGBA: ${blenderRgba ? JSON.stringify(blenderRgba) : 'null'}`)
        
        return { 
          partId: setPart.part_id, 
          colorId: null, // ìˆ«ì ID ëŒ€ì‹  RGB ì§ì ‘ ì‚¬ìš©
          colorName: colorName,
          colorRgb: colorRgb,
          blenderRgba: blenderRgba, // Blenderì—ì„œ ì§ì ‘ ì‚¬ìš©í•  RGBA ê°’
          originalColorId: colorId // ì›ë³¸ UUID ë³´ì¡´
        }
      } else {
        console.log('ğŸ“­ set_partsì—ì„œ elementIdë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ')
      }
    } catch (setPartError) {
      console.error('ğŸ’¥ set_parts ì¡°íšŒ ì‹¤íŒ¨:', setPartError)
    }
    
    // 2. set_partsì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš° parts_masterì—ì„œ ì¡°íšŒ
    console.log('ğŸ“Š parts_master í…Œì´ë¸”ì—ì„œ elementId ì¡°íšŒ ì¤‘...')
    try {
      const { data: partData, error: dbError } = await supabase
        .from('parts_master')
        .select('part_id, element_id')
        .eq('element_id', elementId)
        .limit(1)
      
      if (dbError) {
        console.error('âŒ parts_master ì¡°íšŒ ì˜¤ë¥˜:', dbError)
      } else if (partData && partData.length > 0) {
        const part = partData[0]
        console.log(`âœ… parts_masterì—ì„œ ë°œê²¬: partId=${part.part_id}`)
        
        return { 
          partId: part.part_id, 
          colorId: null 
        }
      } else {
        console.log('ğŸ“­ parts_masterì—ì„œë„ elementIdë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ')
      }
    } catch (dbError) {
      console.error('ğŸ’¥ parts_master ì¡°íšŒ ì‹¤íŒ¨:', dbError)
    }
    
    // 2. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš° Rebrickable API ì‹œë„
    console.log('ğŸŒ Rebrickable API ì¡°íšŒ ì‹œë„...')
    
    // í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì‹œë„
    try {
      const { config } = await import('dotenv')
      config({ path: path.join(__dirname, '..', 'config', 'synthetic_dataset.env') })
    } catch (e) {
      console.log('âš ï¸ dotenv ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©')
    }
    
    const apiKey = process.env.VITE_REBRICKABLE_API_KEY
    console.log(`ğŸ”‘ API í‚¤ ì¡´ì¬ ì—¬ë¶€: ${!!apiKey}`)
    console.log(`ğŸ”‘ API í‚¤ ë¯¸ë¦¬ë³´ê¸°: ${apiKey ? apiKey.substring(0, 8) + '...' : 'ì—†ìŒ'}`)
    
    if (!apiKey || apiKey === 'your-rebrickable-api-key-here') {
      console.log('âš ï¸ Rebrickable API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ, fallback ëª¨ë“œë¡œ ì „í™˜')
      return null
    }
    
    const url = `https://rebrickable.com/api/v3/lego/elements/${encodeURIComponent(elementId)}/?key=${apiKey}`
    console.log(`ğŸŒ API URL: ${url.replace(apiKey, 'API_KEY_HIDDEN')}`)
    
    const f = await ensureFetch()
    if (!f) {
      console.error('âŒ fetch í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
      return null
    }
    
    console.log('ğŸ“¡ API ìš”ì²­ ì „ì†¡ ì¤‘...')
    const res = await f(url, { headers: { 'Accept': 'application/json' } })
    console.log(`ğŸ“¡ API ì‘ë‹µ ìƒíƒœ: ${res.status} ${res.statusText}`)
    
    if (!res.ok) {
      const errorText = await res.text()
      console.error(`âŒ API ì‘ë‹µ ì˜¤ë¥˜: ${res.status} - ${errorText}`)
      return null
    }
    
    const json = await res.json()
    console.log('ğŸ“„ API ì‘ë‹µ ë°ì´í„°:', JSON.stringify(json, null, 2))
    
    // ì‘ë‹µ ì˜ˆ: { part: { part_num }, color: { id } }
    const p = json?.part?.part_num
    const c = json?.color?.id
    console.log(`ğŸ” íŒŒì‹±ëœ ë°ì´í„° - partId: ${p}, colorId: ${c}`)
    
    if (p && Number.isInteger(c)) {
      console.log(`âœ… Rebrickable APIì—ì„œ elementId ${elementId} í•´ì„ ì„±ê³µ: partId=${p}, colorId=${c}`)
      return { partId: p, colorId: c }
    }
    
    console.error(`âŒ ìœ íš¨í•˜ì§€ ì•Šì€ API ì‘ë‹µ í˜•ì‹: partId=${p}, colorId=${c}`)
    return null
  } catch (e) {
    console.error('ğŸ’¥ element í•´ì„ ì‹¤íŒ¨:', e)
    console.error('ğŸ“Š ì˜¤ë¥˜ íƒ€ì…:', e.name)
    console.error('ğŸ“Š ì˜¤ë¥˜ ë©”ì‹œì§€:', e.message)
    if (e.stack) {
      console.error('ğŸ“Š ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:', e.stack)
    }
    return null
  }
}

// Rebrickableì—ì„œ partId â†’ LDraw íŒŒíŠ¸ë²ˆí˜¸ í•´ì„
async function resolvePartToLdraw(partId) {
  try {
    const apiKey = process.env.VITE_REBRICKABLE_API_KEY
    if (!apiKey || !partId) return null
    const url = `https://rebrickable.com/api/v3/lego/parts/${encodeURIComponent(partId)}/?key=${apiKey}`
    const f = await ensureFetch()
    if (!f) return null
    const res = await f(url, { headers: { 'Accept': 'application/json' } })
    if (!res.ok) return null
    const json = await res.json()
    const ldrawIds = json?.external_ids?.LDraw
    if (Array.isArray(ldrawIds) && ldrawIds.length > 0) {
      return String(ldrawIds[0])
    }
    return null
  } catch (e) {
    console.error('partâ†’LDraw í•´ì„ ì‹¤íŒ¨:', e)
    return null
  }
}

// Rebrickableì—ì„œ colorId â†’ HEX ì¡°íšŒ
async function resolveColorHex(colorId) {
  try {
    const apiKey = process.env.VITE_REBRICKABLE_API_KEY
    if (!apiKey) return null
    const url = `https://rebrickable.com/api/v3/lego/colors/${encodeURIComponent(colorId)}/?key=${apiKey}`
    const f = await ensureFetch()
    if (!f) return null
    const res = await f(url, { headers: { 'Accept': 'application/json' } })
    if (!res.ok) return null
    const json = await res.json()
    // ì‘ë‹µ ì˜ˆ: { rgb: "6D6E5C" }
    const hex = json?.rgb
    if (typeof hex === 'string' && /^[0-9A-Fa-f]{6}$/.test(hex)) {
      return `#${hex}`
    }
    return null
  } catch (e) {
    console.error('color HEX ì¡°íšŒ ì‹¤íŒ¨:', e)
    return null
  }
}

// Blender ë Œë”ë§ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
async function startBlenderRendering(job) {
  const { mode, partId, setNum, imageCount } = job.config
  const quality = job.config.quality ? (job.config.quality === 'medium' ? 'normal' : job.config.quality) : 'high' // ğŸ”§ ìˆ˜ì •ë¨
  const background = job.config.background || 'white'
  // ì •ë°€ë„ ëª¨ë“œ: í° ë°°ê²½ì¼ ë•Œ Standard ê°•ì œ, grayëŠ” Filmic
  const colorManagement = 'standard'
  // í•´ìƒë„/í™”ë©´ì ìœ ìœ¨(ê¸°ë³¸ ì •ë°€ ê°’)
  const resolution = job.config.resolution || '1024x1024'
  const targetFill = typeof job.config.targetFill === 'number' ? job.config.targetFill : 0.92
  let colorId = job.config.colorId
  let effectivePartId = partId
  let displayPartId = partId
  let resolved = null // ğŸ”§ ìˆ˜ì •ë¨: resolved ë³€ìˆ˜ë¥¼ í•¨ìˆ˜ ìŠ¤ì½”í”„ë¡œ ì´ë™

  // ğŸ”§ ìˆ˜ì •ë¨: ì„¸íŠ¸ ë Œë”ë§ ëª¨ë“œ ì²˜ë¦¬
  if (mode === 'set' && setNum) {
    console.log(`ğŸ¯ ì„¸íŠ¸ ë Œë”ë§ ëª¨ë“œ: setNum=${setNum}`)
    job.logs.push({ timestamp: new Date(), type: 'info', message: `ì„¸íŠ¸ ${setNum} ë Œë”ë§ ì‹œì‘...` })
    
    try {
      // ì„¸íŠ¸ ë²ˆí˜¸ ì •ê·œí™” (ì˜ˆ: "76917" â†’ "76917-1")
      let normalizedSetNum = setNum.trim()
      if (!normalizedSetNum.includes('-')) {
        normalizedSetNum = `${normalizedSetNum}-1`
      }
      
      // lego_sets í…Œì´ë¸”ì—ì„œ ì„¸íŠ¸ ì¡°íšŒ
      let legoSet = null
      const { data: setData, error: setError } = await supabase
        .from('lego_sets')
        .select('id, set_num, name')
        .eq('set_num', normalizedSetNum)
        .limit(1)
        .maybeSingle()
      
      if (setError || !setData) {
        // base ë²ˆí˜¸ë¡œ ì¬ì‹œë„
        const baseNum = normalizedSetNum.split('-')[0]
        const { data: baseData } = await supabase
          .from('lego_sets')
          .select('id, set_num, name')
          .eq('set_num', `${baseNum}-1`)
          .limit(1)
          .maybeSingle()
        
        if (baseData) legoSet = baseData
      } else {
        legoSet = setData
      }
      
      if (!legoSet) {
        job.status = 'failed'
        job.logs.push({ timestamp: new Date(), type: 'error', message: `ì„¸íŠ¸ ${setNum}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.` })
        return
      }
      
      job.logs.push({ timestamp: new Date(), type: 'info', message: `âœ… ì„¸íŠ¸ ë°œê²¬: ${legoSet.set_num} - ${legoSet.name}` })
      
      // set_parts í…Œì´ë¸”ì—ì„œ ì„¸íŠ¸ì˜ ëª¨ë“  ë¶€í’ˆ ì¡°íšŒ
      const { data: setPartsData, error: partsError } = await supabase
        .from('set_parts')
        .select(`
          element_id,
          part_id,
          quantity,
          lego_parts(part_num, name),
          lego_colors(id, name, rgb)
        `)
        .eq('set_id', legoSet.id)
      
      if (partsError || !setPartsData || setPartsData.length === 0) {
        job.status = 'failed'
        job.logs.push({ timestamp: new Date(), type: 'error', message: `ì„¸íŠ¸ ${setNum}ì˜ ë¶€í’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.` })
        return
      }
      
      job.logs.push({ timestamp: new Date(), type: 'info', message: `ğŸ“¦ ì„¸íŠ¸ ë¶€í’ˆ ${setPartsData.length}ê°œ ë°œê²¬` })
      
      // ğŸ”§ ìˆ˜ì •ë¨: í•œ ê°œì”© ìˆœì°¨ ì²˜ë¦¬ (ê°€ì¥ ì•ˆì „í•œ ë°©ì‹)
      // ë™ì¼ ë¶€í’ˆ ì—˜ë¦¬ë¨¼íŠ¸ì•„ì´ë”” ë° íŒŒíŠ¸ë„˜ë²„ ì¤‘ë³µ ë°©ì§€
      const processedKeys = new Set()
      const results = {
        completed: 0,
        failed: 0,
        errors: []
      }
      
      job.logs.push({ timestamp: new Date(), type: 'info', message: `ğŸš€ ${setPartsData.length}ê°œ ë¶€í’ˆ ìˆœì°¨ ë Œë”ë§ ì‹œì‘` })
      
      // í•œ ê°œì”© ìˆœì°¨ ì²˜ë¦¬
      for (let i = 0; i < setPartsData.length; i++) {
        const setPart = setPartsData[i]
        const elementId = setPart.element_id
        const partId = setPart.part_id
        
        if (!elementId && !partId) {
          console.warn(`âš ï¸ ë¶€í’ˆ ì •ë³´ ëˆ„ë½: elementId=${elementId}, partId=${partId}`)
          continue
        }
        
        // ì¤‘ë³µ ì²´í¬
        const dedupeKey = elementId || partId
        if (processedKeys.has(dedupeKey)) {
          job.logs.push({ 
            timestamp: new Date(), 
            type: 'info', 
            message: `â­ ì¤‘ë³µ ë¶€í’ˆ ê±´ë„ˆëœ€: ${setPart.lego_parts?.name || partId} (${elementId ? `elementId: ${elementId}` : `partId: ${partId}`})` 
          })
          continue
        }
        
        processedKeys.add(dedupeKey)
        
        // ìƒ‰ìƒ ì •ë³´ ì¶”ì¶œ (ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ RGB ê°’)
        let colorRgba = null
        if (setPart.lego_colors && setPart.lego_colors.rgb) {
          const colorRgb = setPart.lego_colors.rgb
          const cleanRgb = colorRgb.replace(/^#/, '')
          if (cleanRgb.length === 6 && /^[0-9A-Fa-f]{6}$/.test(cleanRgb)) {
            const r = parseInt(cleanRgb.substring(0, 2), 16) / 255
            const g = parseInt(cleanRgb.substring(2, 4), 16) / 255
            const b = parseInt(cleanRgb.substring(4, 6), 16) / 255
            colorRgba = [r, g, b, 1.0]
            console.log(`ğŸ¨ ì„¸íŠ¸ ë¶€í’ˆ ìƒ‰ìƒ ì •ë³´: ${colorRgb} â†’ RGBA [${r.toFixed(3)}, ${g.toFixed(3)}, ${b.toFixed(3)}, 1.0]`)
          }
        }
        
        // ë¶€í’ˆ ë Œë”ë§ ì‘ì—… ìƒì„± ë° ì¦‰ì‹œ ì‹¤í–‰
        const partJobId = `job_${Date.now()}_${elementId || partId}_${Math.random().toString(36).substr(2, 9)}`
        const partJob = {
          id: partJobId,
          status: 'running',
          progress: 0,
          config: {
            mode: 'part',
            partId: partId,
            elementId: elementId,
            imageCount: imageCount || 200,
            quality: quality,
            background: background,
            resolution: resolution,
            targetFill: targetFill,
            colorRgba: colorRgba // ğŸ”§ ìˆ˜ì •ë¨: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ ìƒ‰ìƒ ì •ë³´ ì €ì¥
          },
          startTime: new Date(),
          logs: [{
            timestamp: new Date(),
            type: 'info',
            message: `ë¶€í’ˆ ë Œë”ë§ ì¤‘: ${setPart.lego_parts?.name || partId} (elementId: ${elementId}) - ${i + 1}/${setPartsData.length}`
          }]
        }
        
        activeJobs.set(partJobId, partJob)
        
        try {
          job.logs.push({ 
            timestamp: new Date(), 
            type: 'info', 
            message: `ğŸ“¦ ë¶€í’ˆ ${i + 1}/${setPartsData.length} ë Œë”ë§ ì‹œì‘: ${setPart.lego_parts?.name || partId}` 
          })
          
          // ğŸ”§ ìˆ˜ì •ë¨: í•œ ê°œì”© ìˆœì°¨ ë Œë”ë§ ë° ì™„ë£Œ ëŒ€ê¸°
          await startBlenderRendering(partJob)
          
          // ë Œë”ë§ ì™„ë£Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 20ë¶„)
          const maxWaitTime = 20 * 60 * 1000
          const startTime = Date.now()
          
          while (partJob.status === 'running' && (Date.now() - startTime) < maxWaitTime) {
            await new Promise(resolve => setTimeout(resolve, 3000)) // 3ì´ˆë§ˆë‹¤ ì²´í¬
            
            // í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
            if (partJob.blenderProcess && partJob.blenderProcess.exitCode !== null) {
              break
            }
          }
          
          // ìµœì¢… ìƒíƒœ í™•ì¸
          if (partJob.status === 'completed') {
            results.completed++
            job.logs.push({ 
              timestamp: new Date(), 
              type: 'success', 
              message: `âœ… ë¶€í’ˆ ${i + 1}/${setPartsData.length} ì™„ë£Œ: ${setPart.lego_parts?.name || partId}` 
            })
          } else if (partJob.status === 'failed') {
            results.failed++
            results.errors.push({
              partId: partJob.config.partId,
              elementId: partJob.config.elementId,
              error: 'ë Œë”ë§ ì‹¤íŒ¨ ë˜ëŠ” íƒ€ì„ì•„ì›ƒ'
            })
            job.logs.push({ 
              timestamp: new Date(), 
              type: 'error', 
              message: `âŒ ë¶€í’ˆ ${i + 1}/${setPartsData.length} ì‹¤íŒ¨: ${setPart.lego_parts?.name || partId}` 
            })
          }
          
          // ì‘ì—… ì •ë³´ ì‚­ì œ (ë©”ëª¨ë¦¬ ì •ë¦¬)
          setTimeout(() => {
            activeJobs.delete(partJobId)
          }, 60000) // 1ë¶„ í›„ ì‚­ì œ
          
        } catch (renderError) {
          console.error(`âŒ ë¶€í’ˆ ë Œë”ë§ ì‹¤íŒ¨ (${partJob.id}):`, renderError)
          partJob.status = 'failed'
          results.failed++
          results.errors.push({
            partId: partJob.config.partId,
            elementId: partJob.config.elementId,
            error: renderError?.message || String(renderError)
          })
          job.logs.push({ 
            timestamp: new Date(), 
            type: 'error', 
            message: `âŒ ë¶€í’ˆ ${i + 1}/${setPartsData.length} ë Œë”ë§ ì˜¤ë¥˜: ${renderError.message}` 
          })
          // ì—ëŸ¬ ë°œìƒí•´ë„ ë‹¤ìŒ ë¶€í’ˆ ê³„ì† ì²˜ë¦¬
        }
        
        // ë‹¤ìŒ ë¶€í’ˆ ì²˜ë¦¬ ì „ ì ì‹œ ëŒ€ê¸° (ì‹œìŠ¤í…œ ì•ˆì •í™”)
        if (i < setPartsData.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 2000)) // 2ì´ˆ ëŒ€ê¸°
        }
      }
      
      job.status = 'completed'
      job.progress = 100
      job.logs.push({ 
        timestamp: new Date(), 
        type: 'success', 
        message: `âœ… ì„¸íŠ¸ ${setNum} ë Œë”ë§ ì™„ë£Œ (ì„±ê³µ: ${results.completed}ê°œ, ì‹¤íŒ¨: ${results.failed}ê°œ)` 
      })
      
      if (results.failed > 0) {
        job.logs.push({ 
          timestamp: new Date(), 
          type: 'warning', 
          message: `âš ï¸ ${results.failed}ê°œ ë¶€í’ˆ ë Œë”ë§ ì‹¤íŒ¨. ìì„¸í•œ ë‚´ìš©ì€ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.` 
        })
      }
      
      // ğŸ”§ ìˆ˜ì •ë¨: ì„¸íŠ¸ ë Œë”ë§ ì™„ë£Œ í›„ ì „ì²´ ë°ì´í„°ì…‹ train/val ë¶„í•  ì‹¤í–‰
      try {
        console.log('ğŸ“Š ì„¸íŠ¸ ë Œë”ë§ ì™„ë£Œ - ì „ì²´ ë°ì´í„°ì…‹ train/val ë¶„í•  ì‹œì‘...')
        job.logs.push({
          timestamp: new Date(),
          message: 'ì „ì²´ ë°ì´í„°ì…‹ train/val ë¶„í•  ì‹œì‘ (ì„¸íŠ¸ ë Œë”ë§ ì™„ë£Œ)',
          type: 'info'
        })
        
        const prepareProcess = spawn('python', [
          path.join(__dirname, '..', 'scripts', 'prepare_training_dataset.py'),
          '--source', path.join(__dirname, '..', 'output', 'synthetic'),
          '--output', path.join(__dirname, '..', 'output', 'synthetic', 'dataset_synthetic')
        ], {
          cwd: path.join(__dirname, '..'),
          stdio: ['pipe', 'pipe', 'pipe'],
          env: {
            ...process.env,
            PYTHONIOENCODING: 'utf-8',
            LANG: 'ko_KR.UTF-8',
            LC_ALL: 'ko_KR.UTF-8',
            PYTHONUTF8: '1'
          }
        })
        
        let prepareOutput = ''
        let prepareError = ''
        
        prepareProcess.stdout.on('data', (data) => {
          const message = data.toString('utf8').trim()
          if (message) {
            console.log(`[Dataset Prepare] ${message}`)
            prepareOutput += message + '\n'
            job.logs.push({
              timestamp: new Date(),
              message: `[Dataset Prepare] ${message}`,
              type: 'info'
            })
          }
        })
        
        prepareProcess.stderr.on('data', (data) => {
          const message = data.toString('utf8').trim()
          if (message) {
            console.error(`[Dataset Prepare Error] ${message}`)
            prepareError += message + '\n'
          }
        })
        
        prepareProcess.on('close', async (prepareCode) => {
          if (prepareCode === 0) {
            console.log('âœ… ì „ì²´ ë°ì´í„°ì…‹ train/val ë¶„í•  ì™„ë£Œ')
            job.logs.push({
              timestamp: new Date(),
              message: 'ì „ì²´ ë°ì´í„°ì…‹ train/val ë¶„í•  ì™„ë£Œ',
              type: 'success'
            })
          } else {
            console.warn(`âš ï¸ ë°ì´í„°ì…‹ ë¶„í•  ì‹¤íŒ¨ (ì½”ë“œ: ${prepareCode})`)
            job.logs.push({
              timestamp: new Date(),
              message: `ë°ì´í„°ì…‹ ë¶„í•  ì‹¤íŒ¨ (ì½”ë“œ: ${prepareCode})`,
              type: 'warning'
            })
          }
          
          // ğŸ”§ ìˆ˜ì •ë¨: ìë™ í•™ìŠµ í™œì„±í™” í™•ì¸ ë° íŠ¸ë¦¬ê±° (ì„¸íŠ¸ ë Œë”ë§ ì™„ë£Œ ì‹œ)
          try {
            const { data: autoTrainingConfig, error: configError } = await supabase
              .from('automation_config')
              .select('config_value')
              .eq('config_key', 'auto_training_enabled')
              .eq('is_active', true)
              .maybeSingle()
            
            const configValue = autoTrainingConfig?.config_value
            const autoTrainingEnabled = !configError && (
              configValue === 'true' || 
              configValue === true || 
              (typeof configValue === 'object' && configValue !== null && configValue.value === true)
            )
            
            if (autoTrainingEnabled) {
              console.log('ğŸ¤– ìë™ í•™ìŠµ í™œì„±í™”ë¨ - ì„¸íŠ¸ ë Œë”ë§ ì™„ë£Œ í›„ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹œì‘...')
              job.logs.push({
                timestamp: new Date(),
                message: 'ìë™ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹œì‘ (ì„¸íŠ¸ ë Œë”ë§ ì™„ë£Œ)',
                type: 'info'
              })
              
              // ìë™ í•™ìŠµ íŠ¸ë¦¬ê±°
              try {
                const triggerResponse = await fetch(`${process.env.VITE_SUPABASE_URL || 'https://npferbxuxocbfnfbpcnz.supabase.co'}/functions/v1/auto-training-trigger`, {
                  method: 'POST',
                  headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.VITE_SUPABASE_SERVICE_ROLE || ''}`
                  },
                  body: JSON.stringify({
                    job_id: job.id,
                    set_num: setNum,
                    completed_parts: results.completed,
                    failed_parts: results.failed
                  })
                })
                
                if (triggerResponse.ok) {
                  const triggerResult = await triggerResponse.json()
                  console.log('âœ… ìë™ í•™ìŠµ íŠ¸ë¦¬ê±° ì„±ê³µ (ì„¸íŠ¸):', triggerResult)
                  job.logs.push({
                    timestamp: new Date(),
                    message: `ìë™ í•™ìŠµ íŠ¸ë¦¬ê±° ì™„ë£Œ: ${triggerResult.message || 'ì„±ê³µ'}`,
                    type: 'success'
                  })
                } else {
                  console.warn('âš ï¸ ìë™ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤íŒ¨ (ì„¸íŠ¸):', await triggerResponse.text())
                  job.logs.push({
                    timestamp: new Date(),
                    message: 'ìë™ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤íŒ¨ (ìˆ˜ë™ ì‹¤í–‰ í•„ìš”)',
                    type: 'warning'
                  })
                }
              } catch (triggerError) {
                console.error('âŒ ìë™ í•™ìŠµ íŠ¸ë¦¬ê±° ì˜¤ë¥˜ (ì„¸íŠ¸):', triggerError)
                job.logs.push({
                  timestamp: new Date(),
                  message: `ìë™ í•™ìŠµ íŠ¸ë¦¬ê±° ì˜¤ë¥˜: ${triggerError.message}`,
                  type: 'warning'
                })
              }
            } else {
              console.log('â¸ï¸ ìë™ í•™ìŠµ ë¹„í™œì„±í™”ë¨ ë˜ëŠ” ì„¤ì • ì—†ìŒ')
            }
          } catch (autoTrainError) {
            console.error('âŒ ìë™ í•™ìŠµ ì„¤ì • í™•ì¸ ì‹¤íŒ¨:', autoTrainError)
          }
        })
      } catch (datasetSplitError) {
        console.error('âŒ ë°ì´í„°ì…‹ ë¶„í•  ì‹œì‘ ì‹¤íŒ¨:', datasetSplitError)
        job.logs.push({
          timestamp: new Date(),
          message: `ë°ì´í„°ì…‹ ë¶„í•  ì‹œì‘ ì‹¤íŒ¨: ${datasetSplitError.message}`,
          type: 'warning'
        })
      }
      
      return
      
    } catch (error) {
      console.error('ğŸ’¥ ì„¸íŠ¸ ë Œë”ë§ ì˜¤ë¥˜:', error)
      job.status = 'failed'
      job.logs.push({ timestamp: new Date(), type: 'error', message: `ì„¸íŠ¸ ë Œë”ë§ ì‹¤íŒ¨: ${error.message}` })
      return
    }
  }

  if (job.config.elementId && typeof job.config.elementId === 'string') {
    const raw = job.config.elementId.trim()
    const m = raw.match(/^([A-Za-z0-9]+)[-_](\d+)$/)
    if (m) {
      effectivePartId = m[1]
      const extractedColorId = parseInt(m[2], 10)
      colorId = extractedColorId
      job.logs.push({ timestamp: new Date(), type: 'info', message: `element ${raw} â†’ part ${effectivePartId}, color ${colorId} (íŒ¨í„´ ë§¤ì¹­)` })
      
      // ğŸ”§ ìˆ˜ì •ë¨: íŒ¨í„´ ë§¤ì¹­ ì‹œ colorIdë¡œë¶€í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ RGB ì¡°íšŒ
      try {
        const { data: colorData, error: colorError } = await supabase
          .from('lego_colors')
          .select('rgb, name')
          .eq('color_id', extractedColorId) // ğŸ”§ ìˆ˜ì •ë¨: color_idë¡œ ì¡°íšŒ (idëŠ” UUID, color_idëŠ” integer)
          .limit(1)
          .maybeSingle()
        
        if (!colorError && colorData && colorData.rgb) {
          const colorRgb = colorData.rgb
          const cleanRgb = colorRgb.replace(/^#/, '')
          if (cleanRgb.length === 6 && /^[0-9A-Fa-f]{6}$/.test(cleanRgb)) {
            const r = parseInt(cleanRgb.substring(0, 2), 16) / 255
            const g = parseInt(cleanRgb.substring(2, 4), 16) / 255
            const b = parseInt(cleanRgb.substring(4, 6), 16) / 255
            resolved = {
              partId: effectivePartId,
              colorId: extractedColorId,
              colorName: colorData.name || 'unknown',
              colorRgb: colorRgb,
              blenderRgba: [r, g, b, 1.0]
            }
            console.log(`ğŸ¨ íŒ¨í„´ ë§¤ì¹­ ìƒ‰ìƒ ì •ë³´ ì¡°íšŒ ì„±ê³µ: ${colorRgb} â†’ RGBA [${r.toFixed(3)}, ${g.toFixed(3)}, ${b.toFixed(3)}, 1.0]`)
            job.logs.push({ timestamp: new Date(), type: 'info', message: `ìƒ‰ìƒ ì •ë³´ ì¡°íšŒ: ${colorData.name || 'unknown'} (${colorRgb})` })
          }
        } else if (colorError) {
          console.warn(`âš ï¸ colorId ${extractedColorId} ì¡°íšŒ ì‹¤íŒ¨: ${colorError.message}`)
        }
      } catch (colorLookupError) {
        console.error(`âŒ colorId ìƒ‰ìƒ ì¡°íšŒ ì˜¤ë¥˜: ${colorLookupError}`)
      }
    } else if (/^\d+$/.test(raw)) {
      console.log(`ğŸ” ìˆ«ìí˜• elementId ê°ì§€: ${raw}`)
      resolved = await resolveElementToPartAndColor(raw) // ğŸ”§ ìˆ˜ì •ë¨: const ì œê±°
      if (resolved) {
        effectivePartId = resolved.partId
        colorId = resolved.colorId
        job.logs.push({ timestamp: new Date(), type: 'info', message: `element ${raw} â†’ part ${effectivePartId}, color ${colorId} (API ì¡°íšŒ)` })
      } else {
        // API ì¡°íšŒ ì‹¤íŒ¨ ì‹œ fallback: elementIdë¥¼ ê·¸ëŒ€ë¡œ partIdë¡œ ì‚¬ìš©
        console.log(`âš ï¸ API ì¡°íšŒ ì‹¤íŒ¨, fallback ëª¨ë“œë¡œ ì „í™˜: elementId ${raw}ë¥¼ partIdë¡œ ì‚¬ìš©`)
        effectivePartId = raw
        colorId = null // ìƒ‰ìƒ ì •ë³´ ì—†ìŒ
        job.logs.push({ timestamp: new Date(), type: 'warning', message: `elementId(${raw}) API ì¡°íšŒ ì‹¤íŒ¨. elementIdë¥¼ partIdë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.` })
        job.logs.push({ timestamp: new Date(), type: 'info', message: `fallback: element ${raw} â†’ part ${effectivePartId} (ìƒ‰ìƒ ì •ë³´ ì—†ìŒ)` })
        
        // ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ì ‘ ì¡°íšŒ ì‹œë„ (Supabase í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©)
        console.log('ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ì§ì ‘ ì¡°íšŒ ì‹œë„...')
        try {
          const { data: directData, error: directError } = await supabase
            .from('parts_master')
            .select('part_id')
            .eq('element_id', raw)
            .limit(1)
          
          if (!directError && directData && directData.length > 0) {
            effectivePartId = directData[0].part_id
            console.log(`âœ… ë°ì´í„°ë² ì´ìŠ¤ ì§ì ‘ ì¡°íšŒ ì„±ê³µ: elementId ${raw} â†’ partId ${effectivePartId}`)
            job.logs.push({ timestamp: new Date(), type: 'success', message: `ë°ì´í„°ë² ì´ìŠ¤ ì§ì ‘ ì¡°íšŒ ì„±ê³µ: elementId ${raw} â†’ partId ${effectivePartId}` })
          } else {
            console.log(`âŒ ë°ì´í„°ë² ì´ìŠ¤ ì§ì ‘ ì¡°íšŒ ì‹¤íŒ¨: ${directError?.message || 'ë°ì´í„° ì—†ìŒ'}`)
          }
        } catch (directError) {
          console.error('ğŸ’¥ ë°ì´í„°ë² ì´ìŠ¤ ì§ì ‘ ì¡°íšŒ ì˜¤ë¥˜:', directError)
        }
      }
    }
  }

  if (!effectivePartId) {
    job.status = 'failed'
    job.logs.push({ timestamp: new Date(), type: 'error', message: 'ìœ íš¨í•œ partIdë¥¼ ê²°ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (elementId í™•ì¸ í•„ìš”)' })
    return
  }
  // Rebrickable íŒŒíŠ¸ë²ˆí˜¸ê°€ LDrawì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ LDraw IDë¡œ ë³€í™˜ ì‹œë„
  try {
    const ldrawId = await resolvePartToLdraw(effectivePartId)
    if (ldrawId) {
      displayPartId = effectivePartId
      effectivePartId = ldrawId
      job.logs.push({ timestamp: new Date(), type: 'info', message: `part ${displayPartId} â†’ LDraw ${effectivePartId}` })
    }
  } catch {}
  
  // ë Œë”ë§ í’ˆì§ˆ ì„¤ì • (íì‡„ ì„¸ê³„ ìµœì í™”)
  const samples = quality === 'fast' ? 64 : quality === 'medium' ? 128 : quality === 'high' ? 256 : 400
  
  // Blender ëª…ë ¹ì–´ êµ¬ì„±
  const blenderPath = process.env.BLENDER_PATH || 'C:/Program Files/Blender Foundation/Blender 4.5/blender.exe'
  const scriptPath = path.join(__dirname, '../scripts/render_ldraw_to_supabase.py')
  
  const ldrawPath = process.env.LDRAW_PATH || 'C:/LDraw/parts'
  
  // Blenderì— ì „ë‹¬í•  Supabase í‚¤ ì„ íƒ: ì„œë¹„ìŠ¤ í‚¤ ìš°ì„ , ì—†ìœ¼ë©´ anon í‚¤
  const blenderSupabaseKey = process.env.SUPABASE_SERVICE_ROLE
    || process.env.VITE_SUPABASE_SERVICE_ROLE
    || process.env.SUPABASE_SERVICE_KEY
    || process.env.SUPABASE_SERVICE_KEY_JWT
    || process.env.VITE_SUPABASE_ANON_KEY

  const safeImageCount = Number.isFinite(Number(imageCount)) && Number(imageCount) > 0 ? Number(imageCount) : 200 // ğŸ”§ ìˆ˜ì •ë¨: ê¸°ìˆ ë¬¸ì„œ ê¸°ì¤€ ë¶€í’ˆë‹¹ 200ì¥
  const args = [
    '--background',
    '--python', scriptPath,
    '--',
    '--part-id', effectivePartId,
    '--count', String(safeImageCount), // ğŸ”§ ìˆ˜ì •ë¨
    '--quality', String(quality), // ğŸ”§ ìˆ˜ì •ë¨
    '--samples', String(samples),
    '--background', background,
    '--ldraw-path', ldrawPath,
    '--output-dir', './output/synthetic',
    '--output-subdir', job.config.elementId ? String(job.config.elementId) : String(displayPartId),
    ...(job.config.elementId ? ['--element-id', String(job.config.elementId)] : []),
    '--resolution', String(resolution),
    '--target-fill', String(targetFill),
    '--color-management', colorManagement,
    '--supabase-url', process.env.VITE_SUPABASE_URL,
    '--supabase-key', blenderSupabaseKey
  ]

  // elementIdì˜ ìƒ‰ìƒ ì •ë³´ë¥¼ Blenderë¡œ ì „ë‹¬
  if (job.config.elementId && colorId !== null && colorId !== undefined) {
    args.push('--color-id', String(colorId))
    console.log(`ğŸ¨ elementId ìƒ‰ìƒ ì •ë³´ ì „ë‹¬: colorId=${colorId}`)
  }
  
  // RGB ìƒ‰ìƒ ì •ë³´ë„ ì „ë‹¬ (Blenderì—ì„œ ì§ì ‘ ì‚¬ìš©)
  // ğŸ”§ ìˆ˜ì •ë¨: ìš°ì„ ìˆœìœ„ 1) job.config.colorRgba (ì„¸íŠ¸ ë Œë”ë§ì—ì„œ ì „ë‹¬), 2) resolved.blenderRgba (elementId ì¡°íšŒ ê²°ê³¼)
  let colorRgbaToSend = null
  if (job.config.colorRgba && Array.isArray(job.config.colorRgba) && job.config.colorRgba.length >= 3) {
    colorRgbaToSend = job.config.colorRgba
    console.log(`ğŸ¨ ì„¸íŠ¸ ë Œë”ë§ ìƒ‰ìƒ ì •ë³´ ì‚¬ìš©: RGBA [${colorRgbaToSend.join(', ')}]`)
  } else if (job.config.elementId && resolved && resolved.blenderRgba) {
    colorRgbaToSend = resolved.blenderRgba
    console.log(`ğŸ¨ Element ID ì¡°íšŒ ìƒ‰ìƒ ì •ë³´ ì‚¬ìš©: RGBA [${colorRgbaToSend.join(', ')}]`)
  }
  
  if (colorRgbaToSend) {
    args.push('--color-rgba', `${colorRgbaToSend[0]},${colorRgbaToSend[1]},${colorRgbaToSend[2]},${colorRgbaToSend[3] || 1.0}`)
    console.log(`ğŸ¨ Blender RGBA ì „ë‹¬: [${colorRgbaToSend.join(', ')}]`)
  }

  // ë””ë²„ê·¸: ë¯¼ê°ì •ë³´ ë…¸ì¶œ ì—†ì´ ì „ë‹¬ ì—¬ë¶€ë§Œ ë¡œê¹…
  try {
    const maskedKey = blenderSupabaseKey ? (String(blenderSupabaseKey).slice(0, 6) + 'â€¦') : 'missing'
    console.log('Blender Supabase args:', {
      url_present: !!process.env.VITE_SUPABASE_URL,
      key_present: !!blenderSupabaseKey,
      key_preview: maskedKey
    })
  } catch {}
  let colorHex = null
  if (Number.isInteger(colorId)) {
    args.push('--color-id', String(colorId))
    // ì •í™•ë„ í–¥ìƒ: HEXë„ í•¨ê»˜ ì „ë‹¬ (ê°€ëŠ¥í•˜ë©´)
    try {
      colorHex = await resolveColorHex(colorId)
      if (colorHex) {
        args.push('--color-hex', colorHex)
      }
    } catch {}
  } else if (colorId === null) {
    console.log('â„¹ï¸ colorIdê°€ nullì…ë‹ˆë‹¤. elementIdëŠ” ìƒ‰ìƒ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ íšŒìƒ‰ìœ¼ë¡œ ë Œë”ë§í•©ë‹ˆë‹¤')
    // colorIdê°€ nullì¸ ê²½ìš° Blenderì—ì„œ ê¸°ë³¸ íšŒìƒ‰ì„ ì‚¬ìš©í•˜ë„ë¡ í•¨ (ëœë¤ ìƒ‰ìƒ ê¸ˆì§€)
  }
  
  console.log('ğŸ¨ Blender ë Œë”ë§ ì‹œì‘:', blenderPath, args.join(' '))
  console.log('ğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬:', path.join(__dirname, '..'))
  console.log('ğŸ”§ Blender ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€:', fs.existsSync(blenderPath))
  
  // Blender ì‹¤í–‰ ì „ í™˜ê²½ í™•ì¸
  try {
    const scriptExists = fs.existsSync(scriptPath)
    const outputDirExists = fs.existsSync(path.dirname(args.find(arg => arg.startsWith('--output-dir'))?.split(' ')[1] || './output'))
    
    console.log('ğŸ“„ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ì¡´ì¬:', scriptExists)
    console.log('ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì¡´ì¬:', outputDirExists)
    
    if (!scriptExists) {
      throw new Error(`Blender ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${scriptPath}`)
    }
  } catch (envError) {
    console.error('âŒ í™˜ê²½ í™•ì¸ ì‹¤íŒ¨:', envError)
    job.status = 'failed'
    job.logs.push({
      timestamp: new Date(),
      message: `í™˜ê²½ í™•ì¸ ì‹¤íŒ¨: ${envError.message}`,
      type: 'error'
    })
    return
  }
  
  let blenderProcess
  try {
    // ğŸ”§ ìˆ˜ì •ë¨: Blender ê²½ë¡œ ì¡´ì¬ í™•ì¸
    if (!fs.existsSync(blenderPath)) {
      throw new Error(`Blender ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${blenderPath}`)
    }
    
    blenderProcess = spawn(blenderPath, args, {
      cwd: path.join(__dirname, '..'),
      env: { ...process.env, PYTHONIOENCODING: 'utf-8' },
      stdio: ['pipe', 'pipe', 'pipe'] // ğŸ”§ ìˆ˜ì •ë¨: ëª…ì‹œì  stdio ì„¤ì •
    })
    
    if (!blenderProcess || !blenderProcess.pid) {
      throw new Error('Blender í”„ë¡œì„¸ìŠ¤ê°€ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (PID ì—†ìŒ)')
    }
    
    console.log('âœ… Blender í”„ë¡œì„¸ìŠ¤ ì‹œì‘ë¨ (PID:', blenderProcess.pid, ')')
  } catch (spawnError) {
    console.error('âŒ Blender í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹¤íŒ¨:', spawnError)
    job.status = 'failed'
    job.logs.push({
      timestamp: new Date(),
      message: `Blender í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹¤íŒ¨: ${spawnError?.message || String(spawnError)}`,
      type: 'error'
    })
    // ğŸ”§ ìˆ˜ì •ë¨: ì—ëŸ¬ ë°œìƒí•´ë„ í•¨ìˆ˜ ë°˜í™˜ (ì„œë²„ í¬ë˜ì‹œ ë°©ì§€)
    return
  }
  
  job.blenderProcess = blenderProcess
  
  // í”„ë¡œì„¸ìŠ¤ ì¶œë ¥ ì²˜ë¦¬
  blenderProcess.stdout.on('data', (data) => {
    const output = data.toString()
    console.log('ğŸ¨ Blender ì¶œë ¥:', output.trim())
    
    // ì§„í–‰ë¥  íŒŒì‹± (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
    const progressPatterns = [
      /(\d+)%/,
      /progress[:\s]*(\d+)%/i,
      /rendering[:\s]*(\d+)%/i,
      /frame[:\s]*(\d+)%/i
    ]
    
    for (const pattern of progressPatterns) {
      const match = output.match(pattern)
      if (match) {
        const progress = parseInt(match[1])
        if (progress > job.progress) {
          job.progress = Math.min(progress, 100)
          console.log(`ğŸ“Š ì§„í–‰ë¥  ì—…ë°ì´íŠ¸: ${job.progress}%`)
        }
        break
      }
    }
    
    // ëª¨ë“  ì¶œë ¥ì„ ë¡œê·¸ì— ì¶”ê°€ (ë””ë²„ê¹…ìš©)
    job.logs.push({
      timestamp: new Date(),
      message: output.trim(),
      type: output.includes('ì˜¤ë¥˜') || output.includes('error') || output.includes('Error') ? 'error' : 
             output.includes('ì™„ë£Œ') || output.includes('success') ? 'success' : 'info'
    })
    
    // ì¤‘ìš”í•œ ë©”ì‹œì§€ëŠ” ë³„ë„ ë¡œê¹…
    if (output.includes('ë Œë”ë§') || output.includes('ì™„ë£Œ') || output.includes('ì˜¤ë¥˜') || output.includes('error') || output.includes('Error')) {
      console.log(`ğŸ“ ì¤‘ìš” ë©”ì‹œì§€: ${output.trim()}`)
    }
  })
  
  blenderProcess.stderr.on('data', (data) => {
    const error = data.toString()
    console.error('âŒ Blender ì˜¤ë¥˜:', error.trim())
    
    job.logs.push({
      timestamp: new Date(),
      message: error.trim(),
      type: 'error'
    })
  })
  
  // í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜ ì´ë²¤íŠ¸ ì²˜ë¦¬
  blenderProcess.on('error', (error) => {
    console.error('ğŸ’¥ Blender í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error)
    job.status = 'failed'
    job.logs.push({
      timestamp: new Date(),
      message: `í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: ${error.message}`,
      type: 'error'
    })
    // ğŸ”§ ìˆ˜ì •ë¨: ì—ëŸ¬ ë°œìƒí•´ë„ ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰ (ë‹¤ë¥¸ ì‘ì—… ìœ ì§€)
    // ì´ ì—ëŸ¬ëŠ” í•´ë‹¹ ì‘ì—…ì—ë§Œ ì˜í–¥
  })
  
  blenderProcess.on('close', async (code) => {
    try {
    console.log(`ğŸ Blender í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ: ì½”ë“œ ${code}`)
    
    if (code === 0) {
      console.log('âœ… ë Œë”ë§ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ')
      job.status = 'completed'
      job.progress = 100
      job.logs.push({
        timestamp: new Date(),
        message: 'ë Œë”ë§ ì™„ë£Œ',
          type: 'success'
        })
        
        // ğŸ”§ ìˆ˜ì •ë¨: ë‹¨ì¼ ë¶€í’ˆ ë Œë”ë§ ì™„ë£Œ ì‹œì—ëŠ” ë¶„í• í•˜ì§€ ì•ŠìŒ (ì„¸íŠ¸ ë Œë”ë§ ì™„ë£Œ ì‹œì—ë§Œ ë¶„í• )
        // ë‹¨ì¼ ë¶€í’ˆì€ ì„¸íŠ¸ê°€ ì•„ë‹ˆë¯€ë¡œ ì „ì²´ ë¶„í• ì„ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        if (job.config.mode !== 'set') {
          console.log('ğŸ“Š ë‹¨ì¼ ë¶€í’ˆ ë Œë”ë§ ì™„ë£Œ (ì„¸íŠ¸ê°€ ì•„ë‹ˆë¯€ë¡œ ë¶„í•  ê±´ë„ˆëœ€)')
        } else {
          // ì„¸íŠ¸ ë Œë”ë§ì¸ ê²½ìš°ì—ëŠ” ì„¸íŠ¸ ë Œë”ë§ ì™„ë£Œ ì²˜ë¦¬ì—ì„œ ë¶„í• í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
          console.log('ğŸ“Š ì„¸íŠ¸ ë Œë”ë§ ì¤‘ ë¶€í’ˆ ì™„ë£Œ (ì „ì²´ ì„¸íŠ¸ ì™„ë£Œ í›„ ë¶„í•  ì˜ˆì •)')
        }
    } else {
      console.error(`âŒ ë Œë”ë§ ì‹¤íŒ¨ - ì¢…ë£Œ ì½”ë“œ: ${code}`)
      job.status = 'failed'
      job.logs.push({
        timestamp: new Date(),
        message: `ë Œë”ë§ ì‹¤íŒ¨ (ì½”ë“œ: ${code})`,
        type: 'error'
      })
    }
    
    // 5ë¶„ í›„ ì‘ì—… ì •ë³´ ì‚­ì œ
    setTimeout(() => {
      console.log(`ğŸ—‘ï¸ ì‘ì—… ${job.id} ì •ë³´ ì‚­ì œ`)
      activeJobs.delete(job.id)
    }, 5 * 60 * 1000)
    } catch (closeHandlerError) {
      // ğŸ”§ ìˆ˜ì •ë¨: close í•¸ë“¤ëŸ¬ ë‚´ë¶€ ì—ëŸ¬ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
      console.error('âŒ [Blender close í•¸ë“¤ëŸ¬ ì—ëŸ¬]:', closeHandlerError)
      // ì—ëŸ¬ ë°œìƒí•´ë„ ì‘ì—… ìƒíƒœëŠ” ì—…ë°ì´íŠ¸ ì‹œë„
      if (job && job.status !== 'failed') {
        job.status = 'failed'
        job.logs.push({
          timestamp: new Date(),
          message: `í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: ${closeHandlerError.message}`,
          type: 'error'
        })
      }
    }
  })
}

// ================================
// ğŸ”§ Auto Port Selection Logic
// ================================

const DEFAULT_PORT = parseInt(process.env.SYNTHETIC_API_PORT || '3011', 10);
const MAX_PORT = 3100;

/**
 * ì§€ì •ëœ í¬íŠ¸ê°€ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸
 * @param {number} port
 * @returns {Promise<boolean>}
 */
function isPortAvailable(port) {
  return new Promise((resolve) => {
    const tester = net
      .createServer()
      .once('error', () => resolve(false))
      .once('listening', () => {
        tester
          .once('close', () => resolve(true))
          .close();
      })
      .listen(port);
  });
}

// ê¸°ì¡´ startServer í•¨ìˆ˜ ì œê±°ë¨ - ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©

// ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ë°˜í™˜ API (ë¡œì»¬ ì¶œë ¥ ê¸°ë°˜)
app.get('/api/synthetic/files/:partId', async (req, res) => {
  try {
    const { partId } = req.params
    const baseDir = path.join(__dirname, '..', 'output', 'synthetic', partId)
    if (!fs.existsSync(baseDir)) {
      res.set('Cache-Control', 'no-store, no-cache, must-revalidate, proxy-revalidate')
      res.set('Pragma', 'no-cache')
      res.set('Expires', '0')
      res.set('Surrogate-Control', 'no-store')
      return res.json({ success: true, results: [] })
    }
    const allFiles = await fs.promises.readdir(baseDir)
    const imageFiles = allFiles.filter((f) => f.toLowerCase().endsWith('.webp'))

    const results = imageFiles.map((fileName) => ({
      id: `${partId}_${fileName}`,
      partId,
      imageUrl: `/api/synthetic/static/synthetic/${partId}/${fileName}`,
      colorName: 'ì•Œìˆ˜ì—†ìŒ',
      angle: 'ì•Œìˆ˜ì—†ìŒ',
      resolution: '640x640'
    }))

    res.set('Cache-Control', 'no-store, no-cache, must-revalidate, proxy-revalidate')
    res.set('Pragma', 'no-cache')
    res.set('Expires', '0')
    res.set('Surrogate-Control', 'no-store')
    res.json({ success: true, results })
  } catch (error) {
    console.error('íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({ success: false, error: error.message })
  }
})

// ë°ì´í„°ì…‹ ë³€í™˜ API ì—”ë“œí¬ì¸íŠ¸ë“¤
app.post('/api/dataset/convert', async (req, res) => {
  try {
    const { sourcePath, targetPath, format } = req.body
    const jobId = `conversion_${Date.now()}`
    
    console.log(`ğŸ”„ ë°ì´í„°ì…‹ ë³€í™˜ ì‹œì‘: ${jobId}`)
    
    // ë³€í™˜ ì‘ì—… ì‹œì‘
    const conversionProcess = spawn('python', [
      path.join(__dirname, '..', 'scripts', 'prepare_training_dataset.py')
    ], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: {
        ...process.env,
        PYTHONIOENCODING: 'utf-8',
        LANG: 'ko_KR.UTF-8',
        LC_ALL: 'ko_KR.UTF-8',
        PYTHONUTF8: '1'
      }
    })
    
    // ì‘ì—… ì €ì¥
    conversionJobs.set(jobId, {
      process: conversionProcess,
      startTime: new Date(),
      status: 'running'
    })
    
    conversionProgress.set(jobId, {
      progress: 0,
      status: 'ë³€í™˜ ì‹œì‘...',
      logs: []
    })
    
    // í”„ë¡œì„¸ìŠ¤ ì¶œë ¥ ì²˜ë¦¬
    conversionProcess.stdout.on('data', (data) => {
      const message = data.toString('utf8').trim()
      console.log(`[${jobId}] ${message}`)
      
      const progress = conversionProgress.get(jobId)
      progress.logs.push({
        time: new Date().toLocaleTimeString(),
        message,
        type: 'info'
      })
      
      // ì§„í–‰ë¥  ì¶”ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
      if (message.includes('ì „ì²´ ì´ë¯¸ì§€ ìˆ˜')) {
        progress.progress = 10
        progress.status = 'ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...'
      } else if (message.includes('Train:')) {
        progress.progress = 50
        progress.status = 'ë°ì´í„°ì…‹ ë¶„í•  ì¤‘...'
      } else if (message.includes('ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ')) {
        progress.progress = 100
        progress.status = 'ë³€í™˜ ì™„ë£Œ!'
      }
    })
    
    conversionProcess.stderr.on('data', (data) => {
      const message = data.toString('utf8').trim()
      console.error(`[${jobId}] ERROR: ${message}`)
      
      const progress = conversionProgress.get(jobId)
      progress.logs.push({
        time: new Date().toLocaleTimeString(),
        message,
        type: 'error'
      })
    })
    
    conversionProcess.on('close', (code) => {
      const job = conversionJobs.get(jobId)
      if (job) {
        job.status = code === 0 ? 'completed' : 'failed'
        job.endTime = new Date()
      }
      
      const progress = conversionProgress.get(jobId)
      if (code === 0) {
        progress.progress = 100
        progress.status = 'ë³€í™˜ ì™„ë£Œ!'
        progress.logs.push({
          time: new Date().toLocaleTimeString(),
          message: 'ë°ì´í„°ì…‹ ë³€í™˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!',
          type: 'success'
        })
      } else {
        progress.status = 'ë³€í™˜ ì‹¤íŒ¨'
        progress.logs.push({
          time: new Date().toLocaleTimeString(),
          message: `ë³€í™˜ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code})`,
          type: 'error'
        })
      }
    })
    
    res.json({ 
      success: true, 
      jobId,
      message: 'ë°ì´í„°ì…‹ ë³€í™˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.' 
    })
    
  } catch (error) {
    console.error('ë°ì´í„°ì…‹ ë³€í™˜ ì‹œì‘ ì‹¤íŒ¨:', error)
    res.status(500).json({ 
      success: false, 
      error: error.message 
    })
  }
})

app.get('/api/dataset/progress', (req, res) => {
  try {
    const { jobId } = req.query
    
    if (!jobId) {
      return res.status(400).json({ 
        success: false, 
        error: 'jobIdê°€ í•„ìš”í•©ë‹ˆë‹¤.' 
      })
    }
    
    const progress = conversionProgress.get(jobId)
    if (!progress) {
      return res.status(404).json({ 
        success: false, 
        error: 'ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' 
      })
    }
    
    res.json({
      success: true,
      progress: progress.progress,
      status: progress.status,
      logs: progress.logs.slice(-10) // ìµœê·¼ 10ê°œ ë¡œê·¸ë§Œ ë°˜í™˜
    })
    
  } catch (error) {
    console.error('ì§„í–‰ë¥  ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({ 
      success: false, 
      error: error.message 
    })
  }
})

app.get('/api/dataset/source-count', async (req, res) => {
  try {
    const outputDir = path.join(__dirname, '..', 'output', 'synthetic')
    
    if (!fs.existsSync(outputDir)) {
      return res.json({ count: 0 })
    }
    
    // WebP ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜ ê³„ì‚° (ì¬ê·€ì ìœ¼ë¡œ)
    let imageCount = 0
    
    const countWebPFiles = (dir) => {
      try {
        const items = fs.readdirSync(dir)
        for (const item of items) {
          const fullPath = path.join(dir, item)
          const stat = fs.statSync(fullPath)
          
          if (stat.isDirectory()) {
            countWebPFiles(fullPath)
          } else if (item.endsWith('.webp')) {
            imageCount++
          }
        }
      } catch (error) {
        console.warn(`ë””ë ‰í† ë¦¬ ì½ê¸° ì‹¤íŒ¨: ${dir}`, error.message)
      }
    }
    
    countWebPFiles(outputDir)
    
    res.json({ count: imageCount })
    
  } catch (error) {
    console.error('ì†ŒìŠ¤ ì´ë¯¸ì§€ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({ 
      success: false, 
      error: error.message 
    })
  }
})

app.get('/api/dataset/download', async (req, res) => {
  try {
    const datasetPath = path.join(__dirname, '..', 'data', 'brickbox_dataset')
    
    if (!fs.existsSync(datasetPath)) {
      return res.status(404).json({ 
        success: false, 
        error: 'ë°ì´í„°ì…‹ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.' 
      })
    }
    
    // í´ë” êµ¬ì¡° ì •ë³´ ë°˜í™˜ (ZIP ìƒì„± ëŒ€ì‹ )
    try {
      // ë°ì´í„°ì…‹ í´ë” êµ¬ì¡° ì½ê¸°
      const readDirRecursive = (dir, basePath = '') => {
        const items = []
        const entries = fs.readdirSync(dir, { withFileTypes: true })
        
        for (const entry of entries) {
          const fullPath = path.join(dir, entry.name)
          const relativePath = path.join(basePath, entry.name)
          
          if (entry.isDirectory()) {
            items.push({
              name: entry.name,
              type: 'directory',
              path: relativePath,
              children: readDirRecursive(fullPath, relativePath)
            })
          } else {
            const stats = fs.statSync(fullPath)
            items.push({
              name: entry.name,
              type: 'file',
              path: relativePath,
              size: stats.size,
              modified: stats.mtime
            })
          }
        }
        
        return items
      }
      
      const datasetStructure = readDirRecursive(datasetPath)
      
      // í´ë” êµ¬ì¡° ì •ë³´ ë°˜í™˜
      res.json({
        success: true,
        message: 'ë°ì´í„°ì…‹ í´ë” êµ¬ì¡° ì •ë³´',
        datasetPath: datasetPath,
        structure: datasetStructure,
        instructions: [
          '1. ìœ„ ê²½ë¡œì˜ í´ë”ë¥¼ ì§ì ‘ ì••ì¶•í•˜ì„¸ìš”',
          '2. Windows: í´ë” ìš°í´ë¦­ â†’ "ì••ì¶•" ë˜ëŠ” "ZIPìœ¼ë¡œ ì••ì¶•"',
          '3. ìƒì„±ëœ ì••ì¶• íŒŒì¼ì„ YOLO í•™ìŠµì— ì‚¬ìš©í•˜ì„¸ìš”'
        ],
        downloadNote: 'ZIP ìë™ ìƒì„± ê¸°ëŠ¥ì€ í˜„ì¬ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í´ë”ë¥¼ ì§ì ‘ ì••ì¶•í•´ì£¼ì„¸ìš”.'
      })
      
    } catch (error) {
      console.error('í´ë” êµ¬ì¡° ì½ê¸° ì˜¤ë¥˜:', error)
      res.status(500).json({
        success: false,
        error: 'ë°ì´í„°ì…‹ í´ë”ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        message: error.message
      })
    }
    
  } catch (error) {
    console.error('ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨:', error)
    res.status(500).json({ 
      success: false, 
      error: error.message 
    })
  }
})

// í¬íŠ¸ ìë™ í• ë‹¹ í•¨ìˆ˜
const findAvailablePort = async (startPort = 3001, maxPort = 3010) => {
  const net = await import('net')
  
  for (let port = startPort; port <= maxPort; port++) {
    try {
      await new Promise((resolve, reject) => {
        const server = net.createServer()
        
        server.listen(port, () => {
          server.close(() => resolve(port))
        })
        
        server.on('error', (err) => {
          if (err.code === 'EADDRINUSE') {
            reject(new Error(`Port ${port} is in use`))
          } else {
            reject(err)
          }
        })
      })
      
      return port
    } catch (error) {
      if (port === maxPort) {
        throw new Error(`No available ports found between ${startPort} and ${maxPort}`)
      }
      continue
    }
  }
}

// ì„œë²„ ì‹œì‘
const startServer = async () => {
  try {
    // ê²€ì¦ ë¼ìš°í„° ì¶”ê°€
    try {
      const validateRouter = await import('../api/synthetic/validate.js')
      app.use('/api/synthetic/validate', validateRouter.default)
      console.log('âœ… ê²€ì¦ ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ: /api/synthetic/validate')
    } catch (error) {
      console.error('âŒ ê²€ì¦ ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨:', error.message)
      console.log('ğŸ”§ ì§ì ‘ ê²€ì¦ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€...')
    }
    
    // ê³ ì • í¬íŠ¸ 3011 ì‚¬ìš© (ê·¼ë³¸ ë¬¸ì œ í•´ê²°)
    const PORT = 3011;
    console.log(`ğŸ”’ ê³ ì • í¬íŠ¸ ì‚¬ìš©: ${PORT}`);
    
    // í¬íŠ¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if (!(await isPortAvailable(PORT))) {
      console.warn(`âš ï¸ í¬íŠ¸ ${PORT}ì´ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.`);
      
      // í¬íŠ¸ 3011ì„ ì‚¬ìš©í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ ì°¾ê¸° ë° ì¢…ë£Œ
      try {
        const { exec } = require('child_process');
        const { promisify } = require('util');
        const execAsync = promisify(exec);
        
        // Windowsì—ì„œ í¬íŠ¸ 3011ì„ ì‚¬ìš©í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ ì°¾ê¸°
        const { stdout } = await execAsync(`netstat -ano | findstr ":3011"`);
        const lines = stdout.split('\n').filter(line => line.includes('LISTENING'));
        
        for (const line of lines) {
          const parts = line.trim().split(/\s+/);
          if (parts.length >= 5) {
            const pid = parts[4];
            if (pid && pid !== '0') {
              console.log(`ğŸ”ª í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ: PID ${pid}`);
              await execAsync(`taskkill /F /PID ${pid}`);
              await new Promise(resolve => setTimeout(resolve, 1000)); // 1ì´ˆ ëŒ€ê¸°
            }
          }
        }
      } catch (killError) {
        console.warn('ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹¤íŒ¨:', killError.message);
      }
    }
    
    app.listen(PORT, () => {
      console.log(`ğŸš€ Synthetic API ì„œë²„ê°€ í¬íŠ¸ ${PORT}ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.`)
      console.log(`ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸: http://localhost:${PORT}`)
      console.log(`ğŸ–¼ï¸  ì •ì  íŒŒì¼: http://localhost:${PORT}/api/synthetic/static`)
      console.log(`ğŸ“Š ë°ì´í„°ì…‹ ë³€í™˜: http://localhost:${PORT}/api/dataset/convert`)
      
      // í¬íŠ¸ ì •ë³´ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (Vite í”„ë¡ì‹œì—ì„œ ì‚¬ìš©)
      const portInfo = {
        port: PORT,
        timestamp: new Date().toISOString(),
        pid: process.pid
      }
      
      try {
        const portFilePath = path.join(process.cwd(), '.synthetic-api-port.json')
        fs.writeFileSync(portFilePath, JSON.stringify(portInfo, null, 2))
        console.log(`ğŸ“ í¬íŠ¸ ì •ë³´ ì €ì¥: ${portFilePath}`)
      } catch (fileError) {
        console.warn('í¬íŠ¸ ì •ë³´ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨:', fileError.message)
      }
    })
    
  } catch (error) {
    console.error('âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨:', error.message)
    console.error('ìŠ¤íƒ:', error.stack)
    console.error('âš ï¸ í¬íŠ¸ê°€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì´ê±°ë‚˜ í™˜ê²½ ì„¤ì • ì˜¤ë¥˜ì…ë‹ˆë‹¤.')
    console.error('ğŸ’¡ í•´ê²° ë°©ë²•:')
    console.error('   1. npm run cleanup:force')
    console.error('   2. npm run dev:full')
    // ğŸ”§ ìˆ˜ì •ë¨: ì‹œì‘ ì‹¤íŒ¨ ì‹œì—ë§Œ ì¢…ë£Œ (ëŸ°íƒ€ì„ ì—ëŸ¬ëŠ” ì „ì—­ í•¸ë“¤ëŸ¬ê°€ ì²˜ë¦¬)
    setTimeout(() => {
      console.error('âš ï¸ 5ì´ˆ í›„ ì¢…ë£Œí•©ë‹ˆë‹¤...')
      process.exit(1)
    }, 5000)
  }
}

// ë Œë”ë§ ìµœì í™” ì§„ë‹¨ API
app.post('/api/render-optimization/audit', async (req, res) => {
  try {
    const {
      glob = 'output/synthetic/*/*.json',
      baseline_sec = 4.0,
      auto_baseline = true,
      quality_simulation = true,
      group_by = 'shape_tag',
      max_files = 0,
      workers = 8
    } = req.body;

    console.log('ë Œë”ë§ ìµœì í™” ì§„ë‹¨ ìš”ì²­:', { glob, baseline_sec, auto_baseline, quality_simulation, group_by });

    // Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    const scriptPath = path.join(__dirname, '..', 'scripts', 'render_optimize_audit_enhanced.py');
    console.log('Python ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ:', scriptPath);
    console.log('ìŠ¤í¬ë¦½íŠ¸ ì¡´ì¬ ì—¬ë¶€:', fs.existsSync(scriptPath));
    
    const args = [
      '--glob', glob,
      '--baseline-sec', baseline_sec.toString(),
      '--report', 'json'
    ];

    if (auto_baseline) {
      args.push('--auto-baseline');
    }

    if (quality_simulation) {
      args.push('--quality-simulation');
    }

    if (group_by) {
      args.push('--group-by', group_by);
    }

    if (max_files > 0) {
      args.push('--max-files', max_files.toString());
    }

    args.push('--workers', workers.toString());

    console.log('Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:', scriptPath, args);
    console.log('ì‘ì—… ë””ë ‰í† ë¦¬:', process.cwd());

    const pythonProcess = spawn('python', [scriptPath, ...args], {
      cwd: process.cwd(),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: {
        ...process.env,
        PYTHONIOENCODING: 'utf-8',
        PYTHONUTF8: '1'
      }
    });
    
    console.log('Python í”„ë¡œì„¸ìŠ¤ ì‹œì‘ë¨, PID:', pythonProcess.pid);

    let stdout = '';
    let stderr = '';

    pythonProcess.stdout.on('data', (data) => {
      const output = data.toString('utf8');
      stdout += output;
      console.log('Python STDOUT:', output);
    });

    pythonProcess.stderr.on('data', (data) => {
      const output = data.toString('utf8');
      stderr += output;
      console.log('Python STDERR:', output);
    });

    pythonProcess.on('close', (code) => {
      console.log('Python í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ, ì½”ë“œ:', code);
      console.log('ì „ì²´ STDOUT:', stdout);
      console.log('ì „ì²´ STDERR:', stderr);
      
      if (code === 0) {
        try {
          const result = JSON.parse(stdout);
          console.log('ì§„ë‹¨ ì™„ë£Œ:', result.files, 'ê°œ íŒŒì¼ ë¶„ì„');
          res.json({
            success: true,
            data: result,
            timestamp: new Date().toISOString()
          });
        } catch (parseError) {
          console.error('JSON íŒŒì‹± ì˜¤ë¥˜:', parseError);
          console.error('stdout:', stdout);
          res.status(500).json({
            success: false,
            error: 'ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨',
            details: parseError.message,
            stdout: stdout.substring(0, 500)
          });
        }
      } else {
        console.error('Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨:', code);
        console.error('stderr:', stderr);
        res.status(500).json({
          success: false,
          error: 'ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨',
          details: stderr,
          code: code
        });
      }
    });

    pythonProcess.on('error', (error) => {
      console.error('Python í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error);
      res.status(500).json({
        success: false,
        error: 'Python í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹¤íŒ¨',
        details: error.message
      });
    });

  } catch (error) {
    console.error('API ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'ì„œë²„ ì˜¤ë¥˜',
      details: error.message
    });
  }
});

// ë Œë”ë§ ìµœì í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
app.get('/api/render-optimization/history', async (req, res) => {
  try {
    const { limit = 10, offset = 0 } = req.query;
    
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Supabaseì—ì„œ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
    // í˜„ì¬ëŠ” ë¹ˆ ë°°ì—´ ë°˜í™˜
    res.json({
      success: true,
      data: [],
      total: 0,
      message: 'íˆìŠ¤í† ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì§„ë‹¨ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.'
    });

  } catch (error) {
    console.error('íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨',
      details: error.message
    });
  }
});

// ìµœì í™” ê¶Œì¥ì‚¬í•­ ì ìš©
app.post('/api/render-optimization/apply', async (req, res) => {
  try {
    const { 
      scenario, 
      target_samples, 
      gpu_enabled, 
      cache_enabled,
      parallel_workers 
    } = req.body;

    console.log('ìµœì í™” ì ìš© ìš”ì²­:', { scenario, target_samples, gpu_enabled, cache_enabled, parallel_workers });

    const result = {
      success: true,
      applied_changes: {
        samples: target_samples,
        gpu_enabled: gpu_enabled,
        cache_enabled: cache_enabled,
        parallel_workers: parallel_workers
      },
      estimated_improvement: {
        speedup: scenario === 'once_render_low' ? 3.44 : 1.50,
        quality_impact: 'low'
      },
      timestamp: new Date().toISOString()
    };

    res.json(result);

  } catch (error) {
    console.error('ìµœì í™” ì ìš© ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'ìµœì í™” ì ìš© ì‹¤íŒ¨',
      details: error.message
    });
  }
});

// ì‹¤ì‹œê°„ ë Œë”ë§ ìƒíƒœ ëª¨ë‹ˆí„°ë§
app.get('/api/render-optimization/status', async (req, res) => {
  try {
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í˜„ì¬ ë Œë”ë§ ì‘ì—… ìƒíƒœ ì¡°íšŒ
    const status = {
      active_jobs: 0,
      completed_today: 0,
      average_time: 0,
      gpu_utilization: 0,
      memory_usage: 0,
      last_optimization: null
    };

    res.json({
      success: true,
      data: status,
      timestamp: new Date().toISOString(),
      message: 'ë Œë”ë§ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤.'
    });

  } catch (error) {
    console.error('ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨',
      details: error.message
    });
  }
});

// ë Œë”ë§ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¡°íšŒ
app.get('/api/render-optimization/metrics', async (req, res) => {
  try {
    const { period = '24h' } = req.query;
    
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹œê³„ì—´ ë°ì´í„° ì¡°íšŒ
    const metrics = {
      ssim_trend: [],
      snr_trend: [],
      render_time_trend: []
    };

    res.json({
      success: true,
      data: metrics,
      period: period,
      message: 'ë©”íŠ¸ë¦­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì§„ë‹¨ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.'
    });

  } catch (error) {
    console.error('ë©”íŠ¸ë¦­ ì¡°íšŒ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: 'ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨',
      details: error.message
    });
  }
});

// ë²„í‚· ë™ê¸°í™” ê²€ì¦ í•¨ìˆ˜
async function validateBucketSync(sourcePath, bucketName) {
  const result = {
    totalFiles: 0,
    uploadedFiles: 0,
    missingFiles: 0,
    syncErrors: [],
    bucketStats: {
      totalObjects: 0,
      totalSize: 0
    }
  }
  
  try {
    console.log(`ğŸ” ë²„í‚· ë™ê¸°í™” ê²€ì¦: ${bucketName}`)
    
    if (!supabaseUrl || !supabaseKey) {
      result.syncErrors.push('Supabase ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤')
      return result
    }
    
    // ë¡œì»¬ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
    const localFiles = []
    const items = await fs.promises.readdir(sourcePath)
    
    for (const item of items) {
      const itemPath = path.join(sourcePath, item)
      const stats = await fs.promises.stat(itemPath)
      
      if (stats.isDirectory() && !['dataset_synthetic', 'logs', 'temp', 'cache'].includes(item)) {
        const partItems = await fs.promises.readdir(itemPath)
        for (const file of partItems) {
          if (/\.(jpg|jpeg|png|bmp|tiff|webp|txt|json)$/i.test(file)) {
            localFiles.push({
              path: path.join(item, file),
              fullPath: path.join(itemPath, file),
              size: (await fs.promises.stat(path.join(itemPath, file))).size
            })
          }
        }
      }
    }
    
    result.totalFiles = localFiles.length
    console.log(`ğŸ“ ë¡œì»¬ íŒŒì¼: ${result.totalFiles}ê°œ`)
    
    // ë²„í‚·ì—ì„œ íŒŒì¼ ëª©ë¡ ì¡°íšŒ (ê° ë¶€í’ˆ í´ë”ë³„ë¡œ)
    try {
      const bucketFileMap = new Map()
      let totalBucketFiles = 0
      
      // ê° ë¶€í’ˆ í´ë” ì¡°íšŒ
      for (const item of items) {
        const itemPath = path.join(sourcePath, item)
        const stats = await fs.promises.stat(itemPath)
        
        if (stats.isDirectory() && !['dataset_synthetic', 'logs', 'temp', 'cache'].includes(item)) {
          console.log(`ğŸ” ë²„í‚· í´ë” ì¡°íšŒ: synthetic/${item}`)
          
          const { data: partFiles, error } = await supabase.storage
            .from(bucketName)
            .list(`synthetic/${item}`, { limit: 1000 })
          
          if (error) {
            console.error(`âŒ í´ë” ì¡°íšŒ ì‹¤íŒ¨ synthetic/${item}:`, error.message)
            continue
          }
          
          partFiles.forEach(file => {
            bucketFileMap.set(file.name, file)
            result.bucketStats.totalSize += file.metadata?.size || 0
            totalBucketFiles++
          })
        }
      }
      
      result.bucketStats.totalObjects = totalBucketFiles
      console.log(`â˜ï¸ ë²„í‚· íŒŒì¼: ${result.bucketStats.totalObjects}ê°œ`)

      // ===== UUID ê¸°ë°˜ ì •í™• ë§¤ì¹­: íŒŒíŠ¸ í´ë”/íŒŒì¼íƒ€ì…(E2)/í™•ì¥ì/ì‚¬ì´ì¦ˆ ë©€í‹°ì…‹ìœ¼ë¡œ ë§¤ì¹­ =====
      // 1) íŒŒíŠ¸ í´ë”ë³„ ë²„í‚· íŒŒì¼ í’€(ë©€í‹°ì…‹) êµ¬ì„±
      const bucketPoolsByPart = new Map() // partId -> { key -> Map<size, count> }

      // helper: íŒŒì¼ í‚¤ ìƒì„± (í™•ì¥ì + e2 êµ¬ë¶„)
      const getFileKey = (name) => {
        const ext = path.extname(name).toLowerCase()
        const isE2 = name.includes('_e2.json')
        return `${ext}|${isE2 ? 'e2' : 'std'}`
      }

      for (const item of items) {
        const itemPath = path.join(sourcePath, item)
        const stats = await fs.promises.stat(itemPath)
        if (!(stats.isDirectory()) || ['dataset_synthetic', 'logs', 'temp', 'cache'].includes(item)) continue

        const { data: partFiles, error } = await supabase.storage
          .from(bucketName)
          .list(`synthetic/${item}`, { limit: 1000 })

        if (error) {
          console.error(`âŒ í´ë” ì¡°íšŒ ì‹¤íŒ¨ synthetic/${item}:`, error.message)
          continue
        }

        const pool = new Map() // key -> Map<size, count>
        partFiles.forEach(file => {
          const key = getFileKey(file.name)
          const size = (file.metadata && typeof file.metadata.size === 'number') ? file.metadata.size : undefined
          if (!pool.has(key)) pool.set(key, new Map())
          const sizeMap = pool.get(key)
          const bucketCount = size ? ((sizeMap.get(size) || 0) + 1) : ((sizeMap.get('unknown') || 0) + 1)
          sizeMap.set(size || 'unknown', bucketCount)
        })

        bucketPoolsByPart.set(item, pool)
      }

      // 2) ë¡œì»¬ íŒŒì¼ê³¼ ë²„í‚· í’€ë¡œ 1:1 ë§¤ì¹­ (ì‚¬ì´ì¦ˆë¡œ ì†Œëª¨ ë§¤ì¹­)
      let matched = 0
      for (const localFile of localFiles) {
        const partId = path.dirname(localFile.path).split(path.sep)[0]
        const fileName = path.basename(localFile.path)
        const key = getFileKey(fileName)
        const size = localFile.size || 'unknown'

        const pool = bucketPoolsByPart.get(partId)
        if (!pool) {
          result.missingFiles++
          result.syncErrors.push(`ëˆ„ë½ëœ íŒŒì¼: ${localFile.path}`)
          continue
        }

        const sizeMap = pool.get(key)
        if (!sizeMap) {
          result.missingFiles++
          result.syncErrors.push(`ëˆ„ë½ëœ íŒŒì¼: ${localFile.path}`)
          continue
        }

        let matchedThis = false
        
        // 1. ì •í™• ì‚¬ì´ì¦ˆ ë§¤ì¹­
        if (sizeMap.has(size) && sizeMap.get(size) > 0) {
          sizeMap.set(size, sizeMap.get(size) - 1)
          matched++
          matchedThis = true
        } 
        // 2. ë©”íƒ€ë°ì´í„° ì—†ëŠ” íŒŒì¼ ë§¤ì¹­
        else if (sizeMap.has('unknown') && sizeMap.get('unknown') > 0) {
          sizeMap.set('unknown', sizeMap.get('unknown') - 1)
          matched++
          matchedThis = true
        }
        // 3. ìœ ì—°í•œ ë§¤ì¹­: ê°™ì€ íƒ€ì…ì˜ ë‹¤ë¥¸ í¬ê¸° íŒŒì¼ë„ í—ˆìš©
        else {
          // ê°™ì€ í‚¤(í™•ì¥ì+E2)ì˜ ë‹¤ë¥¸ í¬ê¸° íŒŒì¼ ì°¾ê¸°
          for (const [bucketSize, count] of sizeMap) {
            if (count > 0) {
              sizeMap.set(bucketSize, count - 1)
              matched++
              matchedThis = true
              break
            }
          }
        }

        if (!matchedThis) {
          result.missingFiles++
          result.syncErrors.push(`ëˆ„ë½ëœ íŒŒì¼: ${localFile.path}`)
        }
      }

      result.uploadedFiles = matched
      console.log(`âœ… ë²„í‚· ë™ê¸°í™” ë§¤ì¹­ ì™„ë£Œ: ì—…ë¡œë“œë¨ ${result.uploadedFiles}ê°œ / ì´ ${result.totalFiles}ê°œ`)
      
    } catch (error) {
      result.syncErrors.push(`ë²„í‚· ì ‘ê·¼ ì‹¤íŒ¨: ${error.message}`)
    }
    
  } catch (error) {
    result.syncErrors.push(`ë™ê¸°í™” ê²€ì¦ ì‹¤íŒ¨: ${error.message}`)
  }
  
  return result
}

// íŒŒì¼ ê°œìˆ˜ ê³„ì‚° í•¨ìˆ˜
async function countFiles(directoryPath) {
  try {
    const files = await fs.promises.readdir(directoryPath)
    return files.filter(file => !file.startsWith('.')).length
  } catch (error) {
    console.error(`íŒŒì¼ ê°œìˆ˜ ê³„ì‚° ì‹¤íŒ¨ (${directoryPath}):`, error)
    return 0
  }
}

// ë°ì´í„°ì…‹ ì¤€ë¹„ API ì—”ë“œí¬ì¸íŠ¸
app.post('/api/synthetic/dataset/prepare', async (req, res) => {
  try {
    console.log('ğŸ“‹ ë°ì´í„°ì…‹ ì¤€ë¹„ ìš”ì²­ ë°›ìŒ:', req.body)
    
    const { sourcePath = 'output/synthetic', forceRebuild = false } = req.body
    const fullPath = path.isAbsolute(sourcePath) ? sourcePath : path.join(process.cwd(), sourcePath)
    
    console.log(`ğŸ“ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹œì‘: ${fullPath}`)
    console.log(`ğŸ”„ ëª¨ë“œ: ${forceRebuild ? 'ê°•ì œ ì¬ìƒì„±' : 'ì¦ë¶„ ì—…ë°ì´íŠ¸'}`)
    
    // ë°ì´í„°ì…‹ ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    const scriptArgs = [
      '--source', fullPath,
      '--output', path.join(fullPath, 'dataset_synthetic')
    ]
    
    if (forceRebuild) {
      scriptArgs.push('--force-rebuild')
    }
    
    const prepareProcess = spawn('python', [
      path.join(__dirname, '..', 'scripts', 'prepare_training_dataset.py'),
      ...scriptArgs
    ], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: {
        ...process.env,
        PYTHONIOENCODING: 'utf-8',
        LANG: 'ko_KR.UTF-8',
        LC_ALL: 'ko_KR.UTF-8',
        PYTHONUTF8: '1'
      }
    })
    
    const jobId = `prepare_${Date.now()}`
    const logs = []
    
    // í”„ë¡œì„¸ìŠ¤ ì¶œë ¥ ì²˜ë¦¬
    prepareProcess.stdout.on('data', (data) => {
      const message = data.toString('utf8').trim()
      if (message) {
        console.log(`[ë°ì´í„°ì…‹ ì¤€ë¹„] ${message}`)
        logs.push({
          timestamp: new Date().toLocaleTimeString(),
          message: message
        })
      }
    })
    
    prepareProcess.stderr.on('data', (data) => {
      const message = data.toString('utf8').trim()
      if (message) {
        console.error(`[ë°ì´í„°ì…‹ ì¤€ë¹„ ì˜¤ë¥˜] ${message}`)
        logs.push({
          timestamp: new Date().toLocaleTimeString(),
          message: `ì˜¤ë¥˜: ${message}`,
          type: 'error'
        })
      }
    })
    
    prepareProcess.on('close', async (code) => {
      console.log(`ğŸ“‹ ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ (ì¢…ë£Œ ì½”ë“œ: ${code})`)
      
      if (code === 0) {
        logs.push({
          timestamp: new Date().toLocaleTimeString(),
          message: 'âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!',
          type: 'success'
        })
        
        // ì‹¤ì œ íŒŒì¼ ê°œìˆ˜ ê³„ì‚°
        try {
          const datasetPath = path.join(fullPath, 'dataset_synthetic')
          const imageCount = await countFiles(path.join(datasetPath, 'images', 'train')) + 
                           await countFiles(path.join(datasetPath, 'images', 'val'))
          const labelCount = await countFiles(path.join(datasetPath, 'labels', 'train')) + 
                           await countFiles(path.join(datasetPath, 'labels', 'val'))
          const metadataCount = await countFiles(path.join(datasetPath, 'metadata'))
          
          logs.push({
            timestamp: new Date().toLocaleTimeString(),
            message: `ğŸ“Š ì¤€ë¹„ëœ íŒŒì¼: ì´ë¯¸ì§€ ${imageCount}ê°œ, ë¼ë²¨ ${labelCount}ê°œ, ë©”íƒ€ë°ì´í„° ${metadataCount}ê°œ`,
            type: 'info'
          })
        } catch (error) {
          console.error('íŒŒì¼ ê°œìˆ˜ ê³„ì‚° ì‹¤íŒ¨:', error)
        }
      } else {
        logs.push({
          timestamp: new Date().toLocaleTimeString(),
          message: `âŒ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code})`,
          type: 'error'
        })
      }
    })
    
    // ì¦‰ì‹œ ì‘ë‹µ (ë¹„ë™ê¸° ì²˜ë¦¬)
    res.json({
      success: true,
      jobId: jobId,
      message: 'ë°ì´í„°ì…‹ ì¤€ë¹„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤',
      logs: logs
    })
    
  } catch (error) {
    console.error('âŒ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ë°ì´í„°ì…‹ ì¤€ë¹„ ì§„í–‰ ìƒí™© ì¡°íšŒ
app.get('/api/synthetic/dataset/prepare/status/:jobId', (req, res) => {
  const { jobId } = req.params
  
  res.set('Cache-Control', 'no-store, no-cache, must-revalidate, proxy-revalidate')
  res.set('Pragma', 'no-cache')
  res.set('Expires', '0')
  res.set('Surrogate-Control', 'no-store')
  
  res.json({
    success: true,
    jobId: jobId,
    status: 'completed',
    progress: 100,
    message: 'ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ'
  })
})

// ë°ì´í„°ì…‹ íŒŒì¼ ê°œìˆ˜ ì¡°íšŒ
app.get('/api/synthetic/dataset/files', async (req, res) => {
  try {
    const datasetPath = path.join(process.cwd(), 'output', 'dataset_synthetic')
    
    const imageCount = await countFiles(path.join(datasetPath, 'images', 'train')) + 
                      await countFiles(path.join(datasetPath, 'images', 'val'))
    const labelCount = await countFiles(path.join(datasetPath, 'labels', 'train')) + 
                      await countFiles(path.join(datasetPath, 'labels', 'val'))
    const metadataCount = await countFiles(path.join(datasetPath, 'metadata'))
    
    res.json({
      success: true,
      images: imageCount,
      labels: labelCount,
      metadata: metadataCount,
      total: imageCount + labelCount + metadataCount
    })
  } catch (error) {
    console.error('íŒŒì¼ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ë°ì´í„°ì…‹ ë²„ì „ ëª©ë¡ ì¡°íšŒ
app.get('/api/synthetic/dataset/versions', async (req, res) => {
  try {
    console.log('ğŸ“‹ ë²„ì „ ëª©ë¡ ì¡°íšŒ ìš”ì²­')
    
    // Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    const listProcess = spawn('python', [
      path.join(__dirname, '..', 'scripts', 'dataset_version_manager.py'),
      '--action', 'list'
    ], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: {
        ...process.env,
        PYTHONIOENCODING: 'utf-8',
        LANG: 'ko_KR.UTF-8',
        LC_ALL: 'ko_KR.UTF-8',
        PYTHONUTF8: '1'
      }
    })
    
    let output = ''
    let errorOutput = ''
    
    listProcess.stdout.on('data', (data) => {
      output += data.toString('utf8')
    })
    
    listProcess.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8')
    })
    
    listProcess.on('close', (code) => {
      console.log('ë²„ì „ ëª©ë¡ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì½”ë“œ:', code)
      console.log('ì¶œë ¥:', output)
      console.log('ì˜¤ë¥˜:', errorOutput)
      
      if (code === 0) {
        // Python ìŠ¤í¬ë¦½íŠ¸ì—ì„œ JSON ì¶œë ¥ì„ íŒŒì‹±
        try {
          const lines = output.split('\n')
          // JSON ë°°ì—´ ì‹œì‘ ë¶€ë¶„ ì°¾ê¸°
          const jsonStartIndex = lines.findIndex(line => line.trim().startsWith('['))
          if (jsonStartIndex !== -1) {
            // JSON ë°°ì—´ ë¶€ë¶„ë§Œ ì¶”ì¶œ
            const jsonLines = lines.slice(jsonStartIndex)
            const jsonText = jsonLines.join('\n')
            const versions = JSON.parse(jsonText)
            console.log(`âœ… ë²„ì „ ëª©ë¡ ì¡°íšŒ ì„±ê³µ: ${versions.length}ê°œ ë²„ì „`)
            res.json({
              success: true,
              versions: versions
            })
          } else {
            // JSON ì¶œë ¥ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ
            console.log('âš ï¸ JSON ë°°ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ë¹ˆ ë°°ì—´ ë°˜í™˜')
            res.json({
              success: true,
              versions: []
            })
          }
        } catch (parseError) {
          console.error('âŒ JSON íŒŒì‹± ì‹¤íŒ¨:', parseError)
          console.error('ì¶œë ¥ ë‚´ìš©:', output)
          res.json({
            success: true,
            versions: []
          })
        }
      } else {
        console.error('âŒ Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨:', errorOutput)
        console.error('ì¶œë ¥ ë‚´ìš©:', output)
        res.status(500).json({
          success: false,
          error: `ë²„ì „ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: ${errorOutput}`,
          output: output
        })
      }
    })
    
    listProcess.on('error', (error) => {
      console.error('âŒ ë²„ì „ ëª©ë¡ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error)
      res.status(500).json({
        success: false,
        error: `ë²„ì „ ëª©ë¡ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: ${error.message}`
      })
    })
    
  } catch (error) {
    console.error('ë²„ì „ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ë°ì´í„°ì…‹ ë°±ì—… (Node.js ì§ì ‘ êµ¬í˜„)
app.post('/api/synthetic/dataset/backup', async (req, res) => {
  try {
    const { description = 'í†µí•© ì²˜ë¦¬ ë°±ì—…' } = req.body
    console.log('ğŸ’¾ ë°±ì—… ìš”ì²­:', description)
    
    const currentPath = path.join(__dirname, '..', 'output', 'synthetic')
    const versionsDir = path.join(__dirname, '..', 'output', 'datasets')
    const versionMetadataPath = path.join(__dirname, '..', 'output', 'dataset_versions.json')
    
    console.log('ğŸ“ ê²½ë¡œ í™•ì¸:')
    console.log('  currentPath:', currentPath)
    console.log('  versionsDir:', versionsDir)
    console.log('  versionMetadataPath:', versionMetadataPath)
    
    // current í´ë” í™•ì¸
    if (!fs.existsSync(currentPath)) {
      console.error('âŒ current í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤')
      return res.status(400).json({
        success: false,
        error: 'current í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•˜ì„¸ìš”.'
      })
    }
    
    // ë²„ì „ ë©”íƒ€ë°ì´í„° ë¡œë“œ
    let metadata = { versions: [] }
    if (fs.existsSync(versionMetadataPath)) {
      const content = await fs.promises.readFile(versionMetadataPath, 'utf8')
      metadata = JSON.parse(content)
    }
    
    // ìƒˆ ë²„ì „ ë²ˆí˜¸ ìƒì„±
    let newVersion = '1.0'
    if (metadata.versions && metadata.versions.length > 0) {
      const versions = metadata.versions.map(v => parseFloat(v.version))
      const maxVersion = Math.max(...versions)
      newVersion = (maxVersion + 0.1).toFixed(1)
    }
    
    console.log(`ğŸ“Š ë²„ì „ ì •ë³´:`)
    console.log(`  ê¸°ì¡´ ë²„ì „ ìˆ˜: ${metadata.versions ? metadata.versions.length : 0}`)
    console.log(`  ìƒˆ ë²„ì „: ${newVersion}`)
    
    const newVersionPath = path.join(versionsDir, `v${newVersion}`)
    
    console.log(`ğŸ“¦ ë°±ì—… ì‹œì‘: v${newVersion}`)
    
    // ê¸°ì¡´ ë²„ì „ í´ë”ê°€ ìˆìœ¼ë©´ ì‚­ì œ
    if (fs.existsSync(newVersionPath)) {
      await fs.promises.rm(newVersionPath, { recursive: true, force: true })
    }
    
    // current í´ë” ë³µì‚¬
    try {
      await fs.promises.cp(currentPath, newVersionPath, { recursive: true })
      console.log(`âœ… íŒŒì¼ ë³µì‚¬ ì™„ë£Œ: ${newVersionPath}`)
    } catch (copyError) {
      console.error('âŒ íŒŒì¼ ë³µì‚¬ ì‹¤íŒ¨:', copyError)
      return res.status(500).json({
        success: false,
        error: `íŒŒì¼ ë³µì‚¬ ì‹¤íŒ¨: ${copyError.message}`
      })
    }
    
    // íŒŒì¼ ê°œìˆ˜ ê³„ì‚° ë° í•´ì‹œ ê³„ì‚°
    const countFiles = async (dir, ext) => {
      try {
        if (!fs.existsSync(dir)) {
          return 0
        }
        const files = await fs.promises.readdir(dir, { recursive: true })
        return files.filter(f => f.endsWith(ext)).length
      } catch (error) {
        console.log(`âš ï¸ íŒŒì¼ ê°œìˆ˜ ê³„ì‚° ì‹¤íŒ¨ (${dir}):`, error.message)
        return 0
      }
    }

    
    // ë°ì´í„°ì…‹ í•´ì‹œ ê³„ì‚°
    const calculateDatasetHash = async (datasetPath) => {
      try {
        const crypto = await import('crypto')
        const allHashes = []
        
        const scanDirectory = async (dir) => {
          const items = await fs.promises.readdir(dir, { withFileTypes: true })
          for (const item of items) {
            const fullPath = path.join(dir, item.name)
            if (item.isDirectory()) {
              await scanDirectory(fullPath)
            } else if (item.isFile()) {
              const content = await fs.promises.readFile(fullPath)
              const hash = crypto.createHash('md5').update(content).digest('hex')
              allHashes.push(hash)
            }
          }
        }
        
        await scanDirectory(datasetPath)
        allHashes.sort() // ì¼ê´€ì„± ë³´ì¥
        
        const combinedHash = allHashes.join('')
        return crypto.createHash('sha256').update(combinedHash).digest('hex')
      } catch (error) {
        console.log(`âš ï¸ í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨:`, error.message)
        return ''
      }
    }
    
    const imageCount = await countFiles(path.join(newVersionPath, 'images'), '.webp')
    const labelCount = await countFiles(path.join(newVersionPath, 'labels'), '.txt')
    const metadataCount = await countFiles(path.join(newVersionPath, 'meta'), '.json')
    const metaECount = await countFiles(path.join(newVersionPath, 'meta-e'), '_e2.json')
    const datasetHash = await calculateDatasetHash(newVersionPath)
    
    // ë²„ì „ ì •ë³´ ì €ì¥
    const versionInfo = {
      version: newVersion,
      description: description,
      created_at: new Date().toISOString(),
      is_current: true,
      path: newVersionPath,
      source_path: currentPath,
      dataset_hash: datasetHash,
      file_counts: {
        images: imageCount,
        labels: labelCount,
        metadata: metadataCount,
        meta_e: metaECount,
        total: imageCount + labelCount + metadataCount + metaECount
      }
    }
    
    // ê¸°ì¡´ ë²„ì „ì˜ is_currentë¥¼ falseë¡œ ì„¤ì •
    if (metadata.versions) {
      metadata.versions.forEach(v => {
        v.is_current = false
      })
      metadata.versions.push(versionInfo)
    } else {
      metadata.versions = [versionInfo]
    }
    
    // ë©”íƒ€ë°ì´í„° ì €ì¥
    try {
      await fs.promises.writeFile(
        versionMetadataPath,
        JSON.stringify(metadata, null, 2),
        'utf8'
      )
      console.log(`âœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: ${versionMetadataPath}`)
    } catch (saveError) {
      console.error('âŒ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨:', saveError)
      return res.status(500).json({
        success: false,
        error: `ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: ${saveError.message}`
      })
    }
    
    console.log(`âœ… ë°±ì—… ì™„ë£Œ - ë²„ì „ ${newVersion}`)
    res.json({
      success: true,
      version: newVersion,
      message: `ë°±ì—… ì™„ë£Œ - ë²„ì „ ${newVersion}`,
      file_counts: versionInfo.file_counts
    })
    
  } catch (error) {
    console.error('âŒ ë°±ì—… ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ë°ì´í„°ì…‹ ë²„ì „ ì „í™˜
app.post('/api/synthetic/dataset/switch', async (req, res) => {
  try {
    const { version } = req.body
    console.log('ğŸ”„ ë²„ì „ ì „í™˜ ìš”ì²­:', version)
    
    // Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    const switchProcess = spawn('python', [
      path.join(__dirname, '..', 'scripts', 'dataset_version_manager.py'),
      '--action', 'switch',
      '--version', version
    ], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: {
        ...process.env,
        PYTHONIOENCODING: 'utf-8',
        LANG: 'ko_KR.UTF-8',
        LC_ALL: 'ko_KR.UTF-8',
        PYTHONUTF8: '1'
      }
    })
    
    let output = ''
    let errorOutput = ''
    
    switchProcess.stdout.on('data', (data) => {
      output += data.toString('utf8')
    })
    
    switchProcess.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8')
    })
    
    switchProcess.on('close', (code) => {
      if (code === 0) {
        console.log(`âœ… ë²„ì „ ${version} ì „í™˜ ì„±ê³µ`)
        res.json({
          success: true,
          version: version,
          message: `ë²„ì „ ${version}ìœ¼ë¡œ ì „í™˜ ì™„ë£Œ`
        })
      } else {
        console.error('âŒ ë²„ì „ ì „í™˜ ì‹¤íŒ¨:', errorOutput)
        console.error('ì¶œë ¥ ë‚´ìš©:', output)
        res.status(500).json({
          success: false,
          error: `ë²„ì „ ì „í™˜ ì‹¤íŒ¨: ${errorOutput}`
        })
      }
    })
  } catch (error) {
    console.error('ë²„ì „ ì „í™˜ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// Supabase ë™ê¸°í™” ì—”ë“œí¬ì¸íŠ¸
app.post('/api/synthetic/dataset/sync-to-supabase', async (req, res) => {
  try {
    console.log('ğŸ”„ Supabase ë™ê¸°í™” ìš”ì²­')
    
    const syncProcess = spawn('python', [
      path.join(__dirname, '..', 'scripts', 'sync_dataset_versions_to_supabase.py')
    ], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: {
        ...process.env,
        PYTHONIOENCODING: 'utf-8',
        LANG: 'ko_KR.UTF-8',
        LC_ALL: 'ko_KR.UTF-8',
        PYTHONUTF8: '1',
        // Supabase í™˜ê²½ ë³€ìˆ˜ (ì‹œìŠ¤í…œ í™˜ê²½ ë³€ìˆ˜ ìš°ì„ )
        SUPABASE_URL: process.env.SUPABASE_URL || 'https://npferbxuxocbfnfbpcnz.supabase.co',
        SUPABASE_ANON_KEY: process.env.SUPABASE_ANON_KEY || 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTk0NzQ5ODUsImV4cCI6MjA3NTA1MDk4NX0.eqKQh_o1k2VmP-_v__gUMHVOgvdIzml-zDhZyzfxUmk',
        SUPABASE_SERVICE_ROLE: process.env.SUPABASE_SERVICE_ROLE || 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1OTQ3NDk4NSwiZXhwIjoyMDc1MDUwOTg1fQ.placeholder-service-role-key',
        VITE_SUPABASE_URL: process.env.VITE_SUPABASE_URL || 'https://npferbxuxocbfnfbpcnz.supabase.co',
        VITE_SUPABASE_ANON_KEY: process.env.VITE_SUPABASE_ANON_KEY || 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTk0NzQ5ODUsImV4cCI6MjA3NTA1MDk4NX0.eqKQh_o1k2VmP-_v__gUMHVOgvdIzml-zDhZyzfxUmk',
        VITE_SUPABASE_SERVICE_ROLE: process.env.VITE_SUPABASE_SERVICE_ROLE || 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1OTQ3NDk4NSwiZXhwIjoyMDc1MDUwOTg1fQ.placeholder-service-role-key'
      }
    })
    
    let output = ''
    let errorOutput = ''
    
    syncProcess.stdout.on('data', (data) => {
      output += data.toString('utf8')
    })
    
    syncProcess.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8')
    })
    
    syncProcess.on('close', (code) => {
      if (code === 0) {
        console.log('âœ… Supabase ë™ê¸°í™” ì„±ê³µ')
        res.json({
          success: true,
          message: 'Supabase ë™ê¸°í™” ì™„ë£Œ',
          output: output
        })
      } else {
        console.error('âŒ Supabase ë™ê¸°í™” ì‹¤íŒ¨:', errorOutput)
        res.status(500).json({
          success: false,
          error: `ë™ê¸°í™” ì‹¤íŒ¨: ${errorOutput}`,
          output: output
        })
      }
    })
    
  } catch (error) {
    console.error('Supabase ë™ê¸°í™” ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// Supabase ë²„ì „ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸
app.get('/api/synthetic/dataset/supabase-versions', async (req, res) => {
  try {
    console.log('ğŸ“‹ Supabase ë²„ì „ ì¡°íšŒ ìš”ì²­')
    
    const { createClient } = await import('@supabase/supabase-js')
    
    const supabaseUrl = process.env.SUPABASE_URL
    const supabaseKey = process.env.SUPABASE_ANON_KEY
    
    if (!supabaseUrl || !supabaseKey) {
      return res.status(500).json({
        success: false,
        error: 'Supabase ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤'
      })
    }
    
    const supabase = createClient(supabaseUrl, supabaseKey)
    
    const { data, error } = await supabase
      .from('dataset_versions')
      .select('*')
      .order('created_at', { ascending: false })
    
    if (error) {
      console.error('Supabase ì¡°íšŒ ì˜¤ë¥˜:', error)
      return res.status(500).json({
        success: false,
        error: error.message
      })
    }
    
    res.json({
      success: true,
      versions: data || []
    })
    
  } catch (error) {
    console.error('Supabase ë²„ì „ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ë°ì´í„°ì…‹ íŒŒì¼ Storage ë™ê¸°í™” ì—”ë“œí¬ì¸íŠ¸
app.post('/api/synthetic/dataset/sync-files-to-storage', async (req, res) => {
  try {
    console.log('ğŸ“ ë°ì´í„°ì…‹ íŒŒì¼ Storage ë™ê¸°í™” ìš”ì²­')
    
    const syncProcess = spawn('python', [
      path.join(__dirname, '..', 'scripts', 'sync_dataset_files_to_storage.py')
    ], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: {
        ...process.env,
        PYTHONIOENCODING: 'utf-8',
        LANG: 'ko_KR.UTF-8',
        LC_ALL: 'ko_KR.UTF-8',
        PYTHONUTF8: '1'
      }
    })
    
    let output = ''
    let errorOutput = ''
    
    syncProcess.stdout.on('data', (data) => {
      output += data.toString('utf8')
    })
    
    syncProcess.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8')
    })
    
    syncProcess.on('close', (code) => {
      if (code === 0) {
        console.log('âœ… ë°ì´í„°ì…‹ íŒŒì¼ Storage ë™ê¸°í™” ì„±ê³µ')
        res.json({
          success: true,
          message: 'ë°ì´í„°ì…‹ íŒŒì¼ Storage ë™ê¸°í™” ì™„ë£Œ',
          output: output
        })
      } else {
        console.error('âŒ ë°ì´í„°ì…‹ íŒŒì¼ Storage ë™ê¸°í™” ì‹¤íŒ¨:', errorOutput)
        res.status(500).json({
          success: false,
          error: `Storage ë™ê¸°í™” ì‹¤íŒ¨: ${errorOutput}`,
          output: output
        })
      }
    })
    
  } catch (error) {
    console.error('ë°ì´í„°ì…‹ íŒŒì¼ Storage ë™ê¸°í™” ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ìµœì í™”ëœ ë°ì´í„°ì…‹ Storage ë™ê¸°í™” ì—”ë“œí¬ì¸íŠ¸
app.post('/api/synthetic/dataset/sync-optimized-storage', async (req, res) => {
  try {
    console.log('ğŸ“ ìµœì í™”ëœ ë°ì´í„°ì…‹ Storage ë™ê¸°í™” ìš”ì²­')
    
    const syncProcess = spawn('python', [
      path.join(__dirname, '..', 'scripts', 'optimized_storage_sync.py')
    ], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: {
        ...process.env,
        PYTHONIOENCODING: 'utf-8',
        LANG: 'ko_KR.UTF-8',
        LC_ALL: 'ko_KR.UTF-8',
        PYTHONUTF8: '1',
        // Supabase í™˜ê²½ ë³€ìˆ˜ (ì‹œìŠ¤í…œ í™˜ê²½ ë³€ìˆ˜ ìš°ì„ )
        SUPABASE_URL: process.env.SUPABASE_URL || 'https://npferbxuxocbfnfbpcnz.supabase.co',
        SUPABASE_ANON_KEY: process.env.SUPABASE_ANON_KEY || 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTk0NzQ5ODUsImV4cCI6MjA3NTA1MDk4NX0.eqKQh_o1k2VmP-_v__gUMHVOgvdIzml-zDhZyzfxUmk',
        SUPABASE_SERVICE_ROLE: process.env.SUPABASE_SERVICE_ROLE || 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1OTQ3NDk4NSwiZXhwIjoyMDc1MDUwOTg1fQ.placeholder-service-role-key',
        VITE_SUPABASE_URL: process.env.VITE_SUPABASE_URL || 'https://npferbxuxocbfnfbpcnz.supabase.co',
        VITE_SUPABASE_ANON_KEY: process.env.VITE_SUPABASE_ANON_KEY || 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTk0NzQ5ODUsImV4cCI6MjA3NTA1MDk4NX0.eqKQh_o1k2VmP-_v__gUMHVOgvdIzml-zDhZyzfxUmk',
        VITE_SUPABASE_SERVICE_ROLE: process.env.VITE_SUPABASE_SERVICE_ROLE || 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1OTQ3NDk4NSwiZXhwIjoyMDc1MDUwOTg1fQ.placeholder-service-role-key'
      }
    })
    
    let output = ''
    let errorOutput = ''
    
    syncProcess.stdout.on('data', (data) => {
      output += data.toString('utf8')
    })
    
    syncProcess.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8')
    })
    
    syncProcess.on('close', (code) => {
      if (code === 0) {
        console.log('âœ… ìµœì í™”ëœ Storage ë™ê¸°í™” ì„±ê³µ')
        res.json({
          success: true,
          message: 'ìµœì í™”ëœ Storage ë™ê¸°í™” ì™„ë£Œ',
          output: output
        })
      } else {
        console.error('âŒ ìµœì í™”ëœ Storage ë™ê¸°í™” ì‹¤íŒ¨:', errorOutput)
        res.status(500).json({
          success: false,
          error: `ìµœì í™”ëœ Storage ë™ê¸°í™” ì‹¤íŒ¨: ${errorOutput}`,
          output: output
        })
      }
    })
    
  } catch (error) {
    console.error('ìµœì í™”ëœ Storage ë™ê¸°í™” ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ë¡œì»¬ Storage ìµœì í™” ì—”ë“œí¬ì¸íŠ¸
app.post('/api/synthetic/dataset/optimize-local-storage', async (req, res) => {
  try {
    console.log('ğŸ“ ë¡œì»¬ Storage ìµœì í™” ìš”ì²­')
    
    const optimizeProcess = spawn('python', [
      path.join(__dirname, '..', 'scripts', 'optimize_local_storage.py')
    ], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: {
        ...process.env,
        PYTHONIOENCODING: 'utf-8',
        LANG: 'ko_KR.UTF-8',
        LC_ALL: 'ko_KR.UTF-8',
        PYTHONUTF8: '1'
      }
    })
    
    let output = ''
    let errorOutput = ''
    
    optimizeProcess.stdout.on('data', (data) => {
      output += data.toString('utf8')
    })
    
    optimizeProcess.stderr.on('data', (data) => {
      errorOutput += data.toString('utf8')
    })
    
    optimizeProcess.on('close', (code) => {
      if (code === 0) {
        console.log('âœ… ë¡œì»¬ Storage ìµœì í™” ì„±ê³µ')
        res.json({
          success: true,
          message: 'ë¡œì»¬ Storage ìµœì í™” ì™„ë£Œ',
          output: output
        })
      } else {
        console.error('âŒ ë¡œì»¬ Storage ìµœì í™” ì‹¤íŒ¨:', errorOutput)
        res.status(500).json({
          success: false,
          error: `ë¡œì»¬ Storage ìµœì í™” ì‹¤íŒ¨: ${errorOutput}`,
          output: output
        })
      }
    })
    
  } catch (error) {
    console.error('ë¡œì»¬ Storage ìµœì í™” ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì¡°íšŒ: manifests/v{version}.json ë°˜í™˜
app.get('/api/synthetic/dataset/manifest/:version', async (req, res) => {
  try {
    const { version } = req.params
    const manifestPath = path.join(__dirname, '..', 'output', 'manifests', `v${version}.json`)
    try {
      const data = await fs.promises.readFile(manifestPath, 'utf-8')
      res.setHeader('Content-Type', 'application/json; charset=utf-8')
      res.send(data)
    } catch (e) {
      return res.status(404).json({ success: false, error: 'manifest not found' })
    }
  } catch (error) {
    console.error('ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({ success: false, error: error.message })
  }
})

// data.yaml ë™ì  ìƒì„±/ë‹¤ìš´ë¡œë“œ (manifests ê¸°ë°˜, íŒŒì¼ ê²½ë¡œëŠ” ì •ì  ì„œë²„ URLë¡œ ë…¸ì¶œ)
app.get('/api/synthetic/dataset/data.yaml', async (req, res) => {
  try {
    const { version } = req.query
    if (!version) {
      return res.status(400).json({ success: false, error: 'version is required' })
    }
    const manifestPath = path.join(__dirname, '..', 'output', 'manifests', `v${version}.json`)
    const raw = await fs.promises.readFile(manifestPath, 'utf-8')
    const manifest = JSON.parse(raw)

    // ì •ì  ì œê³µ ë² ì´ìŠ¤ URL (output í´ë”ëŠ” /api/synthetic/static ì•„ë˜ì— ë…¸ì¶œë¨)
    const host = req.headers.host
    const baseUrl = `http://${host}/api/synthetic/static`

    // ì´ë¯¸ì§€ ê²½ë¡œë¥¼ train/valë¡œ êµ¬ë¶„ (manifest.files í‚¤ê°€ ìƒëŒ€ê²½ë¡œ í¬í•¨)
    const fileEntries = Object.keys(manifest.files || {})
    const trainImages = fileEntries
      .filter(p => p.startsWith('images/train/') && (p.endsWith('.webp') || p.endsWith('.jpg') || p.endsWith('.png')))
      .map(p => `${baseUrl}/${p.replace(/\\/g, '/')}`)
    const valImages = fileEntries
      .filter(p => p.startsWith('images/val/') && (p.endsWith('.webp') || p.endsWith('.jpg') || p.endsWith('.png')))
      .map(p => `${baseUrl}/${p.replace(/\\/g, '/')}`)

    // labels ê²½ë¡œëŠ” í•„ìš” ì‹œ ì‚¬ìš© (ì—¬ê¸°ì„œëŠ” ì°¸ê³ ìš©ìœ¼ë¡œ ë³´ê´€)
    const trainLabels = fileEntries
      .filter(p => p.startsWith('labels/train/') && p.endsWith('.txt'))
      .map(p => `${baseUrl}/${p.replace(/\\/g, '/')}`)
    const valLabels = fileEntries
      .filter(p => p.startsWith('labels/val/') && p.endsWith('.txt'))
      .map(p => `${baseUrl}/${p.replace(/\\/g, '/')}`)

    // YOLO data.yaml (UltralyticsëŠ” ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ë„ ì§€ì›)
    const yaml = [
      'path: .',
      'names: ["lego"]',
      'nc: 1',
      `train:`,
      ...trainImages.map(u => `  - ${u}`),
      `val:`,
      ...valImages.map(u => `  - ${u}`),
      '# labels (optional references)',
      'labels:',
      '  train:',
      ...trainLabels.map(u => `    - ${u}`),
      '  val:',
      ...valLabels.map(u => `    - ${u}`)
    ].join('\n')

    res.setHeader('Content-Type', 'text/yaml; charset=utf-8')
    res.setHeader('Content-Disposition', `attachment; filename="data.v${version}.yaml"`)
    res.send(yaml)
  } catch (error) {
    console.error('data.yaml ìƒì„± ì‹¤íŒ¨:', error)
    res.status(500).json({ success: false, error: error.message })
  }
})

// ì‹¤ì œ ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜ ì§€í‘œ ê³„ì‚° (ê¸°ìˆ ì„œ SLO ê¸°ì¤€)
const calculatePerformanceMetrics = async () => {
  try {
    console.log('ğŸ“Š ì‹¤ì œ ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì‹œì‘')
    
    // 1. í˜„ì¬ ëª¨ë¸ ì¡´ì¬ í™•ì¸
    const currentModelPath = path.join(__dirname, '..', 'models', 'current_model.pt')
    if (!fs.existsSync(currentModelPath)) {
      console.log('âš ï¸ í˜„ì¬ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ë°˜í™˜')
      return getDefaultMetrics()
    }
    
    // 2. ì‹¤ì œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰
    const evaluationResult = await evaluateCurrentModel(currentModelPath)
    
    if (evaluationResult.success) {
      console.log('âœ… ì‹¤ì œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ:', evaluationResult.metrics)
      return evaluationResult.metrics
    } else {
      console.log('âš ï¸ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©:', evaluationResult.error)
      return getDefaultMetrics()
    }
    
  } catch (error) {
    console.log('âš ï¸ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©:', error.message)
    return getDefaultMetrics()
  }
}

// í˜„ì¬ ëª¨ë¸ ì‹¤ì œ í‰ê°€
const evaluateCurrentModel = async (modelPath) => {
  try {
    const { spawn } = await import('child_process')
    
    const evaluationScript = path.join(__dirname, '..', 'scripts', 'evaluate_model.py')
    const dataPath = path.join(__dirname, '..', 'output', 'dataset_synthetic')
    
    return new Promise((resolve) => {
      const process = spawn('python', [evaluationScript, '--model', modelPath, '--data', dataPath], {
        cwd: path.join(__dirname, '..'),
        stdio: ['pipe', 'pipe', 'pipe']
      })
      
      let stdout = ''
      let stderr = ''
      
      process.stdout.on('data', (data) => {
        stdout += data.toString()
      })
      
      process.stderr.on('data', (data) => {
        stderr += data.toString()
      })
      
      process.on('close', (code) => {
        if (code === 0) {
          try {
            const result = JSON.parse(stdout)
            resolve({ success: true, metrics: result.metrics })
          } catch (e) {
            resolve({ success: false, error: 'JSON íŒŒì‹± ì‹¤íŒ¨' })
          }
        } else {
          resolve({ success: false, error: stderr })
        }
      })
      
      process.on('error', (error) => {
        resolve({ success: false, error: error.message })
      })
    })
  } catch (error) {
    return { success: false, error: error.message }
  }
}

// ê¸°ë³¸ ë©”íŠ¸ë¦­ (SLO ê¸°ì¤€)
const getDefaultMetrics = () => {
  return {
    recall: 0.85,           // SLO: â‰¥0.95
    top1Accuracy: 0.90,      // SLO: â‰¥0.97  
    p95Latency: 150,        // SLO: â‰¤150ms
    holdRate: 0.08,         // ìš´ì˜ ì§€í‘œ
    stage2Rate: 0.25,       // ìš´ì˜ ì§€í‘œ
    falseDetectionRate: 0.03, // SLO: â‰¤3%
    occlusionIQR: 0.15,     // ìš´ì˜ ì§€í‘œ
    webpDecodeP95: 15,      // SLO: â‰¤15ms
    oodRate: 0.02,          // ìš´ì˜ ì§€í‘œ
    lastUpdated: new Date().toISOString()
  }
}

// ë°ì´í„°ì…‹ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
const calculateDatasetQuality = async (datasetPath) => {
  try {
    let qualityScore = 0.5 // ê¸°ë³¸ ì ìˆ˜
    
    // ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦
    const imagesPath = path.join(datasetPath, 'images')
    if (fs.existsSync(imagesPath)) {
      const imageFiles = await fs.promises.readdir(imagesPath)
      const validImages = imageFiles.filter(f => f.endsWith('.webp')).length
      if (validImages > 0) qualityScore += 0.2
    }
    
    // ë¼ë²¨ íŒŒì¼ ê²€ì¦
    const labelsPath = path.join(datasetPath, 'labels')
    if (fs.existsSync(labelsPath)) {
      const labelFiles = await fs.promises.readdir(labelsPath)
      const validLabels = labelFiles.filter(f => f.endsWith('.txt')).length
      if (validLabels > 0) qualityScore += 0.2
    }
    
    // ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²€ì¦
    const metadataPath = path.join(datasetPath, 'metadata')
    if (fs.existsSync(metadataPath)) {
      const metadataFiles = await fs.promises.readdir(metadataPath)
      const validMetadata = metadataFiles.filter(f => f.endsWith('.json')).length
      if (validMetadata > 0) qualityScore += 0.1
    }
    
    return Math.min(1.0, qualityScore)
  } catch (error) {
    console.log('âš ï¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨:', error.message)
    return 0.5
  }
}

// ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì§€í‘œ ì¡°íšŒ
app.get('/api/synthetic/monitor/metrics', async (req, res) => {
  try {
    console.log('ğŸ“Š ì„±ëŠ¥ ì§€í‘œ ì¡°íšŒ ìš”ì²­')
    
    // ì‹¤ì œ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    const metrics = await calculatePerformanceMetrics()
    
    // 2ë‹¨ê³„ ëª¨ë¸ SLO ê¸°ë°˜ ì„ê³„ì¹˜ ì„¤ì • (ê¸°ìˆ ì„œ ê¸°ì¤€)
    const thresholds = {
      // Stage-1 (íƒì§€) SLO
      recall: 0.95,                   // SLO: ì†Œí˜• Recall â‰¥0.95
      detectionLatency: 50,           // SLO: íƒì§€ ì§€ì—° â‰¤50ms
      
      // Stage-2 (ì‹ë³„) SLO
      top1Accuracy: 0.97,             // SLO: Top-1@BOM â‰¥0.97
      stage2Rate: 0.25,               // SLO: Stage-2 ì§„ì…ë¥  â‰¤25%
      searchLatency: 15,              // SLO: ê²€ìƒ‰ ì§€ì—° â‰¤15ms
      
      // ì „ì²´ íŒŒì´í”„ë¼ì¸ SLO
      p95Latency: 150,                // SLO: ì „ì²´ ì§€ì—° â‰¤150ms
      holdRate: 0.07,                 // SLO: ë³´ë¥˜ìœ¨ â‰¤7%
      webpDecodeP95: 15,              // SLO: WebP ë””ì½”ë“œ â‰¤15ms
      falseDetectionRate: 0.03,       // SLO: ì˜¤íƒì§€ìœ¨ â‰¤3%
      occlusionIQR: 0.15,             // ìš´ì˜ ì§€í‘œ
      oodRate: 0.02                   // ìš´ì˜ ì§€í‘œ
    }
    
    // 2ë‹¨ê³„ ëª¨ë¸ ìœ„ë°˜ ì§€í‘œ í™•ì¸
    const violations = []
    
    // Stage-1 (íƒì§€) ì§€í‘œ ìœ„ë°˜ í™•ì¸
    if (metrics.recall < thresholds.recall) violations.push({ metric: 'recall', value: metrics.recall, threshold: thresholds.recall })
    if (metrics.detectionLatency > thresholds.detectionLatency) violations.push({ metric: 'detectionLatency', value: metrics.detectionLatency, threshold: thresholds.detectionLatency })
    
    // Stage-2 (ì‹ë³„) ì§€í‘œ ìœ„ë°˜ í™•ì¸
    if (metrics.top1Accuracy < thresholds.top1Accuracy) violations.push({ metric: 'top1Accuracy', value: metrics.top1Accuracy, threshold: thresholds.top1Accuracy })
    if (metrics.stage2Rate > thresholds.stage2Rate) violations.push({ metric: 'stage2Rate', value: metrics.stage2Rate, threshold: thresholds.stage2Rate })
    if (metrics.searchLatency > thresholds.searchLatency) violations.push({ metric: 'searchLatency', value: metrics.searchLatency, threshold: thresholds.searchLatency })
    
    // ì „ì²´ íŒŒì´í”„ë¼ì¸ ì§€í‘œ ìœ„ë°˜ í™•ì¸
    if (metrics.p95Latency > thresholds.p95Latency) violations.push({ metric: 'p95Latency', value: metrics.p95Latency, threshold: thresholds.p95Latency })
    if (metrics.holdRate > thresholds.holdRate) violations.push({ metric: 'holdRate', value: metrics.holdRate, threshold: thresholds.holdRate })
    if (metrics.webpDecodeP95 > thresholds.webpDecodeP95) violations.push({ metric: 'webpDecodeP95', value: metrics.webpDecodeP95, threshold: thresholds.webpDecodeP95 })
    if (metrics.falseDetectionRate > thresholds.falseDetectionRate) violations.push({ metric: 'falseDetectionRate', value: metrics.falseDetectionRate, threshold: thresholds.falseDetectionRate })
    if (metrics.occlusionIQR > thresholds.occlusionIQR) violations.push({ metric: 'occlusionIQR', value: metrics.occlusionIQR, threshold: thresholds.occlusionIQR })
    if (metrics.oodRate > thresholds.oodRate) violations.push({ metric: 'oodRate', value: metrics.oodRate, threshold: thresholds.oodRate })
    
    // 2ë‹¨ê³„ ëª¨ë¸ ê¸°ë°˜ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬
    let recommendedAction = 'none'
    
    // Stage-1 (íƒì§€) ìœ„ë°˜ í™•ì¸
    const stage1Violations = violations.filter(v => 
      ['recall', 'detectionLatency'].includes(v.metric)
    )
    
    // Stage-2 (ì‹ë³„) ìœ„ë°˜ í™•ì¸
    const stage2Violations = violations.filter(v => 
      ['top1Accuracy', 'stage2Rate', 'searchLatency'].includes(v.metric)
    )
    
    // ì „ì²´ íŒŒì´í”„ë¼ì¸ ìœ„ë°˜ í™•ì¸
    const pipelineViolations = violations.filter(v => 
      ['p95Latency', 'holdRate', 'webpDecodeP95'].includes(v.metric)
    )
    
    // ê¸°ìˆ ì„œ ê¸°ë°˜ ì˜ì‚¬ê²°ì •
    if (stage1Violations.length >= 2 || stage2Violations.length >= 2 || pipelineViolations.length >= 2) {
      // ë‹¤ìˆ˜ ì§€í‘œ ìœ„ë°˜ ì‹œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ
      recommendedAction = 'full_pipeline_retrain'
    } else if (stage1Violations.length >= 1) {
      // Stage-1 ìœ„ë°˜ ì‹œ íƒì§€ ëª¨ë¸ ì¬í•™ìŠµ
      recommendedAction = 'stage1_retrain'
    } else if (stage2Violations.length >= 1) {
      // Stage-2 ìœ„ë°˜ ì‹œ ì‹ë³„ ëª¨ë¸ ì¬í•™ìŠµ
      recommendedAction = 'stage2_retrain'
    } else if (violations.length >= 1) {
      // ê¸°íƒ€ ìœ„ë°˜ ì‹œ ì¦ë¶„ í•™ìŠµ
      recommendedAction = 'incremental'
    }
    
    console.log(`âœ… ì„±ëŠ¥ ì§€í‘œ ì¡°íšŒ ì™„ë£Œ: ${violations.length}ê°œ ìœ„ë°˜, ê¶Œì¥ ì•¡ì…˜: ${recommendedAction}`)
    
    res.json({
      success: true,
      metrics,
      thresholds,
      violations,
      recommendedAction,
      status: violations.length === 0 ? 'healthy' : violations.length >= 2 ? 'critical' : 'warning'
    })
  } catch (error) {
    console.error('âŒ ì„±ëŠ¥ ì§€í‘œ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ë¶€í’ˆ ë‹¨ìœ„ í•™ìŠµ íŠ¸ë¦¬ê±°
app.post('/api/synthetic/monitor/trigger', async (req, res) => {
  try {
    const { partId, mode, action, reason } = req.body
    console.log(`ğŸš€ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰: ë¶€í’ˆ ${partId}, ëª¨ë“œ: ${mode}, ì•¡ì…˜: ${action}`)
    console.log('ğŸ“‹ ìš”ì²­ ë³¸ë¬¸:', JSON.stringify(req.body, null, 2))
    
    // ë¶€í’ˆ ë‹¨ìœ„ í•™ìŠµì¸ ê²½ìš°
    if (partId && mode === 'part') {
      console.log(`ğŸ“¦ ë¶€í’ˆ ${partId} ë‹¨ìœ„ í•™ìŠµ ì‹œì‘`)
      
      // ë¶€í’ˆ ì¡´ì¬ í™•ì¸
      const { data: partData, error: partError } = await supabase
        .from('parts_master')
        .select('part_id, part_name')
        .eq('part_id', partId)
        .limit(1)
      
      if (partError) {
        throw new Error(`ë¶€í’ˆ ì¡°íšŒ ì‹¤íŒ¨: ${partError.message}`)
      }
      
      if (!partData || partData.length === 0) {
        throw new Error(`ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¶€í’ˆ: ${partId}`)
      }
      
      // ì´ë¯¸ì§€ ë°ì´í„° í™•ì¸
      const { data: imageData, error: imageError } = await supabase
        .from('synthetic_dataset')
        .select('*')
        .eq('part_id', partId)
        .eq('status', 'uploaded')
      
      if (imageError) {
        throw new Error(`ì´ë¯¸ì§€ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: ${imageError.message}`)
      }
      
      const imageCount = imageData?.length || 0
      console.log(`ğŸ“Š ë¶€í’ˆ ${partId} ì´ë¯¸ì§€ ìˆ˜: ${imageCount}ê°œ`)
      
      if (imageCount === 0) {
        throw new Error(`ë¶€í’ˆ ${partId}ì— í•™ìŠµìš© ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤`)
      }
      
      // í•™ìŠµ ì‘ì—… ìƒì„± (upsert ì‚¬ìš©)
      const { data: trainingJob, error: jobError } = await supabase
        .from('part_training_status')
        .upsert({
          part_id: partId,
          status: 'pending',
          created_at: new Date().toISOString(),
          updated_at: new Date().toISOString()
        }, {
          onConflict: 'part_id'
        })
        .select()
        .single()
      
      if (jobError) {
        throw new Error(`í•™ìŠµ ì‘ì—… ìƒì„± ì‹¤íŒ¨: ${jobError.message}`)
      }
      
      console.log(`âœ… ë¶€í’ˆ ${partId} í•™ìŠµ ì‘ì—… ìƒì„± ì™„ë£Œ: ${trainingJob.id}`)
      
      res.json({
        success: true,
        message: `ë¶€í’ˆ ${partId} í•™ìŠµì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤`,
        jobId: trainingJob.id,
        partId: partId,
        imageCount: imageCount,
        timestamp: new Date().toISOString()
      })
      return
    }
    
    // Storageì—ì„œ model_registryë¡œ ëª¨ë¸ ë™ê¸°í™”
app.post('/api/synthetic/sync-models', async (req, res) => {
  try {
    console.log('ğŸ”„ Storage â†’ model_registry ë™ê¸°í™” ì‹œì‘...')
    
    // Storageì—ì„œ ëª¨ë¸ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
    const { data: storageFiles, error: storageError } = await supabase
      .storage
      .from('models')
      .list('', { limit: 1000 })
    
    if (storageError) {
      throw new Error(`Storage ì¡°íšŒ ì‹¤íŒ¨: ${storageError.message}`)
    }
    
    console.log(`ğŸ“ Storageì—ì„œ ë°œê²¬ëœ íŒŒì¼: ${storageFiles?.length || 0}ê°œ`)
    
    if (!storageFiles || storageFiles.length === 0) {
      return res.json({
        success: true,
        message: 'Storageì— ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤',
        synced: 0
      })
    }
    
    // .pt íŒŒì¼ë§Œ í•„í„°ë§
    const modelFiles = storageFiles.filter(file => file.name.endsWith('.pt'))
    console.log(`ğŸ¤– ëª¨ë¸ íŒŒì¼ (.pt): ${modelFiles.length}ê°œ`)
    
    let syncedCount = 0
    const results = []
    
    for (const file of modelFiles) {
      try {
        // íŒŒì¼ ì •ë³´ ì¡°íšŒ
        const { data: fileInfo } = await supabase
          .storage
          .from('models')
          .getPublicUrl(file.name)
        
        // íŒŒì¼ í¬ê¸° ì¡°íšŒ
        const { data: fileData } = await supabase
          .storage
          .from('models')
          .download(file.name)
        
        const fileSize = fileData?.size || 0
        const fileSizeMB = Math.round((fileSize / (1024 * 1024)) * 100) / 100
        
        // ëª¨ë¸ëª… ìƒì„± (íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°)
        const modelName = file.name.replace('.pt', '')
        
        // ì´ë¯¸ ë“±ë¡ëœ ëª¨ë¸ì¸ì§€ í™•ì¸
        const { data: existingModel } = await supabase
          .from('model_registry')
          .select('id')
          .eq('model_name', modelName)
          .limit(1)
        
        if (existingModel && existingModel.length > 0) {
          console.log(`â­ï¸ ëª¨ë¸ ${modelName}ì€ ì´ë¯¸ ë“±ë¡ë¨`)
          continue
        }
        
        // model_registryì— ë“±ë¡
        const modelData = {
          model_name: modelName,
          version: '1.0.0',
          model_url: fileInfo?.publicUrl || '',
          model_path: file.name,
          model_size: fileSize,
          model_size_mb: fileSizeMB,
          status: 'trained',
          is_active: false, // ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”
          model_type: 'yolo',
          model_stage: 'single',
          performance_metrics: {
            map50: 0.0,
            map75: 0.0,
            precision: 0.0,
            recall: 0.0
          },
          training_metadata: {
            source: 'storage_sync',
            synced_at: new Date().toISOString()
          },
          created_by: 'system',
          created_at: new Date().toISOString(),
          updated_at: new Date().toISOString()
        }
        
        const { data: insertedModel, error: insertError } = await supabase
          .from('model_registry')
          .insert(modelData)
          .select()
          .single()
        
        if (insertError) {
          console.error(`âŒ ëª¨ë¸ ${modelName} ë“±ë¡ ì‹¤íŒ¨:`, insertError)
          results.push({
            model: modelName,
            success: false,
            error: insertError.message
          })
        } else {
          console.log(`âœ… ëª¨ë¸ ${modelName} ë“±ë¡ ì™„ë£Œ`)
          syncedCount++
          results.push({
            model: modelName,
            success: true,
            id: insertedModel.id
          })
        }
        
      } catch (fileError) {
        console.error(`âŒ íŒŒì¼ ${file.name} ì²˜ë¦¬ ì‹¤íŒ¨:`, fileError)
        results.push({
          model: file.name,
          success: false,
          error: fileError.message
        })
      }
    }
    
    console.log(`ğŸ¯ ë™ê¸°í™” ì™„ë£Œ: ${syncedCount}ê°œ ëª¨ë¸ ë“±ë¡ë¨`)
    
    res.json({
      success: true,
      message: `Storageì—ì„œ ${syncedCount}ê°œ ëª¨ë¸ì„ model_registryì— ë“±ë¡í–ˆìŠµë‹ˆë‹¤`,
      synced: syncedCount,
      total: modelFiles.length,
      results: results
    })
    
  } catch (error) {
    console.error('âŒ ëª¨ë¸ ë™ê¸°í™” ì‹¤íŒ¨:', error)
    res.json({
      success: false,
      error: error.message
    })
  }
})

// ë¶€í’ˆ ë‹¨ìœ„ í•™ìŠµ íŠ¸ë¦¬ê±° í•¨ìˆ˜
async function triggerPartTraining(partId, reason) {
  try {
    console.log(`ğŸ§© ë¶€í’ˆ ${partId} ë‹¨ìœ„ í•™ìŠµ ì‹œì‘: ${reason}`)
    
    // ë¶€í’ˆ ë°ì´í„° í™•ì¸
    const { data: partData, error: partError } = await supabase
      .from('parts_master')
      .select('part_id, part_name')
      .eq('part_id', partId)
      .limit(1)
    
    if (partError) throw new Error(`ë¶€í’ˆ ì¡°íšŒ ì‹¤íŒ¨: ${partError.message}`)
    if (!partData || partData.length === 0) throw new Error(`ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¶€í’ˆ: ${partId}`)
    
    // ì´ë¯¸ì§€ ë°ì´í„° í™•ì¸
    const { data: imageData, error: imageError } = await supabase
      .from('synthetic_dataset')
      .select('*')
      .eq('part_id', partId)
      .eq('status', 'uploaded')
    
    if (imageError) throw new Error(`ì´ë¯¸ì§€ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: ${imageError.message}`)
    
    const imageCount = imageData?.length || 0
    console.log(`ğŸ“Š ë¶€í’ˆ ${partId} ì´ë¯¸ì§€ ìˆ˜: ${imageCount}ê°œ`)
    
    if (imageCount === 0) {
      throw new Error(`ë¶€í’ˆ ${partId}ì— í•™ìŠµìš© ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤`)
    }
    
    // í•™ìŠµ ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸
    const { error: updateError } = await supabase
      .from('part_training_status')
      .update({
        status: 'training',
        updated_at: new Date().toISOString()
      })
      .eq('part_id', partId)
    
    if (updateError) {
      console.warn('í•™ìŠµ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:', updateError)
    }
    
    console.log(`âœ… ë¶€í’ˆ ${partId} í•™ìŠµ ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤`)
    
    return {
      success: true,
      partId: partId,
      imageCount: imageCount,
      message: `ë¶€í’ˆ ${partId} í•™ìŠµì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤`
    }
    
  } catch (error) {
    console.error(`âŒ ë¶€í’ˆ ${partId} í•™ìŠµ ì‹¤íŒ¨:`, error)
    throw error
  }
}

// ê¸°ì¡´ ìë™ íŠ¸ë¦¬ê±° ë¡œì§
    let result = null
    
    if (action === 'incremental' || action === 'incremental_learning') {
      // ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±°
      console.log('ğŸ“ˆ ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰')
      result = await triggerIncrementalLearning(reason)
    } else if (action === 'part_training') {
      // ë¶€í’ˆ ë‹¨ìœ„ í•™ìŠµ íŠ¸ë¦¬ê±°
      console.log('ğŸ§© ë¶€í’ˆ ë‹¨ìœ„ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰')
      result = await triggerPartTraining(partId, reason)
    } else if (action === 'full_retrain') {
      // ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
      console.log('ğŸ”„ ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰')
      result = await triggerFullRetraining(reason)
    } else if (action === 'stage1_incremental') {
      // Stage-1 ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±°
      console.log('ğŸ” Stage-1 ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰')
      result = await triggerStage1IncrementalLearning(reason)
    } else if (action === 'stage1_full_retrain') {
      // Stage-1 ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
      console.log('ğŸ” Stage-1 ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰')
      result = await triggerStage1FullRetraining(reason)
    } else if (action === 'stage2_incremental') {
      // Stage-2 ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±°
      console.log('ğŸ¯ Stage-2 ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰')
      result = await triggerStage2IncrementalLearning(reason)
    } else if (action === 'stage2_full_retrain') {
      // Stage-2 ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
      console.log('ğŸ¯ Stage-2 ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰')
      result = await triggerStage2FullRetraining(reason)
    } else if (action === 'full_pipeline_retrain') {
      // ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
      console.log('âš¡ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰')
      result = await triggerFullPipelineRetraining(reason)
    } else {
      throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•¡ì…˜: ${action}`)
    }
    
    res.json({
      success: true,
      message: `${action} íŠ¸ë¦¬ê±°ê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤`,
      result: result,
      timestamp: new Date().toISOString()
    })
  } catch (error) {
    console.error('âŒ ìë™ íŠ¸ë¦¬ê±° ì‹¤í–‰ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰
const triggerIncrementalLearning = async (reason) => {
  try {
    console.log('ğŸ“ˆ ì¦ë¶„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘...')
    
    const { spawn } = await import('child_process')
    const path = await import('path')
    
    const scriptPath = path.join(__dirname, '..', 'scripts', 'incremental_learning_pipeline.py')
    
    return new Promise((resolve, reject) => {
      const process = spawn('python', [scriptPath], {
        cwd: path.join(__dirname, '..'),
        stdio: ['pipe', 'pipe', 'pipe']
      })
      
      let stdout = ''
      let stderr = ''
      
      process.stdout.on('data', (data) => {
        stdout += data.toString()
        console.log(`[ì¦ë¶„í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.stderr.on('data', (data) => {
        stderr += data.toString()
        console.error(`[ì¦ë¶„í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.on('close', (code) => {
        if (code === 0) {
          try {
            const result = JSON.parse(stdout)
            console.log('âœ… ì¦ë¶„ í•™ìŠµ ì™„ë£Œ:', result)
            resolve(result)
          } catch (e) {
            console.log('âœ… ì¦ë¶„ í•™ìŠµ ì™„ë£Œ (JSON íŒŒì‹± ì‹¤íŒ¨):', stdout)
            resolve({ status: 'completed', output: stdout })
          }
        } else {
          console.error('âŒ ì¦ë¶„ í•™ìŠµ ì‹¤íŒ¨:', stderr)
          reject(new Error(`ì¦ë¶„ í•™ìŠµ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code}): ${stderr}`))
        }
      })
      
      process.on('error', (error) => {
        console.error('âŒ ì¦ë¶„ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error)
        reject(error)
      })
    })
  } catch (error) {
    console.error('âŒ ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤íŒ¨:', error)
    throw error
  }
}

// ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤í–‰
const triggerFullRetraining = async (reason) => {
  try {
    console.log('ğŸ”„ ì „ì²´ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘...')
    
    const { spawn } = await import('child_process')
    const path = await import('path')
    
    const scriptPath = path.join(__dirname, '..', 'scripts', 'full_retraining_pipeline.py')
    
    return new Promise((resolve, reject) => {
      const process = spawn('python', [scriptPath], {
        cwd: path.join(__dirname, '..'),
        stdio: ['pipe', 'pipe', 'pipe']
      })
      
      let stdout = ''
      let stderr = ''
      
      process.stdout.on('data', (data) => {
        stdout += data.toString()
        console.log(`[ì „ì²´ì¬í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.stderr.on('data', (data) => {
        stderr += data.toString()
        console.error(`[ì „ì²´ì¬í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.on('close', (code) => {
        if (code === 0) {
          try {
            const result = JSON.parse(stdout)
            console.log('âœ… ì „ì²´ ì¬í•™ìŠµ ì™„ë£Œ:', result)
            resolve(result)
          } catch (e) {
            console.log('âœ… ì „ì²´ ì¬í•™ìŠµ ì™„ë£Œ (JSON íŒŒì‹± ì‹¤íŒ¨):', stdout)
            resolve({ status: 'completed', output: stdout })
          }
        } else {
          console.error('âŒ ì „ì²´ ì¬í•™ìŠµ ì‹¤íŒ¨:', stderr)
          reject(new Error(`ì „ì²´ ì¬í•™ìŠµ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code}): ${stderr}`))
        }
      })
      
      process.on('error', (error) => {
        console.error('âŒ ì „ì²´ ì¬í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error)
        reject(error)
      })
    })
  } catch (error) {
    console.error('âŒ ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤íŒ¨:', error)
    throw error
  }
}

// Stage-1 ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±°
const triggerStage1IncrementalLearning = async (reason) => {
  try {
    console.log('ğŸ” Stage-1 ì¦ë¶„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘...')
    
    const { spawn } = await import('child_process')
    const path = await import('path')
    
    const scriptPath = path.join(__dirname, '..', 'scripts', 'stage1_incremental_learning.py')
    
    return new Promise((resolve, reject) => {
      const process = spawn('python', [scriptPath, '--reason', reason], {
        cwd: path.join(__dirname, '..'),
        stdio: ['pipe', 'pipe', 'pipe']
      })
      
      let stdout = ''
      let stderr = ''
      
      process.stdout.on('data', (data) => {
        stdout += data.toString()
        console.log(`[Stage-1ì¦ë¶„í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.stderr.on('data', (data) => {
        stderr += data.toString()
        console.error(`[Stage-1ì¦ë¶„í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.on('close', (code) => {
        if (code === 0) {
          try {
            const result = JSON.parse(stdout)
            console.log('âœ… Stage-1 ì¦ë¶„ í•™ìŠµ ì™„ë£Œ:', result)
            resolve(result)
          } catch (e) {
            console.log('âœ… Stage-1 ì¦ë¶„ í•™ìŠµ ì™„ë£Œ (JSON íŒŒì‹± ì‹¤íŒ¨):', stdout)
            resolve({ status: 'completed', output: stdout })
          }
        } else {
          console.error('âŒ Stage-1 ì¦ë¶„ í•™ìŠµ ì‹¤íŒ¨:', stderr)
          reject(new Error(`Stage-1 ì¦ë¶„ í•™ìŠµ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code}): ${stderr}`))
        }
      })
      
      process.on('error', (error) => {
        console.error('âŒ Stage-1 ì¦ë¶„ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error)
        reject(error)
      })
    })
  } catch (error) {
    console.error('âŒ Stage-1 ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤íŒ¨:', error)
    throw error
  }
}

// Stage-1 ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
const triggerStage1FullRetraining = async (reason) => {
  try {
    console.log('ğŸ” Stage-1 ì „ì²´ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘...')
    
    const { spawn } = await import('child_process')
    const path = await import('path')
    
    const scriptPath = path.join(__dirname, '..', 'scripts', 'stage1_full_retraining.py')
    
    return new Promise((resolve, reject) => {
      const process = spawn('python', [scriptPath, '--reason', reason], {
        cwd: path.join(__dirname, '..'),
        stdio: ['pipe', 'pipe', 'pipe']
      })
      
      let stdout = ''
      let stderr = ''
      
      process.stdout.on('data', (data) => {
        stdout += data.toString()
        console.log(`[Stage-1ì „ì²´ì¬í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.stderr.on('data', (data) => {
        stderr += data.toString()
        console.error(`[Stage-1ì „ì²´ì¬í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.on('close', (code) => {
        if (code === 0) {
          try {
            const result = JSON.parse(stdout)
            console.log('âœ… Stage-1 ì „ì²´ ì¬í•™ìŠµ ì™„ë£Œ:', result)
            resolve(result)
          } catch (e) {
            console.log('âœ… Stage-1 ì „ì²´ ì¬í•™ìŠµ ì™„ë£Œ (JSON íŒŒì‹± ì‹¤íŒ¨):', stdout)
            resolve({ status: 'completed', output: stdout })
          }
        } else {
          console.error('âŒ Stage-1 ì „ì²´ ì¬í•™ìŠµ ì‹¤íŒ¨:', stderr)
          reject(new Error(`Stage-1 ì „ì²´ ì¬í•™ìŠµ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code}): ${stderr}`))
        }
      })
      
      process.on('error', (error) => {
        console.error('âŒ Stage-1 ì „ì²´ ì¬í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error)
        reject(error)
      })
    })
  } catch (error) {
    console.error('âŒ Stage-1 ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤íŒ¨:', error)
    throw error
  }
}

// Stage-2 ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±°
const triggerStage2IncrementalLearning = async (reason) => {
  try {
    console.log('ğŸ¯ Stage-2 ì¦ë¶„ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘...')
    
    const { spawn } = await import('child_process')
    const path = await import('path')
    
    const scriptPath = path.join(__dirname, '..', 'scripts', 'stage2_incremental_learning.py')
    
    return new Promise((resolve, reject) => {
      const process = spawn('python', [scriptPath, '--reason', reason], {
        cwd: path.join(__dirname, '..'),
        stdio: ['pipe', 'pipe', 'pipe']
      })
      
      let stdout = ''
      let stderr = ''
      
      process.stdout.on('data', (data) => {
        stdout += data.toString()
        console.log(`[Stage-2ì¦ë¶„í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.stderr.on('data', (data) => {
        stderr += data.toString()
        console.error(`[Stage-2ì¦ë¶„í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.on('close', (code) => {
        if (code === 0) {
          try {
            const result = JSON.parse(stdout)
            console.log('âœ… Stage-2 ì¦ë¶„ í•™ìŠµ ì™„ë£Œ:', result)
            resolve(result)
          } catch (e) {
            console.log('âœ… Stage-2 ì¦ë¶„ í•™ìŠµ ì™„ë£Œ (JSON íŒŒì‹± ì‹¤íŒ¨):', stdout)
            resolve({ status: 'completed', output: stdout })
          }
        } else {
          console.error('âŒ Stage-2 ì¦ë¶„ í•™ìŠµ ì‹¤íŒ¨:', stderr)
          reject(new Error(`Stage-2 ì¦ë¶„ í•™ìŠµ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code}): ${stderr}`))
        }
      })
      
      process.on('error', (error) => {
        console.error('âŒ Stage-2 ì¦ë¶„ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error)
        reject(error)
      })
    })
  } catch (error) {
    console.error('âŒ Stage-2 ì¦ë¶„ í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤íŒ¨:', error)
    throw error
  }
}

// Stage-2 ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
const triggerStage2FullRetraining = async (reason) => {
  try {
    console.log('ğŸ¯ Stage-2 ì „ì²´ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘...')
    
    const { spawn } = await import('child_process')
    const path = await import('path')
    
    const scriptPath = path.join(__dirname, '..', 'scripts', 'stage2_full_retraining.py')
    
    return new Promise((resolve, reject) => {
      const process = spawn('python', [scriptPath, '--reason', reason], {
        cwd: path.join(__dirname, '..'),
        stdio: ['pipe', 'pipe', 'pipe']
      })
      
      let stdout = ''
      let stderr = ''
      
      process.stdout.on('data', (data) => {
        stdout += data.toString()
        console.log(`[Stage-2ì „ì²´ì¬í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.stderr.on('data', (data) => {
        stderr += data.toString()
        console.error(`[Stage-2ì „ì²´ì¬í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.on('close', (code) => {
        if (code === 0) {
          try {
            const result = JSON.parse(stdout)
            console.log('âœ… Stage-2 ì „ì²´ ì¬í•™ìŠµ ì™„ë£Œ:', result)
            resolve(result)
          } catch (e) {
            console.log('âœ… Stage-2 ì „ì²´ ì¬í•™ìŠµ ì™„ë£Œ (JSON íŒŒì‹± ì‹¤íŒ¨):', stdout)
            resolve({ status: 'completed', output: stdout })
          }
        } else {
          console.error('âŒ Stage-2 ì „ì²´ ì¬í•™ìŠµ ì‹¤íŒ¨:', stderr)
          reject(new Error(`Stage-2 ì „ì²´ ì¬í•™ìŠµ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code}): ${stderr}`))
        }
      })
      
      process.on('error', (error) => {
        console.error('âŒ Stage-2 ì „ì²´ ì¬í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error)
        reject(error)
      })
    })
  } catch (error) {
    console.error('âŒ Stage-2 ì „ì²´ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤íŒ¨:', error)
    throw error
  }
}

// ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
const triggerFullPipelineRetraining = async (reason) => {
  try {
    console.log('âš¡ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ ì‹œì‘...')
    
    const { spawn } = await import('child_process')
    const path = await import('path')
    
    const scriptPath = path.join(__dirname, '..', 'scripts', 'full_pipeline_retraining.py')
    
    return new Promise((resolve, reject) => {
      const process = spawn('python', [scriptPath, '--reason', reason], {
        cwd: path.join(__dirname, '..'),
        stdio: ['pipe', 'pipe', 'pipe']
      })
      
      let stdout = ''
      let stderr = ''
      
      process.stdout.on('data', (data) => {
        stdout += data.toString()
        console.log(`[ì „ì²´íŒŒì´í”„ë¼ì¸ì¬í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.stderr.on('data', (data) => {
        stderr += data.toString()
        console.error(`[ì „ì²´íŒŒì´í”„ë¼ì¸ì¬í•™ìŠµ] ${data.toString().trim()}`)
      })
      
      process.on('close', (code) => {
        if (code === 0) {
          try {
            const result = JSON.parse(stdout)
            console.log('âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ ì™„ë£Œ:', result)
            resolve(result)
          } catch (e) {
            console.log('âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ ì™„ë£Œ (JSON íŒŒì‹± ì‹¤íŒ¨):', stdout)
            resolve({ status: 'completed', output: stdout })
          }
        } else {
          console.error('âŒ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ ì‹¤íŒ¨:', stderr)
          reject(new Error(`ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code}): ${stderr}`))
        }
      })
      
      process.on('error', (error) => {
        console.error('âŒ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error)
        reject(error)
      })
    })
  } catch (error) {
    console.error('âŒ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° ì‹¤íŒ¨:', error)
    throw error
  }
}

// ìë™ í•™ìŠµ ì‹¤í–‰ API ì—”ë“œí¬ì¸íŠ¸
app.post('/api/synthetic/training/start', async (req, res) => {
  try {
    const { job_id, config, set_num } = req.body
    console.log('ğŸš€ ìë™ í•™ìŠµ ì‹¤í–‰ ìš”ì²­:', { job_id, config, set_num })
    
    // í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    const { spawn } = await import('child_process')
    const path = await import('path')
    
    const scriptPath = path.join(__dirname, '..', 'scripts', 'local_yolo_training.py')
    const args = [
      '--set_num', set_num || 'latest',
      '--epochs', config.epochs || 100,
      '--batch_size', config.batch_size || 16,
      '--imgsz', config.imgsz || 640,
      '--device', config.device || 'cuda',
      '--job_id', job_id
    ]
    
    console.log('ğŸ“‹ ì‹¤í–‰ ëª…ë ¹ì–´:', `python ${scriptPath} ${args.join(' ')}`)
    
    const trainingProcess = spawn('python', [scriptPath, ...args], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: {
        ...process.env,
        PYTHONIOENCODING: 'utf-8',
        LANG: 'ko_KR.UTF-8',
        LC_ALL: 'ko_KR.UTF-8',
        PYTHONUTF8: '1'
      }
    })
    
    // í”„ë¡œì„¸ìŠ¤ ì¶œë ¥ ì²˜ë¦¬
    trainingProcess.stdout.on('data', (data) => {
      const message = data.toString('utf8').trim()
      console.log(`[í•™ìŠµ] ${message}`)
    })
    
    trainingProcess.stderr.on('data', (data) => {
      const message = data.toString('utf8').trim()
      console.error(`[í•™ìŠµ ì˜¤ë¥˜] ${message}`)
    })
    
    trainingProcess.on('close', (code) => {
      if (code === 0) {
        console.log('âœ… ìë™ í•™ìŠµ ì™„ë£Œ')
      } else {
        console.error(`âŒ ìë™ í•™ìŠµ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: ${code})`)
      }
    })
    
    trainingProcess.on('error', (error) => {
      console.error('âŒ ìë™ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:', error)
    })
    
    res.json({
      success: true,
      message: 'ìë™ í•™ìŠµì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤',
      process_id: trainingProcess.pid,
      job_id: job_id
    })
    
  } catch (error) {
    console.error('âŒ ìë™ í•™ìŠµ ì‹¤í–‰ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// í•™ìŠµ ì‘ì—… ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸ë“¤
// í•™ìŠµ ì‘ì—… ëª©ë¡ ì¡°íšŒ
app.get('/api/synthetic/training/jobs', async (req, res) => {
  try {
    console.log('ğŸ“‹ í•™ìŠµ ì‘ì—… ëª©ë¡ ì¡°íšŒ')
    
    // í•™ìŠµ ì‘ì—… ëª©ë¡ ì¡°íšŒ (ì‹¤ì œ êµ¬í˜„ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ)
    const jobs = await getTrainingJobs()
    
    res.json({
      success: true,
      jobs: jobs
    })
  } catch (error) {
    console.error('âŒ í•™ìŠµ ì‘ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// í•™ìŠµ ì‘ì—… ìƒíƒœ ì¡°íšŒ
app.get('/api/synthetic/training/jobs/:jobId/status', async (req, res) => {
  try {
    const { jobId } = req.params
    console.log(`ğŸ“Š í•™ìŠµ ì‘ì—… ${jobId} ìƒíƒœ ì¡°íšŒ`)
    
    const jobStatus = await getTrainingJobStatus(jobId)
    
    res.json({
      success: true,
      job: jobStatus
    })
  } catch (error) {
    console.error('âŒ í•™ìŠµ ì‘ì—… ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// í•™ìŠµ ì‘ì—… ì¬ì‹œë„
app.post('/api/synthetic/training/jobs/:jobId/retry', async (req, res) => {
  try {
    const { jobId } = req.params
    console.log(`ğŸ”„ í•™ìŠµ ì‘ì—… ${jobId} ì¬ì‹œë„`)
    
    const result = await retryTrainingJob(jobId)
    
    res.json({
      success: true,
      message: 'í•™ìŠµ ì‘ì—… ì¬ì‹œë„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤',
      result: result
    })
  } catch (error) {
    console.error('âŒ í•™ìŠµ ì‘ì—… ì¬ì‹œë„ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// í•™ìŠµ ì‘ì—… ì·¨ì†Œ
app.post('/api/synthetic/training/jobs/:jobId/cancel', async (req, res) => {
  try {
    const { jobId } = req.params
    console.log(`â¹ï¸ í•™ìŠµ ì‘ì—… ${jobId} ì·¨ì†Œ`)
    
    const result = await cancelTrainingJob(jobId)
    
    res.json({
      success: true,
      message: 'í•™ìŠµ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤',
      result: result
    })
  } catch (error) {
    console.error('âŒ í•™ìŠµ ì‘ì—… ì·¨ì†Œ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ===== Render Queue ê´€ë¦¬ API =====

// Render Queue ìƒíƒœ ì¡°íšŒ
app.get('/api/synthetic/queue/status', async (req, res) => {
  try {
    console.log('ğŸ“Š Render Queue ìƒíƒœ ì¡°íšŒ')
    // Supabase ê·¸ë£¹ ì§‘ê³„ í˜¸í™˜ ì´ìŠˆë¥¼ í”¼í•˜ê¸° ìœ„í•´ ìƒíƒœë³„ ê°œë³„ ì¹´ìš´íŠ¸ë¡œ ê³„ì‚°
    const safeCount = async (filterStatus) => {
      try {
        let query = supabase
          .from('render_queue')
          .select('*', { count: 'exact', head: true })
        if (filterStatus) query = query.eq('status', filterStatus)
        const { count, error } = await query
        if (error) throw error
        return count || 0
      } catch (e) {
        console.warn('Render Queue ì¹´ìš´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨(0ìœ¼ë¡œ ëŒ€ì²´):', e?.message || e)
        return 0
      }
    }

    const [pending, processing, completed, failed, total] = await Promise.all([
      safeCount('pending'),
      safeCount('processing'),
      safeCount('completed'),
      safeCount('failed'),
      safeCount(null)
    ])

    const stats = { pending, processing, completed, failed, total }

    res.json({
      success: true,
      stats,
      lastUpdated: new Date().toISOString()
    })
  } catch (error) {
    console.error('Render Queue ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error)
    // í´ë°±: 500 ëŒ€ì‹  ì•ˆì „í•œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‘ë‹µí•˜ì—¬ UIê°€ ë™ì‘í•˜ë„ë¡ ìœ ì§€
    res.json({
      success: true,
      stats: { pending: 0, processing: 0, completed: 0, failed: 0, total: 0 },
      lastUpdated: new Date().toISOString(),
      warning: error?.message || String(error)
    })
  }
})

// Render Queue ì‘ì—… ëª©ë¡ ì¡°íšŒ
app.get('/api/synthetic/queue/tasks', async (req, res) => {
  try {
    const { status = 'pending', limit = 50 } = req.query
    console.log(`ğŸ“‹ Render Queue ì‘ì—… ëª©ë¡ ì¡°íšŒ: status=${status}, limit=${limit}`)
    
    let query = supabase
      .from('render_queue')
      .select('*')
      .order('created_at', { ascending: false })
      .limit(parseInt(limit))
    
    if (status !== 'all') {
      query = query.eq('status', status)
    }
    
    const { data: tasks, error } = await query
    
    if (error) {
      throw error
    }
    
    res.json({
      success: true,
      tasks: tasks || [],
      count: tasks?.length || 0
    })
  } catch (error) {
    console.error('Render Queue ì‘ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      message: 'Render Queue ì‘ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨',
      error: error.message
    })
  }
})

// ì‹¤íŒ¨í•œ ì‘ì—… ì¬ì²˜ë¦¬ íŠ¸ë¦¬ê±°
app.post('/api/synthetic/queue/process', async (req, res) => {
  try {
    console.log('ğŸ”„ ì‹¤íŒ¨í•œ ì‘ì—… ì¬ì²˜ë¦¬ íŠ¸ë¦¬ê±°')
    
    // Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
    const process = spawn('python', [
      path.join(__dirname, '..', 'scripts', 'render_ldraw_to_supabase.py'),
      '--process-failed-queue'
    ], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe']
    })
    
    let output = ''
    let errorOutput = ''
    
    process.stdout.on('data', (data) => {
      output += data.toString()
      console.log('ì¬ì²˜ë¦¬ ì¶œë ¥:', data.toString())
    })
    
    process.stderr.on('data', (data) => {
      errorOutput += data.toString()
      console.error('ì¬ì²˜ë¦¬ ì—ëŸ¬:', data.toString())
    })
    
    process.on('close', (code) => {
      if (code === 0) {
        res.json({
          success: true,
          message: 'ì‹¤íŒ¨í•œ ì‘ì—… ì¬ì²˜ë¦¬ ì™„ë£Œ',
          output: output.trim()
        })
      } else {
        res.status(500).json({
          success: false,
          message: 'ì‹¤íŒ¨í•œ ì‘ì—… ì¬ì²˜ë¦¬ ì‹¤íŒ¨',
          error: errorOutput.trim(),
          output: output.trim()
        })
      }
    })
    
    process.on('error', (error) => {
      console.error('ì¬ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨:', error)
      res.status(500).json({
        success: false,
        message: 'ì¬ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨',
        error: error.message
      })
    })
    
  } catch (error) {
    console.error('ì‹¤íŒ¨í•œ ì‘ì—… ì¬ì²˜ë¦¬ íŠ¸ë¦¬ê±° ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      message: 'ì‹¤íŒ¨í•œ ì‘ì—… ì¬ì²˜ë¦¬ íŠ¸ë¦¬ê±° ì‹¤íŒ¨',
      error: error.message
    })
  }
})

// ===== ì—ëŸ¬ ë³µêµ¬ ë¡œê·¸ API =====

// ì—ëŸ¬ ë³µêµ¬ ë¡œê·¸ ì¡°íšŒ
app.get('/api/synthetic/logs/error-recovery', async (req, res) => {
  try {
    const { 
      errorType = 'all', 
      limit = 100, 
      offset = 0,
      startDate,
      endDate 
    } = req.query
    
    console.log(`ğŸ“‹ ì—ëŸ¬ ë³µêµ¬ ë¡œê·¸ ì¡°íšŒ: errorType=${errorType}, limit=${limit}`)
    
    let query = supabase
      .from('operation_logs')
      .select('*')
      .eq('metadata->>log_type', 'error_recovery')
      .order('timestamp', { ascending: false })
      .range(parseInt(offset), parseInt(offset) + parseInt(limit) - 1)
    
    // ë‚ ì§œ í•„í„°ë§
    if (startDate) {
      query = query.gte('timestamp', startDate)
    }
    if (endDate) {
      query = query.lte('timestamp', endDate)
    }
    
    const { data: logs, error } = await query
    
    if (error) {
      throw error
    }
    
    // ì—ëŸ¬ íƒ€ì…ë³„ í•„í„°ë§
    let filteredLogs = logs || []
    if (errorType !== 'all') {
      filteredLogs = filteredLogs.filter(log => 
        log.metadata?.error_type === errorType
      )
    }
    
    res.json({
      success: true,
      logs: filteredLogs,
      count: filteredLogs.length,
      total: logs?.length || 0
    })
  } catch (error) {
    console.error('ì—ëŸ¬ ë³µêµ¬ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      message: 'ì—ëŸ¬ ë³µêµ¬ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨',
      error: error.message
    })
  }
})

// ì—ëŸ¬ ë³µêµ¬ ë¡œê·¸ í†µê³„
app.get('/api/synthetic/logs/error-recovery/stats', async (req, res) => {
  try {
    const { days = 7 } = req.query
    console.log(`ğŸ“Š ì—ëŸ¬ ë³µêµ¬ ë¡œê·¸ í†µê³„: ${days}ì¼`)
    
    const startDate = new Date()
    startDate.setDate(startDate.getDate() - parseInt(days))
    
    const { data: logs, error } = await supabase
      .from('operation_logs')
      .select('metadata, timestamp')
      .eq('metadata->>log_type', 'error_recovery')
      .gte('timestamp', startDate.toISOString())
    
    if (error) {
      throw error
    }
    
    // ì—ëŸ¬ íƒ€ì…ë³„ í†µê³„
    const errorTypeStats = {}
    const dailyStats = {}
    
    logs?.forEach(log => {
      const errorType = log.metadata?.error_type || 'unknown'
      const date = log.timestamp.split('T')[0]
      
      // ì—ëŸ¬ íƒ€ì…ë³„ ì¹´ìš´íŠ¸
      errorTypeStats[errorType] = (errorTypeStats[errorType] || 0) + 1
      
      // ì¼ë³„ ì¹´ìš´íŠ¸
      dailyStats[date] = (dailyStats[date] || 0) + 1
    })
    
    res.json({
      success: true,
      stats: {
        totalErrors: logs?.length || 0,
        errorTypeStats,
        dailyStats,
        period: `${days}ì¼`
      }
    })
  } catch (error) {
    console.error('ì—ëŸ¬ ë³µêµ¬ ë¡œê·¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      message: 'ì—ëŸ¬ ë³µêµ¬ ë¡œê·¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨',
      error: error.message
    })
  }
})

// í•™ìŠµ ì‘ì—… ëª©ë¡ ì¡°íšŒ í•¨ìˆ˜
const getTrainingJobs = async () => {
  try {
    // ì‹¤ì œ êµ¬í˜„ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
    // í˜„ì¬ëŠ” íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì¡°íšŒ
    const fs = await import('fs')
    const path = await import('path')
    
    const jobsFile = path.join(__dirname, '..', 'logs', 'training_jobs.json')
    if (fs.existsSync(jobsFile)) {
      const data = fs.readFileSync(jobsFile, 'utf8')
      return JSON.parse(data)
    }
    
    return []
  } catch (error) {
    console.error('í•™ìŠµ ì‘ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error)
    return []
  }
}

// í•™ìŠµ ì‘ì—… ìƒíƒœ ì¡°íšŒ í•¨ìˆ˜
const getTrainingJobStatus = async (jobId) => {
  try {
    const jobs = await getTrainingJobs()
    return jobs.find(job => job.id === jobId) || null
  } catch (error) {
    console.error('í•™ìŠµ ì‘ì—… ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error)
    return null
  }
}

// í•™ìŠµ ì‘ì—… ì¬ì‹œë„ í•¨ìˆ˜
const retryTrainingJob = async (jobId) => {
  try {
    console.log(`ğŸ”„ í•™ìŠµ ì‘ì—… ${jobId} ì¬ì‹œë„ ì‹œì‘`)
    
    // ì‘ì—… ìƒíƒœë¥¼ pendingìœ¼ë¡œ ë³€ê²½
    const fs = await import('fs')
    const path = await import('path')
    
    const jobsFile = path.join(__dirname, '..', 'logs', 'training_jobs.json')
    if (fs.existsSync(jobsFile)) {
      const jobs = JSON.parse(fs.readFileSync(jobsFile, 'utf8'))
      const jobIndex = jobs.findIndex(job => job.id === jobId)
      
      if (jobIndex !== -1) {
        jobs[jobIndex].status = 'pending'
        jobs[jobIndex].updated_at = new Date().toISOString()
        
        fs.writeFileSync(jobsFile, JSON.stringify(jobs, null, 2))
        console.log(`âœ… í•™ìŠµ ì‘ì—… ${jobId} ì¬ì‹œë„ ì„¤ì • ì™„ë£Œ`)
      }
    }
    
    return { jobId, status: 'pending' }
  } catch (error) {
    console.error('í•™ìŠµ ì‘ì—… ì¬ì‹œë„ ì‹¤íŒ¨:', error)
    throw error
  }
}

// í•™ìŠµ ì‘ì—… ì·¨ì†Œ í•¨ìˆ˜
const cancelTrainingJob = async (jobId) => {
  try {
    console.log(`â¹ï¸ í•™ìŠµ ì‘ì—… ${jobId} ì·¨ì†Œ ì‹œì‘`)
    
    // ì‘ì—… ìƒíƒœë¥¼ cancelledë¡œ ë³€ê²½
    const fs = await import('fs')
    const path = await import('path')
    
    const jobsFile = path.join(__dirname, '..', 'logs', 'training_jobs.json')
    if (fs.existsSync(jobsFile)) {
      const jobs = JSON.parse(fs.readFileSync(jobsFile, 'utf8'))
      const jobIndex = jobs.findIndex(job => job.id === jobId)
      
      if (jobIndex !== -1) {
        jobs[jobIndex].status = 'cancelled'
        jobs[jobIndex].cancelled_at = new Date().toISOString()
        jobs[jobIndex].updated_at = new Date().toISOString()
        
        fs.writeFileSync(jobsFile, JSON.stringify(jobs, null, 2))
        console.log(`âœ… í•™ìŠµ ì‘ì—… ${jobId} ì·¨ì†Œ ì™„ë£Œ`)
      }
    }
    
    return { jobId, status: 'cancelled' }
  } catch (error) {
    console.error('í•™ìŠµ ì‘ì—… ì·¨ì†Œ ì‹¤íŒ¨:', error)
    throw error
  }
}

// fetch polyfill (Node.js í™˜ê²½) - ì„œë²„ ì‹œì‘ ì „ì— ì„ ì–¸
let fetchFn
(async () => {
  try {
    // Node.js 18+ has native fetch
    if (globalThis.fetch) {
      fetchFn = globalThis.fetch
    } else {
      const { default: nodeFetch } = await import('node-fetch')
      fetchFn = nodeFetch
    }
  } catch {
    // node-fetchê°€ ì—†ìœ¼ë©´ HTTP ëª¨ë“ˆ ì‚¬ìš©
    const http = await import('http')
    fetchFn = async (url, options) => {
      return new Promise((resolve, reject) => {
        try {
          const urlObj = new URL(url)
          const request = http.request({
            hostname: urlObj.hostname,
            port: urlObj.port || 80,
            path: urlObj.pathname,
            method: options?.method || 'GET',
            headers: options?.headers || {}
          }, (response) => {
            let data = ''
            response.on('data', chunk => data += chunk)
            response.on('end', () => {
              resolve({
                ok: response.statusCode >= 200 && response.statusCode < 300,
                status: response.statusCode,
                json: async () => JSON.parse(data),
                text: async () => data
              })
            })
          })
          request.on('error', reject)
          if (options?.body) {
            request.write(options.body)
          }
          request.end()
        } catch (error) {
          reject(error)
        }
      })
    }
  }
})()

// ğŸ”§ ìˆ˜ì •ë¨: ì„œë²„ ì‹œì‘ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
startServer().then(async () => {
  // fetchFnì´ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
  while (!fetchFn) {
    await new Promise(resolve => setTimeout(resolve, 100))
  }
  
  // ì„œë²„ ì‹œì‘ ì™„ë£Œ í›„ ì €ì¥ëœ ì‘ì—… ë³µêµ¬ ì‹œë„
  try {
    if (fs.existsSync(ACTIVE_JOBS_STATE_FILE)) {
      const data = fs.readFileSync(ACTIVE_JOBS_STATE_FILE, 'utf8')
      const savedJobs = JSON.parse(data)
      
      // ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜ ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…ë§Œ ë³µêµ¬
      const recoverableJobs = savedJobs.filter(job => 
        job.status === 'running' || job.status === 'pending'
      )
      
      if (recoverableJobs.length > 0) {
        console.log(`ğŸ”„ ë³µêµ¬ ê°€ëŠ¥í•œ ì‘ì—… ë°œê²¬: ${recoverableJobs.length}ê°œ`)
        console.log('ğŸ’¡ ì‘ì—…ì„ ìˆ˜ë™ìœ¼ë¡œ ì¬ê°œí•˜ë ¤ë©´: npm run recover:resume')
        
        // 30ì´ˆ í›„ ìë™ ë³µêµ¬ ì‹œë„ (ì„œë²„ê°€ ì™„ì „íˆ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°)
        setTimeout(async () => {
          for (const job of recoverableJobs) {
            try {
              console.log(`ğŸ”„ ì‘ì—… ì¬ê°œ ì‹œë„: ${job.id}`)
              
              const resumeResponse = await fetchFn('http://localhost:3011/api/synthetic/start-rendering', {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  mode: job.config.mode,
                  partId: job.config.partId,
                  setNum: job.config.setNum || job.config.setNumber,
                  imageCount: job.config.imageCount,
                  quality: job.config.quality,
                  background: job.config.background,
                  resolution: job.config.resolution,
                  targetFill: job.config.targetFill,
                  elementId: job.config.elementId
                })
              })
              
              if (resumeResponse.ok) {
                const result = await resumeResponse.json()
                console.log(`âœ… ì‘ì—… ì¬ê°œ ì™„ë£Œ: ${job.id} -> ${result.jobId}`)
              } else {
                console.warn(`âš ï¸ ì‘ì—… ì¬ê°œ ì‹¤íŒ¨: ${job.id}`)
              }
              
              await new Promise(resolve => setTimeout(resolve, 1000))
            } catch (error) {
              console.error(`âŒ ì‘ì—… ì¬ê°œ ì˜¤ë¥˜ (${job.id}):`, error.message)
            }
          }
        }, 30000) // 30ì´ˆ ëŒ€ê¸°
      }
    }
  } catch (error) {
    console.error('âŒ ì‘ì—… ë³µêµ¬ ì‹¤íŒ¨:', error.message)
  }
}).catch(error => {
  console.error('âŒ [ì„œë²„ ì‹œì‘ ì‹¤íŒ¨]:', error)
  console.error('ìŠ¤íƒ:', error.stack)
  // ì „ì—­ í•¸ë“¤ëŸ¬ê°€ ì²˜ë¦¬í•˜ì§€ë§Œ, ì—¬ê¸°ì„œë„ ëª…ì‹œì ìœ¼ë¡œ ì²˜ë¦¬
})

// Express ì•± ë ˆë²¨ ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì¶”ê°€
app.use((err, req, res, next) => {
  console.error('âŒ [Express ì—ëŸ¬ í•¸ë“¤ëŸ¬]:', err.message)
  console.error('ìŠ¤íƒ:', err.stack)
  res.status(err.status || 500).json({
    success: false,
    error: err.message || 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
    // í”„ë¡œë•ì…˜ì—ì„œëŠ” ìƒì„¸ ìŠ¤íƒ ì¶”ì  ì œê±°
    ...(process.env.NODE_ENV === 'development' && { stack: err.stack })
  })
})

// 404 í•¸ë“¤ëŸ¬
app.use((req, res) => {
  res.status(404).json({
    success: false,
    error: 'ìš”ì²­í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
    path: req.path
  })
})

export default app
