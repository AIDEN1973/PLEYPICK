/**
 * ìˆ˜ë™ ì—…ë¡œë“œ API ì„œë²„
 * ì‹¤íŒ¨í•œ ë Œë”ë§ íŒŒì¼ë“¤ì„ ìˆ˜ë™ìœ¼ë¡œ Supabaseì— ì—…ë¡œë“œ
 */

const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs').promises;
const { createClient } = require('@supabase/supabase-js');
const fsSync = require('fs');

const app = express();

// í¬íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œì—ì„œ í¬íŠ¸ ê°€ì ¸ì˜¤ê¸°
let PORT;
try {
  // í¬íŠ¸ ì„¤ì • íŒŒì¼ì—ì„œ ì½ê¸°
  const portConfigPath = path.join(__dirname, '..', '.port-config.json');
  if (fsSync.existsSync(portConfigPath)) {
    const portConfig = JSON.parse(fsSync.readFileSync(portConfigPath, 'utf8'));
    PORT = portConfig.manualUploadApi;
    console.log(`ğŸ“„ í¬íŠ¸ ì„¤ì • íŒŒì¼ì—ì„œ ì½ê¸°: ${PORT}`);
  } else {
    console.log('ğŸ“„ í¬íŠ¸ ì„¤ì • íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©');
  }
} catch (error) {
  console.warn('âš ï¸ í¬íŠ¸ ì„¤ì • íŒŒì¼ ì½ê¸° ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©:', error.message);
}

// ê¸°ë³¸ê°’ ì„¤ì •
PORT = PORT || process.env.MANUAL_UPLOAD_PORT || 3030;

// Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
const supabaseUrl = process.env.VITE_SUPABASE_URL;
const supabaseKey = process.env.VITE_SUPABASE_SERVICE_ROLE || process.env.VITE_SUPABASE_ANON_KEY;

console.log('ğŸ” í™˜ê²½ ë³€ìˆ˜ í™•ì¸:');
console.log(`  - SUPABASE_URL: ${supabaseUrl ? 'ì„¤ì •ë¨' : 'ì—†ìŒ'}`);
console.log(`  - SUPABASE_KEY: ${supabaseKey ? 'ì„¤ì •ë¨' : 'ì—†ìŒ'}`);

if (!supabaseUrl || !supabaseKey) {
  console.error('âŒ Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
  console.error('í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜: VITE_SUPABASE_URL, VITE_SUPABASE_SERVICE_ROLE ë˜ëŠ” VITE_SUPABASE_ANON_KEY');
  process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseKey);

// ë¯¸ë“¤ì›¨ì–´
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// íŒŒì¼ ì—…ë¡œë“œ ì„¤ì •
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    const uploadDir = path.join(__dirname, '..', 'temp', 'manual_uploads');
    cb(null, uploadDir);
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);
    cb(null, file.fieldname + '-' + uniqueSuffix + path.extname(file.originalname));
  }
});

const upload = multer({ 
  storage: storage,
  limits: {
    fileSize: 50 * 1024 * 1024 // 50MB ì œí•œ
  }
});

// ì‹¤íŒ¨í•œ ì—…ë¡œë“œ ëª©ë¡ ì¡°íšŒ
app.get('/api/manual-upload/failed-uploads', async (req, res) => {
  try {
    const trackingFile = path.join(__dirname, '..', 'scripts', 'failed_uploads.json');
    
    try {
      const data = await fs.readFile(trackingFile, 'utf8');
      const failedUploads = JSON.parse(data);
      
      // ìƒíƒœë³„ í•„í„°ë§
      const status = req.query.status;
      const filteredUploads = status 
        ? failedUploads.filter(upload => upload.status === status)
        : failedUploads;
      
      res.json({
        success: true,
        data: filteredUploads,
        total: filteredUploads.length
      });
    } catch (error) {
      if (error.code === 'ENOENT') {
        res.json({
          success: true,
          data: [],
          total: 0,
          message: 'No failed uploads found'
        });
      } else {
        throw error;
      }
    }
  } catch (error) {
    console.error('Failed to get failed uploads:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ì‹¤íŒ¨ ì´ë²¤íŠ¸ ê¸°ë¡ (ìŠ¤í¬ë¦½íŠ¸ì—ì„œ í˜¸ì¶œ)
app.post('/api/manual-upload/failed-uploads', async (req, res) => {
  try {
    const trackingFile = path.join(__dirname, '..', 'scripts', 'failed_uploads.json');
    const body = req.body || {};
    const required = ['part_id', 'element_id', 'unique_id', 'error_reason'];
    for (const k of required) {
      if (!body[k]) {
        return res.status(400).json({ success: false, error: `Missing field: ${k}` });
      }
    }

    // ê¸°ì¡´ ëª©ë¡ ì½ê¸°
    let entries = [];
    try {
      const data = await fs.readFile(trackingFile, 'utf8');
      entries = JSON.parse(data);
    } catch (e) {
      entries = [];
    }

    const nowIso = new Date().toISOString();
    const entry = {
      id: `${body.element_id}_${body.unique_id}_${Date.now()}`,
      part_id: body.part_id,
      element_id: body.element_id,
      unique_id: body.unique_id,
      status: body.status || 'failed',
      failed_at: nowIso,
      error_reason: body.error_reason,
      retry_count: body.retry_count || 0,
      local_paths: body.local_paths || {},
    };

    entries.push(entry);
    await fs.writeFile(trackingFile, JSON.stringify(entries, null, 2));

    res.json({ success: true, data: entry });
  } catch (error) {
    console.error('Failed to write failed upload:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// ì‹¤íŒ¨í•œ ì—…ë¡œë“œ í†µê³„ ì¡°íšŒ
app.get('/api/manual-upload/statistics', async (req, res) => {
  try {
    const trackingFile = path.join(__dirname, '..', 'scripts', 'failed_uploads.json');
    
    try {
      const data = await fs.readFile(trackingFile, 'utf8');
      const failedUploads = JSON.parse(data);
      
      const statistics = {
        total: failedUploads.length,
        by_status: {}
      };
      
      failedUploads.forEach(upload => {
        const status = upload.status || 'unknown';
        statistics.by_status[status] = (statistics.by_status[status] || 0) + 1;
      });
      
      res.json({
        success: true,
        data: statistics
      });
    } catch (error) {
      if (error.code === 'ENOENT') {
        res.json({
          success: true,
          data: {
            total: 0,
            by_status: {}
          }
        });
      } else {
        throw error;
      }
    }
  } catch (error) {
    console.error('Failed to get statistics:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ë‹¨ì¼ íŒŒì¼ ìˆ˜ë™ ì—…ë¡œë“œ
app.post('/api/manual-upload/upload-file', upload.single('file'), async (req, res) => {
  try {
    const { entryId, fileType, elementId, uniqueId } = req.body;
    
    if (!req.file) {
      return res.status(400).json({
        success: false,
        error: 'No file provided'
      });
    }
    
    if (!entryId || !fileType || !elementId || !uniqueId) {
      return res.status(400).json({
        success: false,
        error: 'Missing required parameters: entryId, fileType, elementId, uniqueId'
      });
    }
    
    // íŒŒì¼ ì½ê¸°
    const fileBuffer = await fs.readFile(req.file.path);
    
    // Supabase ê²½ë¡œ ìƒì„±
    const supabasePath = `synthetic/${elementId}/${uniqueId}${fileType === 'e2_metadata' ? '_e2' : ''}.${getFileExtension(fileType)}`;
    
    // Supabase ì—…ë¡œë“œ
    const result = await supabase.storage
      .from('lego-synthetic')
      .upload(supabasePath, fileBuffer, {
        contentType: getContentType(fileType),
        upsert: true,
        cacheControl: 'public, max-age=31536000'
      });
    
    if (result.error) {
      throw new Error(result.error.message);
    }
    
    // ì„ì‹œ íŒŒì¼ ì‚­ì œ
    await fs.unlink(req.file.path);
    
    res.json({
      success: true,
      data: {
        entryId,
        fileType,
        supabasePath,
        publicUrl: supabase.storage.from('lego-synthetic').getPublicUrl(supabasePath).data.publicUrl
      }
    });
    
  } catch (error) {
    console.error('Manual upload failed:', error);
    
    // ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if (req.file && req.file.path) {
      try {
        await fs.unlink(req.file.path);
      } catch (cleanupError) {
        console.error('Failed to cleanup temp file:', cleanupError);
      }
    }
    
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ì „ì²´ í•­ëª© ì¬ì—…ë¡œë“œ
app.post('/api/manual-upload/retry-entry', async (req, res) => {
  try {
    const { entryId } = req.body;
    
    if (!entryId) {
      return res.status(400).json({
        success: false,
        error: 'Missing entryId'
      });
    }
    
    // ì¶”ì  íŒŒì¼ì—ì„œ í•­ëª© ì¡°íšŒ
    const trackingFile = path.join(__dirname, '..', 'scripts', 'failed_uploads.json');
    const data = await fs.readFile(trackingFile, 'utf8');
    const failedUploads = JSON.parse(data);
    
    const entry = failedUploads.find(upload => upload.id === entryId);
    if (!entry) {
      return res.status(404).json({
        success: false,
        error: 'Entry not found'
      });
    }
    
    // ë¡œì»¬ íŒŒì¼ ì¡´ì¬ í™•ì¸
    const localPaths = entry.local_paths;
    const missingFiles = [];
    
    for (const [fileType, localPath] of Object.entries(localPaths)) {
      try {
        await fs.access(localPath);
      } catch (error) {
        missingFiles.push({ fileType, localPath });
      }
    }
    
    if (missingFiles.length > 0) {
      return res.status(400).json({
        success: false,
        error: 'Some local files are missing',
        missingFiles
      });
    }
    
    // íŒŒì¼ë³„ ì—…ë¡œë“œ ì‹œë„
    const uploadResults = [];
    
    for (const [fileType, localPath] of Object.entries(localPaths)) {
      try {
        const fileBuffer = await fs.readFile(localPath);
        const supabasePath = entry.supabase_paths[fileType];
        
        const result = await supabase.storage
          .from('lego-synthetic')
          .upload(supabasePath, fileBuffer, {
            contentType: getContentType(fileType),
            upsert: true,
            cacheControl: 'public, max-age=31536000'
          });
        
        if (result.error) {
          uploadResults.push({
            fileType,
            success: false,
            error: result.error.message
          });
        } else {
          uploadResults.push({
            fileType,
            success: true,
            supabasePath,
            publicUrl: supabase.storage.from('lego-synthetic').getPublicUrl(supabasePath).data.publicUrl
          });
        }
      } catch (error) {
        uploadResults.push({
          fileType,
          success: false,
          error: error.message
        });
      }
    }
    
    // ì„±ê³µí•œ íŒŒì¼ ìˆ˜
    const successCount = uploadResults.filter(result => result.success).length;
    const totalCount = uploadResults.length;
    
    // ì¶”ì  íŒŒì¼ ì—…ë°ì´íŠ¸
    if (successCount === totalCount) {
      // ëª¨ë“  íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ
      const updatedUploads = failedUploads.map(upload => 
        upload.id === entryId 
          ? { ...upload, status: 'success', success_at: new Date().toISOString() }
          : upload
      );
      
      await fs.writeFile(trackingFile, JSON.stringify(updatedUploads, null, 2));
    } else {
      // ì¼ë¶€ ì‹¤íŒ¨
      const updatedUploads = failedUploads.map(upload => 
        upload.id === entryId 
          ? { ...upload, status: 'partial_success', retry_results: uploadResults }
          : upload
      );
      
      await fs.writeFile(trackingFile, JSON.stringify(updatedUploads, null, 2));
    }
    
    res.json({
      success: true,
      data: {
        entryId,
        uploadResults,
        successCount,
        totalCount,
        allSuccessful: successCount === totalCount
      }
    });
    
  } catch (error) {
    console.error('Retry entry failed:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// í•­ëª© ìƒíƒœ ì—…ë°ì´íŠ¸
app.put('/api/manual-upload/update-status', async (req, res) => {
  try {
    const { entryId, status, note } = req.body;
    
    if (!entryId || !status) {
      return res.status(400).json({
        success: false,
        error: 'Missing entryId or status'
      });
    }
    
    const trackingFile = path.join(__dirname, '..', 'scripts', 'failed_uploads.json');
    const data = await fs.readFile(trackingFile, 'utf8');
    const failedUploads = JSON.parse(data);
    
    const entryIndex = failedUploads.findIndex(upload => upload.id === entryId);
    if (entryIndex === -1) {
      return res.status(404).json({
        success: false,
        error: 'Entry not found'
      });
    }
    
    // ìƒíƒœ ì—…ë°ì´íŠ¸
    failedUploads[entryIndex].status = status;
    failedUploads[entryIndex].updated_at = new Date().toISOString();
    
    if (note) {
      failedUploads[entryIndex].note = note;
    }
    
    await fs.writeFile(trackingFile, JSON.stringify(failedUploads, null, 2));
    
    res.json({
      success: true,
      data: {
        entryId,
        status,
        updated_at: failedUploads[entryIndex].updated_at
      }
    });
    
  } catch (error) {
    console.error('Update status failed:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// í•­ëª© ì‚­ì œ
app.delete('/api/manual-upload/delete-entry', async (req, res) => {
  try {
    const { entryId } = req.body;
    
    if (!entryId) {
      return res.status(400).json({
        success: false,
        error: 'Missing entryId'
      });
    }
    
    const trackingFile = path.join(__dirname, '..', 'scripts', 'failed_uploads.json');
    const data = await fs.readFile(trackingFile, 'utf8');
    const failedUploads = JSON.parse(data);
    
    const filteredUploads = failedUploads.filter(upload => upload.id !== entryId);
    
    if (filteredUploads.length === failedUploads.length) {
      return res.status(404).json({
        success: false,
        error: 'Entry not found'
      });
    }
    
    await fs.writeFile(trackingFile, JSON.stringify(filteredUploads, null, 2));
    
    res.json({
      success: true,
      data: {
        entryId,
        deleted: true
      }
    });
    
  } catch (error) {
    console.error('Delete entry failed:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// í—¬í¼ í•¨ìˆ˜ë“¤
function getFileExtension(fileType) {
  const extensions = {
    'image': 'webp',
    'annotation': 'txt',
    'metadata': 'json',
    'e2_metadata': 'json'
  };
  return extensions[fileType] || 'bin';
}

function getContentType(fileType) {
  const contentTypes = {
    'image': 'image/webp',
    'annotation': 'text/plain',
    'metadata': 'application/json',
    'e2_metadata': 'application/json'
  };
  return contentTypes[fileType] || 'application/octet-stream';
}

// ì„œë²„ ì‹œì‘
app.listen(PORT, () => {
  console.log(`ğŸš€ Manual Upload API server running on port ${PORT}`);
  console.log(`ğŸ“ Tracking file: ${path.join(__dirname, '..', 'scripts', 'failed_uploads.json')}`);
});

module.exports = app;
