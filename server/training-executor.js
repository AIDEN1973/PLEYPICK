#!/usr/bin/env node
/**
 * ğŸ§  BrickBox í•™ìŠµ ì‹¤í–‰ ì„œë²„
 * í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì§ì ‘ í•™ìŠµì„ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” API ì„œë²„
 */

import express from 'express'
import cors from 'cors'
import { spawn } from 'child_process'
import { createClient } from '@supabase/supabase-js'
import path from 'path'
import { fileURLToPath } from 'url'
import fs from 'fs'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

const app = express()

// CORS ì„¤ì •
app.use(cors({
  origin: ['http://localhost:3000', 'http://127.0.0.1:3000'],
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization', 'X-Requested-With']
}))

app.use(express.json())

// Supabase í´ë¼ì´ì–¸íŠ¸ (Service Role Key ì‚¬ìš©)
const supabase = createClient(
  'https://npferbxuxocbfnfbpcnz.supabase.co',
  'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1OTQ3NDk4NSwiZXhwIjoyMDc1MDUwOTg1fQ.pPWhWrb4QBC-DT4dd6Y1p-LlHNd9UTKef3SHEXUDp00'
)

// ì‹¤í–‰ ì¤‘ì¸ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬
const runningProcesses = new Map()

// ì„œë²„ ì‹œì‘ ì‹œ ì¤‘ë‹¨ëœ í•™ìŠµ ì‘ì—… ë³µêµ¬
async function recoverInterruptedTrainings() {
  try {
    console.log('ğŸ”„ ì¤‘ë‹¨ëœ í•™ìŠµ ì‘ì—… ë³µêµ¬ ì¤‘...')
    
    // running/training ìƒíƒœì˜ ì‘ì—…ë“¤ ì¡°íšŒ
    const { data: interruptedJobs, error } = await supabase
      .from('training_jobs')
      .select('id, job_name, status, config, created_at')
      .in('status', ['running', 'training'])
      .order('created_at', { ascending: false })
    
    if (error) {
      console.error('âŒ ì¤‘ë‹¨ëœ í•™ìŠµ ì‘ì—… ì¡°íšŒ ì‹¤íŒ¨:', error)
      return
    }
    
    if (!interruptedJobs || interruptedJobs.length === 0) {
      console.log('âœ… ë³µêµ¬í•  ì¤‘ë‹¨ëœ í•™ìŠµ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤.')
      return
    }
    
    console.log(`ğŸ” ${interruptedJobs.length}ê°œì˜ ì¤‘ë‹¨ëœ í•™ìŠµ ì‘ì—… ë°œê²¬`)
    
    for (const job of interruptedJobs) {
      try {
        // ì‘ì—… ìƒíƒœë¥¼ failedë¡œ ì—…ë°ì´íŠ¸
        const { error: updateError } = await supabase
          .from('training_jobs')
          .update({
            status: 'failed',
            updated_at: new Date().toISOString(),
            error_message: 'ì„œë²„ ì¬ì‹œì‘ìœ¼ë¡œ ì¸í•œ í•™ìŠµ ì¤‘ë‹¨'
          })
          .eq('id', job.id)
        
        if (updateError) {
          console.error(`âŒ ì‘ì—… ${job.id} ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:`, updateError)
        } else {
          console.log(`âœ… ì‘ì—… ${job.id} (${job.job_name}) ìƒíƒœë¥¼ failedë¡œ ì—…ë°ì´íŠ¸`)
        }
      } catch (err) {
        console.error(`âŒ ì‘ì—… ${job.id} ë³µêµ¬ ì‹¤íŒ¨:`, err)
      }
    }
    
    console.log('ğŸ”„ ì¤‘ë‹¨ëœ í•™ìŠµ ì‘ì—… ë³µêµ¬ ì™„ë£Œ')
  } catch (error) {
    console.error('âŒ í•™ìŠµ ì‘ì—… ë³µêµ¬ ì¤‘ ì˜¤ë¥˜:', error)
  }
}

// í•™ìŠµ ì‹¤í–‰ API
app.post('/api/training/execute', async (req, res) => {
  try {
    const { 
      partId, 
      modelStage = 'stage1', 
      epochs = 50, 
      batchSize = 16, 
      imageSize = 640,
      device = 'cuda'
    } = req.body

    console.log(`ğŸš€ í•™ìŠµ ì‹¤í–‰ ìš”ì²­: ë¶€í’ˆ ${partId}, ë‹¨ê³„ ${modelStage}`)

    // í•™ìŠµ ì‘ì—… ìƒì„±
    const { data: trainingJob, error: jobError } = await supabase
      .from('training_jobs')
      .insert({
        job_name: `training_${partId}_${modelStage}_${Date.now()}`,
        status: 'pending',
        config: {
          partId,
          modelStage,
          epochs,
          batchSize,
          imageSize,
          device
        },
        created_at: new Date().toISOString()
      })
      .select()
      .single()

    if (jobError) {
      throw new Error(`í•™ìŠµ ì‘ì—… ìƒì„± ì‹¤íŒ¨: ${jobError.message}`)
    }

    // parts_masterì—ì„œ ì—˜ë¦¬ë¨¼íŠ¸ ID ì¡°íšŒ
    let elementId = partId
    try {
      const { data: partData } = await supabase
        .from('parts_master')
        .select('element_id')
        .eq('part_id', partId)
        .limit(1)
      
      if (partData && partData.length > 0) {
        elementId = partData[0].element_id
        console.log(`ğŸ”„ ë¶€í’ˆ ID ${partId} â†’ ì—˜ë¦¬ë¨¼íŠ¸ ID ${elementId} ë§¤í•‘ë¨`)
      }
    } catch (error) {
      console.warn('âš ï¸ ì—˜ë¦¬ë¨¼íŠ¸ ID ì¡°íšŒ ì‹¤íŒ¨, ë¶€í’ˆ ID ì‚¬ìš©:', error.message)
    }

            // í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (Python 3.11 ì‚¬ìš©)
            const scriptPath = path.join(__dirname, '..', 'scripts', 'local_yolo_training.py')
            const args = [
              '--part_id', elementId, // ì—˜ë¦¬ë¨¼íŠ¸ ID ì‚¬ìš©
              '--model_stage', modelStage,
              '--epochs', epochs.toString(),
              '--batch_size', batchSize.toString(),
              '--imgsz', imageSize.toString(),
              '--device', device,
              '--job_id', trainingJob.id.toString()
            ]

            console.log(`ğŸ“ ì‹¤í–‰ ëª…ë ¹: py -3.11 ${scriptPath} ${args.join(' ')}`)

            // Python 3.11 í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (GPU ê°€ì† ì§€ì›)
            const pythonProcess = spawn('py', ['-3.11', scriptPath, ...args], {
      cwd: path.join(__dirname, '..'),
      stdio: ['pipe', 'pipe', 'pipe']
    })

    // í”„ë¡œì„¸ìŠ¤ ID ì €ì¥
    runningProcesses.set(trainingJob.id, {
      process: pythonProcess,
      startTime: new Date(),
      partId,
      modelStage
    })

    // í•™ìŠµ ìƒíƒœë¥¼ 'training'ìœ¼ë¡œ ì—…ë°ì´íŠ¸
    await supabase
      .from('training_jobs')
      .update({ 
        status: 'training',
        started_at: new Date().toISOString()
      })
      .eq('id', trainingJob.id)

    // í”„ë¡œì„¸ìŠ¤ ì¶œë ¥ ì²˜ë¦¬
    pythonProcess.stdout.on('data', async (data) => {
      const output = data.toString()
      console.log(`[í•™ìŠµ ${trainingJob.id}] ${output}`)
      
      // ë©”íŠ¸ë¦­ íŒŒì‹± ë° ì €ì¥
      await parseAndSaveMetrics(trainingJob.id, output)
    })

    pythonProcess.stderr.on('data', (data) => {
      const error = data.toString()
      console.error(`[í•™ìŠµ ${trainingJob.id} ì˜¤ë¥˜] ${error}`)
    })

    pythonProcess.on('close', async (code) => {
      console.log(`[í•™ìŠµ ${trainingJob.id}] í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ, ì½”ë“œ: ${code}`)
      
      // í”„ë¡œì„¸ìŠ¤ ì œê±°
      runningProcesses.delete(trainingJob.id)
      
      // í•™ìŠµ ìƒíƒœ ì—…ë°ì´íŠ¸
      const finalStatus = code === 0 ? 'completed' : 'failed'
      await supabase
        .from('training_jobs')
        .update({
          status: finalStatus,
          completed_at: new Date().toISOString()
        })
        .eq('id', trainingJob.id)
    })

    pythonProcess.on('error', async (error) => {
      console.error(`[í•™ìŠµ ${trainingJob.id}] í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜:`, error)
      
      // í”„ë¡œì„¸ìŠ¤ ì œê±°
      runningProcesses.delete(trainingJob.id)
      
      // í•™ìŠµ ìƒíƒœë¥¼ 'failed'ë¡œ ì—…ë°ì´íŠ¸
      await supabase
        .from('training_jobs')
        .update({
          status: 'failed',
          completed_at: new Date().toISOString()
        })
        .eq('id', trainingJob.id)
    })

    res.json({
      success: true,
      jobId: trainingJob.id,
      message: 'í•™ìŠµì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤',
      processId: pythonProcess.pid
    })

  } catch (error) {
    console.error('âŒ í•™ìŠµ ì‹¤í–‰ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// í•™ìŠµ ì¤‘ì§€ API
app.post('/api/training/stop/:jobId', async (req, res) => {
  try {
    const { jobId } = req.params
    const processInfo = runningProcesses.get(parseInt(jobId))

    if (!processInfo) {
      return res.status(404).json({
        success: false,
        error: 'ì‹¤í–‰ ì¤‘ì¸ í•™ìŠµì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
      })
    }

    // í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
    processInfo.process.kill('SIGTERM')
    runningProcesses.delete(parseInt(jobId))

    // ìƒíƒœ ì—…ë°ì´íŠ¸
    await supabase
      .from('training_jobs')
      .update({
        status: 'stopped',
        completed_at: new Date().toISOString()
      })
      .eq('id', jobId)

    res.json({
      success: true,
      message: 'í•™ìŠµì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤'
    })

  } catch (error) {
    console.error('âŒ í•™ìŠµ ì¤‘ì§€ ì‹¤íŒ¨:', error)
    res.status(500).json({
      success: false,
      error: error.message
    })
  }
})

// ì‹¤í–‰ ì¤‘ì¸ í•™ìŠµ ëª©ë¡ API
app.get('/api/training/running', (req, res) => {
  const runningList = Array.from(runningProcesses.entries()).map(([jobId, info]) => ({
    jobId,
    partId: info.partId,
    modelStage: info.modelStage,
    startTime: info.startTime,
    pid: info.process.pid
  }))

  res.json({
    success: true,
    running: runningList
  })
})

// ë©”íŠ¸ë¦­ íŒŒì‹± ë° ì €ì¥ í•¨ìˆ˜
async function parseAndSaveMetrics(jobId, output) {
  try {
    // YOLO í•™ìŠµ ì¶œë ¥ì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ
    const metrics = {}
    
    // Box Loss ì¶”ì¶œ
    const boxLossMatch = output.match(/box_loss[:\s]+([\d.]+)/i)
    if (boxLossMatch) {
      metrics.box_loss = parseFloat(boxLossMatch[1])
    }

    // Seg Loss ì¶”ì¶œ
    const segLossMatch = output.match(/seg_loss[:\s]+([\d.]+)/i)
    if (segLossMatch) {
      metrics.seg_loss = parseFloat(segLossMatch[1])
    }

    // Cls Loss ì¶”ì¶œ
    const clsLossMatch = output.match(/cls_loss[:\s]+([\d.]+)/i)
    if (clsLossMatch) {
      metrics.cls_loss = parseFloat(clsLossMatch[1])
    }

    // DFL Loss ì¶”ì¶œ
    const dflLossMatch = output.match(/dfl_loss[:\s]+([\d.]+)/i)
    if (dflLossMatch) {
      metrics.dfl_loss = parseFloat(dflLossMatch[1])
    }

    // mAP50 ì¶”ì¶œ
    const map50Match = output.match(/mAP50[:\s]+([\d.]+)/i)
    if (map50Match) {
      metrics.map50 = parseFloat(map50Match[1])
    }

    // mAP50-95 ì¶”ì¶œ
    const map50_95Match = output.match(/mAP50-95[:\s]+([\d.]+)/i)
    if (map50_95Match) {
      metrics.map50_95 = parseFloat(map50_95Match[1])
    }

    // ì—í­ ì •ë³´ ì¶”ì¶œ
    const epochMatch = output.match(/(\d+)\/(\d+)/)
    if (epochMatch) {
      metrics.current_epoch = parseInt(epochMatch[1])
      metrics.total_epochs = parseInt(epochMatch[2])
    }

    // ë©”íŠ¸ë¦­ì´ ìˆìœ¼ë©´ ì €ì¥
    if (Object.keys(metrics).length > 0) {
      await supabase
        .from('training_metrics')
        .insert({
          job_id: jobId,
          ...metrics,
          created_at: new Date().toISOString()
        })

      // í•™ìŠµ ì‘ì—…ì˜ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
      if (metrics.current_epoch && metrics.total_epochs) {
        const progress = Math.round((metrics.current_epoch / metrics.total_epochs) * 100)
        await supabase
          .from('training_jobs')
          .update({
            progress: progress,
            current_epoch: metrics.current_epoch
          })
          .eq('id', jobId)
      }
    }

  } catch (error) {
    console.error('ë©”íŠ¸ë¦­ íŒŒì‹± ì‹¤íŒ¨:', error)
  }
}

// ì„œë²„ ì‹œì‘
const PORT = process.env.TRAINING_EXECUTOR_PORT || 3012

app.listen(PORT, async () => {
  console.log(`ğŸ§  BrickBox í•™ìŠµ ì‹¤í–‰ ì„œë²„ê°€ í¬íŠ¸ ${PORT}ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤`)
  console.log(`ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸: http://localhost:${PORT}/api/training/`)
  
  // ì„œë²„ ì‹œì‘ ì‹œ ì¤‘ë‹¨ëœ í•™ìŠµ ì‘ì—… ë³µêµ¬
  await recoverInterruptedTrainings()
})

// í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ ì‹¤í–‰ ì¤‘ì¸ í•™ìŠµë“¤ ì •ë¦¬
process.on('SIGINT', () => {
  console.log('\nğŸ›‘ ì„œë²„ ì¢…ë£Œ ì¤‘... ì‹¤í–‰ ì¤‘ì¸ í•™ìŠµë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤.')
  
  for (const [jobId, processInfo] of runningProcesses) {
    console.log(`í•™ìŠµ ${jobId} ì¢…ë£Œ ì¤‘...`)
    processInfo.process.kill('SIGTERM')
  }
  
  process.exit(0)
})

export default app
