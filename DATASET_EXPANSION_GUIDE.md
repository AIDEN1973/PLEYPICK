# 데이터셋 확대 가이드

## 현재 상황

**현재 데이터셋:**
- 총 이미지: **200개**
- 부품 구성: 단일 부품 또는 소수 부품
- 학습: 160개, 검증: 40개

**문제점:**
- YOLO 학습 최소 권장량의 20% 수준
- Recall 17.5%의 주된 원인

---

## 확대 목표 (2가지 전략)

### 전략 A: 여러 부품 포함 (BOM 환경 권장)

**목적:** 실제 사용 환경과 유사 (여러 부품 혼재)

**구성 예시:**
```
최소 목표:
- 10개 부품 × 부품당 100개 = 총 1,000개

권장 목표:
- 20개 부품 × 부품당 250개 = 총 5,000개

이상 목표:
- 50개 부품 × 부품당 200개 = 총 10,000개
```

**장점:**
- 실제 BOM 환경과 유사
- 다양한 부품 간 구분 학습
- 오클루전 케이스 포함 가능

**단점:**
- 렌더링 시간 증가
- 저장 공간 증가

---

### 전략 B: 단일 부품 집중

**목적:** 특정 부품에 대한 높은 품질 데이터셋

**구성 예시:**
```
최소 목표:
- 1개 부품 × 부품당 1,000개 = 총 1,000개

권장 목표:
- 1개 부품 × 부품당 5,000개 = 총 5,000개
```

**장점:**
- 특정 부품에 대한 높은 탐지율
- 빠른 학습 및 검증
- 저장 공간 효율적

**단점:**
- 실제 환경과 차이 (단일 부품만)
- 다른 부품 탐지 불가

---

## 권장 전략: 혼합 접근

**단계별 확대 전략:**

### 1단계: 즉시 적용 (1주일 내)
```
목표: 총 1,000개
- 핵심 부품 5개 선택
- 부품당 200개 이미지
- 총 1,000개 (5 × 200)
```

### 2단계: 확장 (2주일 내)
```
목표: 총 3,000개
- 부품 10개로 확장
- 부품당 300개 이미지
- 총 3,000개 (10 × 300)
```

### 3단계: 완성 (1개월 내)
```
목표: 총 5,000개 이상
- 부품 20-50개
- 부품당 200-500개 이미지
- 총 5,000-10,000개
```

---

## 실제 렌더링 설정

### 현재 기본 설정
```python
# server/synthetic-api.js
safeImageCount = 200  # 부품당 200장 (기술문서 기준)
```

### 확대 설정 예시

**최소 목표 (1,000개):**
```javascript
// 5개 부품 × 200개 = 1,000개
imageCount: 200  // 부품당 이미지 수
```

**권장 목표 (5,000개):**
```javascript
// 10개 부품 × 500개 = 5,000개
imageCount: 500  // 부품당 이미지 수
```

**이상 목표 (10,000개):**
```javascript
// 20개 부품 × 500개 = 10,000개
// 또는 50개 부품 × 200개 = 10,000개
imageCount: 200-500  // 부품당 이미지 수
```

---

## 실행 방법

### 방법 1: 웹 UI를 통한 배치 생성

```javascript
// 여러 부품을 순차적으로 렌더링
const parts = ['3001', '3002', '3003', '3004', '3005']  // 5개 부품
const imagesPerPart = 200  // 부품당 200개

for (const partId of parts) {
  await startRendering({
    part_id: partId,
    imageCount: imagesPerPart,
    quality: 'medium'
  })
}
```

### 방법 2: 스크립트 사용

```bash
# Phase 1: 핵심 부품 (5개 × 200개 = 1,000개)
python scripts/synthetic_dataset_pipeline.py \
  --part-list "3001,3002,3003,3004,3005" \
  --max-images 200 \
  --output-dir "./output/synthetic/phase1_expanded"

# Phase 2: 확장 (10개 × 500개 = 5,000개)
python scripts/synthetic_dataset_pipeline.py \
  --part-list "auto" \
  --max-images 500 \
  --output-dir "./output/synthetic/phase2_expanded"
```

---

## 예상 성능 개선

### 현재 (200개)
- Recall: 17.5% ❌
- mAP50: 53.0% ❌

### 1,000개 달성 시
- Recall: 60-75% ⚠️
- mAP50: 70-80% ⚠️

### 5,000개 달성 시
- Recall: 85-95% ✅ (SLO 기준 충족)
- mAP50: 85-92% ✅

---

## 답변 요약

**질문: "부품당 1000개 이상으로 조정하는가?"**

**답변:**

**아니요. 총 이미지 수 목표입니다.**

- **현재**: 총 200개
- **최소 목표**: 총 1,000개
- **권장 목표**: 총 5,000개

**구성 옵션:**

1. **여러 부품 포함 (권장)**:
   - 10개 부품 × 부품당 100개 = 총 1,000개
   - 20개 부품 × 부품당 250개 = 총 5,000개

2. **단일 부품 집중**:
   - 1개 부품 × 부품당 1,000개 = 총 1,000개
   - 1개 부품 × 부품당 5,000개 = 총 5,000개

**현재 기본 설정:**
- 부품당 200개 (기술문서 기준)
- 이 설정을 유지하고 **부품 수를 늘리는 것**이 권장됩니다.

