{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í·± BrickBox YOLO11n-seg ìë™í™” í•™ìŠµ ë…¸íŠ¸ë¶\n",
    "\n",
    "**BrickBox íŠ¹ì„±ì— ìµœì í™”ëœ YOLO11n-seg ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸**\n",
    "\n",
    "## í¾¯ BrickBox ìµœì í™” ì „ëµ\n",
    "- **í•™ìŠµìš©**: YOLO11n-seg.pt (Colab)\n",
    "- **ì¶”ë¡ ìš©**: YOLO11n-seg.onnx (í”„ë¡ íŠ¸ì—”ë“œ)\n",
    "- **ëª¨ë¸ ì¼ì¹˜**: í•™ìŠµê³¼ ì¶”ë¡ ì´ ë™ì¼í•œ ì•„í‚¤í…ì²˜\n",
    "- **ì„±ëŠ¥ ë³´ì¥**: í•™ìŠµëœ ì„±ëŠ¥ ê·¸ëŒ€ë¡œ í™œìš©\n",
    "\n",
    "## íº€ ìë™í™” ê¸°ëŠ¥\n",
    "- Supabaseì—ì„œ ë°ì´í„°ì…‹ ìë™ ë‹¤ìš´ë¡œë“œ\n",
    "- YOLO11n-seg ëª¨ë¸ ìë™ í•™ìŠµ\n",
    "- ONNX ë³€í™˜ ë° ê²½ëŸ‰í™”\n",
    "- Supabase Storage ìë™ ì—…ë¡œë“œ\n",
    "- ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìë™ ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í´§ 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install ultralytics torch torchvision\n",
    "!pip install supabase\n",
    "!pip install onnxruntime\n",
    "!pip install opencv-python\n",
    "!pip install pyyaml\n",
    "!pip install python-dotenv\n",
    "!pip install matplotlib seaborn\n",
    "!pip install requests\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ultralytics import YOLO\n",
    "from supabase import create_client, Client\n",
    "from IPython.display import clear_output, display\n",
    "import yaml\n",
    "from PIL import Image\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í´— 2. Supabase ì—°ê²° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supabase ì—°ê²° ì„¤ì •\n",
    "SUPABASE_URL = 'https://npferbxuxocbfnfbpcnz.supabase.co'\n",
    "SUPABASE_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTk0NzQ5ODUsImV4cCI6MjA3NTA1MDk4NX0.eqKQh_o1k2VmP-_v__gUMHVOgvdIzml-zDhZyzfxUmk'\n",
    "\n",
    "# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "try:\n",
    "    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "    print(f\"âœ… Supabase ì—°ê²° ì„±ê³µ: {SUPABASE_URL}\")\n",
    "    \n",
    "    # ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "    result = supabase.table('automation_config').select('*').limit(1).execute()\n",
    "    print(f\"í³Š ì„¤ì • ë°ì´í„° í™•ì¸: {len(result.data)}ê°œ\")\n",
    "    \n",
    "    # ë Œë”ë§ëœ ë°ì´í„° í™•ì¸\n",
    "    dataset_result = supabase.table('synthetic_dataset').select('*').limit(5).execute()\n",
    "    print(f\"í³Š ë Œë”ë§ëœ ë°ì´í„° ê°œìˆ˜: {len(dataset_result.data)}ê°œ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í³¥ 3. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "dataset_dir = Path('/content/brickbox_dataset')\n",
    "dataset_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ì„œë¸Œë””ë ‰í† ë¦¬ ìƒì„±\n",
    "images_dir = dataset_dir / 'images'\n",
    "labels_dir = dataset_dir / 'labels'\n",
    "images_dir.mkdir(exist_ok=True)\n",
    "labels_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"í³ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ìƒì„±: {dataset_dir}\")\n",
    "\n",
    "# ë Œë”ë§ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "try:\n",
    "    result = supabase.table('synthetic_dataset').select('*').limit(100).execute()\n",
    "    print(f\"í³Š ë Œë”ë§ëœ ë°ì´í„° ê°œìˆ˜: {len(result.data)}\")\n",
    "    \n",
    "    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜\n",
    "    processed_count = 0\n",
    "    for i, data in enumerate(result.data):\n",
    "        if processed_count >= 50:  # ì²˜ìŒ 50ê°œë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)\n",
    "            break\n",
    "            \n",
    "        part_id = data.get('part_id', f'part_{i}')\n",
    "        image_url = data.get('image_url', '')\n",
    "        annotation_url = data.get('annotation_url', '')\n",
    "        \n",
    "        if image_url:\n",
    "            try:\n",
    "                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "                img_response = requests.get(image_url)\n",
    "                if img_response.status_code == 200:\n",
    "                    img_path = images_dir / f'{part_id}_{processed_count:03d}.jpg'\n",
    "                    with open(img_path, 'wb') as f:\n",
    "                        f.write(img_response.content)\n",
    "                    \n",
    "                    # ë¼ë²¨ íŒŒì¼ ìƒì„± (YOLO í˜•ì‹)\n",
    "                    label_path = labels_dir / f'{part_id}_{processed_count:03d}.txt'\n",
    "                    \n",
    "                    # ê¸°ë³¸ ë°”ìš´ë”© ë°•ìŠ¤ (ì „ì²´ ì´ë¯¸ì§€)\n",
    "                    img = Image.open(img_path)\n",
    "                    w, h = img.size\n",
    "                    \n",
    "                    # YOLO í˜•ì‹: class_id center_x center_y width height (ì •ê·œí™”ëœ ì¢Œí‘œ)\n",
    "                    with open(label_path, 'w') as f:\n",
    "                        f.write(f\"0 0.5 0.5 1.0 1.0\\n\")  # í´ë˜ìŠ¤ 0, ì¤‘ì•™, ì „ì²´ í¬ê¸°\n",
    "                    \n",
    "                    print(f\"âœ… ì²˜ë¦¬ ì™„ë£Œ: {part_id}_{processed_count:03d}\")\n",
    "                    processed_count += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì˜¤ë¥˜ {part_id}: {e}\")\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"í³Š ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(list(images_dir.glob('*.jpg')))}ê°œ ì´ë¯¸ì§€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.yaml íŒŒì¼ ìƒì„±\n",
    "dataset_config = {\n",
    "    'path': str(dataset_dir),\n",
    "    'train': 'images',\n",
    "    'val': 'images',\n",
    "    'nc': 1,\n",
    "    'names': ['lego_part']\n",
    "}\n",
    "\n",
    "yaml_path = dataset_dir / 'dataset.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"âœ… dataset.yaml ìƒì„±: {yaml_path}\")\n",
    "print(f\"í³‹ ì„¤ì • ë‚´ìš©:\")\n",
    "for key, value in dataset_config.items():\n",
    "    print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## íº€ 4. YOLO11n-seg ëª¨ë¸ í•™ìŠµ (BrickBox ìµœì í™”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO11n ëª¨ë¸ ì´ˆê¸°í™” (BrickBox íŠ¹ì„±ì— ìµœì í™”)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"í´§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# YOLO11n ëª¨ë¸ ì´ˆê¸°í™” (ê°ì²´ íƒì§€ + ê²½ëŸ‰í™”)\n",
    "model = YOLO('yolo11n.pt')  # BrickBox ìµœì  ëª¨ë¸!\n",
    "\n",
    "# í•™ìŠµ ì„¤ì • (BrickBox íŠ¹ì„± ê³ ë ¤)\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "imgsz = 640\n",
    "\n",
    "# ê³ ìœ í•œ í•™ìŠµ ì´ë¦„ ìƒì„±\n",
    "training_name = f'brickbox_n_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "print(f\"íº€ YOLO11n í•™ìŠµ ì‹œì‘:\")\n",
    "print(f\"  - Epochs: {epochs}\")\n",
    "print(f\"  - Batch Size: {batch_size}\")\n",
    "print(f\"  - Image Size: {imgsz}\")\n",
    "print(f\"  - Device: {device}\")\n",
    "print(f\"  - Training Name: {training_name}\")\n",
    "print(f\"  - ëª¨ë¸: YOLO11n-seg (ê°ì²´ íƒì§€ + ê²½ëŸ‰í™”)\")\n",
    "print(f\"  - í•™ìŠµ-ì¶”ë¡  ì¼ì¹˜: âœ… ë™ì¼í•œ ì•„í‚¤í…ì²˜\")\n",
    "\n",
    "# ì‹¤ì œ í•™ìŠµ ì‹¤í–‰\n",
    "print(\"í³Š í•™ìŠµ ì‹œì‘...\")\n",
    "results = model.train(\n",
    "    data='/content/brickbox_dataset/dataset.yaml',\n",
    "    epochs=epochs,\n",
    "    batch=batch_size,\n",
    "    imgsz=imgsz,\n",
    "    device=device,\n",
    "    project='brickbox_yolo',\n",
    "    name=training_name,\n",
    "    save=True,\n",
    "    plots=True,\n",
    "    val=True\n",
    ")\n",
    "\n",
    "print(\"âœ… í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í³Š 5. í•™ìŠµ ê²°ê³¼ ë¶„ì„ ë° ëª¨ë¸ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê²°ê³¼ ë¶„ì„\n",
    "print(\"í³Š í•™ìŠµ ê²°ê³¼ ë¶„ì„:\")\n",
    "print(f\"  - ìµœì¢… mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "print(f\"  - ìµœì¢… mAP50-95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
    "print(f\"  - ìµœì¢… Precision: {results.results_dict.get('metrics/precision(B)', 'N/A')}\")\n",
    "print(f\"  - ìµœì¢… Recall: {results.results_dict.get('metrics/recall(B)', 'N/A')}\")\n",
    "\n",
    "# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸\n",
    "best_model_path = f'/content/brickbox_yolo/{training_name}/weights/best.pt'\n",
    "print(f\"âœ… ìµœì  ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {best_model_path}\")\n",
    "\n",
    "# ëª¨ë¸ ê²€ì¦\n",
    "print(\"í´ ëª¨ë¸ ê²€ì¦ ì¤‘...\")\n",
    "validation_results = model.val(data='/content/brickbox_dataset/dataset.yaml')\n",
    "print(\"âœ… ëª¨ë¸ ê²€ì¦ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## íº€ 6. ONNX ë³€í™˜ ë° Supabase ì—…ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX ë³€í™˜ (ê²½ëŸ‰í™”ëœ ì¶”ë¡ ìš©)\n",
    "print(\"í´„ ONNX ë³€í™˜ ì¤‘...\")\n",
    "onnx_model_path = f'/content/brickbox_yolo/{training_name}/weights/best.onnx'\n",
    "model.export(format='onnx', imgsz=640, optimize=True)\n",
    "print(f\"âœ… ONNX ë³€í™˜ ì™„ë£Œ: {onnx_model_path}\")\n",
    "\n",
    "# Supabaseì— ëª¨ë¸ ì—…ë¡œë“œ\n",
    "print(\"í³¤ Supabaseì— ëª¨ë¸ ì—…ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "# ëª¨ë¸ íŒŒì¼ì„ Supabase Storageì— ì—…ë¡œë“œ\n",
    "try:\n",
    "    # PyTorch ëª¨ë¸ ì—…ë¡œë“œ\n",
    "    with open(best_model_path, 'rb') as f:\n",
    "        pt_model_data = f.read()\n",
    "    \n",
    "    # ONNX ëª¨ë¸ ì—…ë¡œë“œ  \n",
    "    with open(onnx_model_path, 'rb') as f:\n",
    "        onnx_model_data = f.read()\n",
    "    \n",
    "    # Supabase Storageì— ì—…ë¡œë“œ\n",
    "    pt_response = supabase.storage.from_('model-storage').upload(\n",
    "        f'models/{training_name}/best.pt', \n",
    "        pt_model_data\n",
    "    )\n",
    "    \n",
    "    onnx_response = supabase.storage.from_('model-storage').upload(\n",
    "        f'models/{training_name}/best.onnx', \n",
    "        onnx_model_data\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸\n",
    "print(\"í³‹ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì¤‘...\")\n",
    "try:\n",
    "    model_info = {\n",
    "        'model_name': training_name,\n",
    "        'model_type': 'YOLO11n',\n",
    "        'version': '1.0.0',\n",
    "        'status': 'active',\n",
    "        'performance_metrics': {\n",
    "            'mAP50': results.results_dict.get('metrics/mAP50(B)', 0),\n",
    "            'mAP50-95': results.results_dict.get('metrics/mAP50-95(B)', 0),\n",
    "            'precision': results.results_dict.get('metrics/precision(B)', 0),\n",
    "            'recall': results.results_dict.get('metrics/recall(B)', 0)\n",
    "        },\n",
    "        'model_path': f'models/{training_name}/best.pt',\n",
    "        'onnx_path': f'models/{training_name}/best.onnx',\n",
    "        'training_config': {\n",
    "            'epochs': epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'imgsz': imgsz,\n",
    "            'device': device\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # model_registry í…Œì´ë¸”ì— ì‚½ì…\n",
    "    registry_response = supabase.table('model_registry').insert(model_info).execute()\n",
    "    print(\"âœ… ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"í¾‰ BrickBox YOLO11n-seg í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
    "print(\"í¾¯ í•™ìŠµ-ì¶”ë¡  ëª¨ë¸ ì¼ì¹˜: âœ… ì™„ë²½í•œ ì„±ëŠ¥ ë³´ì¥!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
