#!/usr/bin/env python3
"""
ğŸ§± BrickBox ë Œë”ë§ ì¼ê´„ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
ë¡œì»¬ output í´ë”ì˜ ë Œë”ë§ ì´ë¯¸ì§€ë¥¼ ë Œë”ë§ ì™„ë£Œ í›„ ì¼ê´„ ì—…ë¡œë“œ
"""

import os
import sys
import json
import time
import shutil
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import requests
from supabase import create_client, Client

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BatchUploadManager:
    """ë Œë”ë§ ì¼ê´„ ì—…ë¡œë“œ ê´€ë¦¬ì"""
    
    def __init__(self, supabase_url: str, supabase_key: str):
        self.supabase_url = supabase_url
        self.supabase_key = supabase_key
        self.supabase: Client = create_client(supabase_url, supabase_key)
        self.upload_queue = []
        self.upload_results = []
    
    def scan_local_renderings(self, output_dir: str) -> List[Dict]:
        """ë¡œì»¬ ë Œë”ë§ ê²°ê³¼ ìŠ¤ìº”"""
        output_path = Path(output_dir)
        if not output_path.exists():
            logger.warning(f"ë¡œì»¬ output í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {output_dir}")
            return []
        
        renderings = []
        
        # ë Œë”ë§ í´ë” ìŠ¤ìº”
        for part_folder in output_path.iterdir():
            if part_folder.is_dir():
                part_id = part_folder.name
                
                # ì´ë¯¸ì§€ íŒŒì¼ ìŠ¤ìº”
                image_files = list(part_folder.glob("*.png")) + list(part_folder.glob("*.jpg"))
                annotation_files = list(part_folder.glob("*.txt"))
                metadata_files = list(part_folder.glob("*.json"))
                
                for image_file in image_files:
                    # í•´ë‹¹í•˜ëŠ” ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ì°¾ê¸°
                    annotation_file = None
                    for ann_file in annotation_files:
                        if ann_file.stem == image_file.stem:
                            annotation_file = ann_file
                            break
                    
                    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì°¾ê¸°
                    metadata_file = None
                    for meta_file in metadata_files:
                        if meta_file.stem == image_file.stem:
                            metadata_file = meta_file
                            break
                    
                    rendering_info = {
                        'part_id': part_id,
                        'image_path': str(image_file),
                        'annotation_path': str(annotation_file) if annotation_file else None,
                        'metadata_path': str(metadata_file) if metadata_file else None,
                        'filename': image_file.name,
                        'size': image_file.stat().st_size,
                        'created_at': datetime.fromtimestamp(image_file.stat().st_ctime)
                    }
                    
                    renderings.append(rendering_info)
        
        logger.info(f"ğŸ“Š ë¡œì»¬ ë Œë”ë§ ìŠ¤ìº” ì™„ë£Œ: {len(renderings)}ê°œ íŒŒì¼")
        return renderings
    
    def check_existing_uploads(self, renderings: List[Dict]) -> List[Dict]:
        """ì´ë¯¸ ì—…ë¡œë“œëœ íŒŒì¼ í™•ì¸"""
        logger.info("ğŸ” ê¸°ì¡´ ì—…ë¡œë“œ íŒŒì¼ í™•ì¸ ì¤‘...")
        
        # Supabaseì—ì„œ ê¸°ì¡´ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
        existing_files = set()
        try:
            # synthetic_dataset í…Œì´ë¸”ì—ì„œ ê¸°ì¡´ íŒŒì¼ í™•ì¸
            result = self.supabase.table('synthetic_dataset').select('image_url').execute()
            
            for row in result.data:
                if row.get('image_url'):
                    # URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
                    filename = row['image_url'].split('/')[-1]
                    existing_files.add(filename)
            
            logger.info(f"ğŸ“‹ ê¸°ì¡´ ì—…ë¡œë“œ íŒŒì¼: {len(existing_files)}ê°œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        # ì—…ë¡œë“œí•  íŒŒì¼ í•„í„°ë§
        upload_queue = []
        for rendering in renderings:
            if rendering['filename'] not in existing_files:
                upload_queue.append(rendering)
            else:
                logger.info(f"â­ï¸ ì´ë¯¸ ì—…ë¡œë“œë¨: {rendering['filename']}")
        
        logger.info(f"ğŸ“¤ ì—…ë¡œë“œ ëŒ€ê¸°: {len(upload_queue)}ê°œ íŒŒì¼")
        return upload_queue
    
    def upload_single_rendering(self, rendering: Dict) -> bool:
        """ë‹¨ì¼ ë Œë”ë§ íŒŒì¼ ì—…ë¡œë“œ"""
        try:
            part_id = rendering['part_id']
            image_path = rendering['image_path']
            annotation_path = rendering['annotation_path']
            metadata_path = rendering['metadata_path']
            filename = rendering['filename']
            
            logger.info(f"ğŸ“¤ ì—…ë¡œë“œ ì¤‘: {filename}")
            
            # ì´ë¯¸ì§€ ì—…ë¡œë“œ
            with open(image_path, 'rb') as f:
                image_data = f.read()
            
            image_supabase_path = f"synthetic/{part_id}/{filename}"
            image_result = self.supabase.storage.from_('lego-synthetic').upload(
                image_supabase_path,
                image_data,
                file_options={"content-type": "image/png", "upsert": True}
            )
            
            if hasattr(image_result, 'error') and image_result.error:
                raise Exception(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {image_result.error}")
            
            # ê³µê°œ URL ìƒì„±
            image_url_data = self.supabase.storage.from_('lego-synthetic').getPublicUrl(image_supabase_path)
            image_url = image_url_data.publicUrl
            
            # ì–´ë…¸í…Œì´ì…˜ ì—…ë¡œë“œ (ìˆëŠ” ê²½ìš°)
            annotation_url = None
            if annotation_path and os.path.exists(annotation_path):
                with open(annotation_path, 'rb') as f:
                    annotation_data = f.read()
                
                annotation_filename = os.path.basename(annotation_path)
                annotation_supabase_path = f"synthetic/{part_id}/{annotation_filename}"
                annotation_result = self.supabase.storage.from_('lego-synthetic').upload(
                    annotation_supabase_path,
                    annotation_data,
                    file_options={"content-type": "text/plain", "upsert": True}
                )
                
                if not (hasattr(annotation_result, 'error') and annotation_result.error):
                    annotation_url_data = self.supabase.storage.from_('lego-synthetic').getPublicUrl(annotation_supabase_path)
                    annotation_url = annotation_url_data.publicUrl
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ (ìˆëŠ” ê²½ìš°)
            metadata = {}
            if metadata_path and os.path.exists(metadata_path):
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
            
            # synthetic_dataset í…Œì´ë¸”ì— ë ˆì½”ë“œ ì‚½ì…
            dataset_record = {
                'part_id': part_id,
                'image_url': image_url,
                'annotation_url': annotation_url,
                'metadata': metadata,
                'created_at': datetime.now().isoformat(),
                'status': 'completed'
            }
            
            insert_result = self.supabase.table('synthetic_dataset').insert(dataset_record).execute()
            
            if hasattr(insert_result, 'error') and insert_result.error:
                raise Exception(f"ë°ì´í„°ë² ì´ìŠ¤ ì‚½ì… ì‹¤íŒ¨: {insert_result.error}")
            
            logger.info(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨ {filename}: {e}")
            return False
    
    def batch_upload(self, output_dir: str, batch_size: int = 10) -> Dict:
        """ì¼ê´„ ì—…ë¡œë“œ ì‹¤í–‰"""
        logger.info("ğŸš€ ë Œë”ë§ ì¼ê´„ ì—…ë¡œë“œ ì‹œì‘")
        
        # 1. ë¡œì»¬ ë Œë”ë§ ìŠ¤ìº”
        renderings = self.scan_local_renderings(output_dir)
        if not renderings:
            logger.warning("ğŸ“­ ì—…ë¡œë“œí•  ë Œë”ë§ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return {'success': False, 'message': 'ì—…ë¡œë“œí•  íŒŒì¼ ì—†ìŒ'}
        
        # 2. ê¸°ì¡´ ì—…ë¡œë“œ í™•ì¸
        upload_queue = self.check_existing_uploads(renderings)
        if not upload_queue:
            logger.info("âœ… ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤")
            return {'success': True, 'message': 'ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ ì—…ë¡œë“œë¨'}
        
        # 3. ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤í–‰
        success_count = 0
        fail_count = 0
        
        for i in range(0, len(upload_queue), batch_size):
            batch = upload_queue[i:i+batch_size]
            logger.info(f"ğŸ“¦ ë°°ì¹˜ {i//batch_size + 1} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ íŒŒì¼)")
            
            for rendering in batch:
                if self.upload_single_rendering(rendering):
                    success_count += 1
                else:
                    fail_count += 1
                
                # ë°°ì¹˜ ê°„ ì ì‹œ ëŒ€ê¸° (API ì œí•œ ë°©ì§€)
                time.sleep(0.5)
            
            # ë°°ì¹˜ ê°„ ëŒ€ê¸°
            if i + batch_size < len(upload_queue):
                logger.info(f"â³ ë‹¤ìŒ ë°°ì¹˜ê¹Œì§€ ëŒ€ê¸° ì¤‘...")
                time.sleep(2)
        
        # 4. ê²°ê³¼ ìš”ì•½
        result = {
            'success': fail_count == 0,
            'total_files': len(upload_queue),
            'success_count': success_count,
            'fail_count': fail_count,
            'message': f'ì—…ë¡œë“œ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {fail_count}ê°œ ì‹¤íŒ¨'
        }
        
        logger.info(f"ğŸ‰ ì¼ê´„ ì—…ë¡œë“œ ì™„ë£Œ: {result['message']}")
        return result
    
    def cleanup_local_files(self, output_dir: str, keep_backup: bool = True) -> bool:
        """ë¡œì»¬ íŒŒì¼ ì •ë¦¬ (ì„ íƒì‚¬í•­)"""
        try:
            if keep_backup:
                # ë°±ì—… í´ë”ë¡œ ì´ë™
                backup_dir = Path(output_dir).parent / f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                backup_dir.mkdir(exist_ok=True)
                shutil.move(output_dir, backup_dir)
                logger.info(f"ğŸ“¦ ë¡œì»¬ íŒŒì¼ì„ ë°±ì—… í´ë”ë¡œ ì´ë™: {backup_dir}")
            else:
                # ì™„ì „ ì‚­ì œ
                shutil.rmtree(output_dir)
                logger.info(f"ğŸ—‘ï¸ ë¡œì»¬ íŒŒì¼ ì‚­ì œ: {output_dir}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë¡œì»¬ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python batch_upload_renderings.py <output_dir> [--cleanup] [--batch-size N]")
        print("ì˜µì…˜:")
        print("  --cleanup: ì—…ë¡œë“œ í›„ ë¡œì»¬ íŒŒì¼ ì •ë¦¬")
        print("  --batch-size N: ë°°ì¹˜ í¬ê¸° ì„¤ì • (ê¸°ë³¸ê°’: 10)")
        sys.exit(1)
    
    output_dir = sys.argv[1]
    cleanup = '--cleanup' in sys.argv
    batch_size = 10
    
    # ë°°ì¹˜ í¬ê¸° ì„¤ì •
    if '--batch-size' in sys.argv:
        try:
            batch_size_idx = sys.argv.index('--batch-size')
            batch_size = int(sys.argv[batch_size_idx + 1])
        except (ValueError, IndexError):
            logger.warning("âš ï¸ ì˜ëª»ëœ ë°°ì¹˜ í¬ê¸°, ê¸°ë³¸ê°’ ì‚¬ìš©")
    
    # Supabase ì„¤ì •
    supabase_url = os.getenv('VITE_SUPABASE_URL', 'https://npferbxuxocbfnfbpcnz.supabase.co')
    supabase_key = os.getenv('VITE_SUPABASE_ANON_KEY', 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTk0NzQ5ODUsImV4cCI6MjA3NTA1MDk4NX0.eqKQh_o1k2VmP-_v__gUMHVOgvdIzml-zDhZyzfxUmk')
    
    try:
        # ì¼ê´„ ì—…ë¡œë“œ ì‹¤í–‰
        uploader = BatchUploadManager(supabase_url, supabase_key)
        result = uploader.batch_upload(output_dir, batch_size)
        
        if result['success']:
            logger.info("ğŸ‰ ì¼ê´„ ì—…ë¡œë“œ ì„±ê³µ!")
            
            # ë¡œì»¬ íŒŒì¼ ì •ë¦¬ (ì„ íƒì‚¬í•­)
            if cleanup:
                uploader.cleanup_local_files(output_dir, keep_backup=True)
        else:
            logger.error(f"âŒ ì¼ê´„ ì—…ë¡œë“œ ì‹¤íŒ¨: {result['message']}")
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
