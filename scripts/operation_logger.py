#!/usr/bin/env python3 """ BrickBox Operation Logger 각 워커 공통 로그 포맷 (ts, op, status, metadata) 정의 """ import os import json import time from datetime import datetime from typing import Dict, List, Optional, Any import logging logger = logging.getLogger(__name__) class OperationLogger: """통합 운영 로그 관리자""" def __init__(self, log_dir: str = "logs"): self.log_dir = log_dir self.operation_log_path = os.path.join(log_dir, "operation_logs.jsonl") self.metrics_log_path = os.path.join(log_dir, "metrics_logs.jsonl") # 로그 디렉토리 생성 os.makedirs(log_dir, exist_ok=True) def log_operation(self, operation: str, status: str, worker: str, metadata: Dict = None, duration: float = None, error: str = None) -> bool: """운영 로그 기록""" try: log_entry = { "timestamp": datetime.now().isoformat(), "operation": operation, "status": status, "worker": worker, "metadata": metadata or {}, "duration_seconds": duration, "error": error } # JSONL 형식으로 저장 with open(self.operation_log_path, 'a', encoding='utf-8') as f: f.write(json.dumps(log_entry, ensure_ascii=False) + '\n') logger.info(f" 운영 로그 기록: {operation} - {status}") return True except Exception as e: logger.error(f" 운영 로그 기록 실패: {e}") return False def get_performance_metrics(self, hours: int = 24) -> Dict: """성능 메트릭 계산 (P95 지연시간, 에러율)""" try: import numpy as np from datetime import datetime, timedelta cutoff_time = datetime.now() - timedelta(hours=hours) cutoff_str = cutoff_time.isoformat() # 로그 파일에서 데이터 읽기 operations = [] if os.path.exists(self.operation_log_path): with open(self.operation_log_path, 'r', encoding='utf-8') as f: for line in f: try: log_entry = json.loads(line.strip()) if log_entry['timestamp'] >= cutoff_str: operations.append(log_entry) except (json.JSONDecodeError, KeyError): continue if not operations: return { 'total_operations': 0, 'success_rate': 0.0, 'error_rate': 0.0, 'p95_duration': 0.0, 'avg_duration': 0.0, 'operations_by_worker': {}, 'operations_by_type': {} } # 기본 통계 total_ops = len(operations) successful_ops = len([op for op in operations if op['status'] == 'completed']) failed_ops = len([op for op in operations if op['status'] == 'failed']) # 지연시간 계산 durations = [op.get('duration_seconds', 0) for op in operations if op.get('duration_seconds')] # P95 지연시간 계산 p95_duration = np.percentile(durations, 95) if durations else 0.0 avg_duration = np.mean(durations) if durations else 0.0 # 워커별 통계 worker_stats = {} for op in operations: worker = op.get('worker', 'unknown') if worker not in worker_stats: worker_stats[worker] = {'total': 0, 'success': 0, 'failed': 0} worker_stats[worker]['total'] += 1 if op['status'] == 'completed': worker_stats[worker]['success'] += 1 elif op['status'] == 'failed': worker_stats[worker]['failed'] += 1 # 작업 타입별 통계 type_stats = {} for op in operations: op_type = op.get('operation', 'unknown') if op_type not in type_stats: type_stats[op_type] = {'total': 0, 'success': 0, 'failed': 0} type_stats[op_type]['total'] += 1 if op['status'] == 'completed': type_stats[op_type]['success'] += 1 elif op['status'] == 'failed': type_stats[op_type]['failed'] += 1 return { 'total_operations': total_ops, 'success_rate': (successful_ops / total_ops * 100) if total_ops > 0 else 0.0, 'error_rate': (failed_ops / total_ops * 100) if total_ops > 0 else 0.0, 'p95_duration': float(p95_duration), 'avg_duration': float(avg_duration), 'operations_by_worker': worker_stats, 'operations_by_type': type_stats, 'time_range_hours': hours } except Exception as e: logger.error(f" 성능 메트릭 계산 실패: {e}") return {} def get_qa_quality_metrics(self, hours: int = 24) -> Dict: """QA 품질 메트릭 계산""" try: from datetime import datetime, timedelta cutoff_time = datetime.now() - timedelta(hours=hours) cutoff_str = cutoff_time.isoformat() # QA 로그에서 데이터 읽기 qa_operations = [] if os.path.exists(self.operation_log_path): with open(self.operation_log_path, 'r', encoding='utf-8') as f: for line in f: try: log_entry = json.loads(line.strip()) if (log_entry['timestamp'] >= cutoff_str and log_entry.get('operation') == 'qa_verification'): qa_operations.append(log_entry) except (json.JSONDecodeError, KeyError): continue if not qa_operations: return { 'total_qa_checks': 0, 'pass_rate': 0.0, 'avg_ssim': 0.0, 'avg_snr': 0.0, 'quality_issues': [] } # 품질 지표 추출 ssim_scores = [] snr_scores = [] quality_issues = [] for op in qa_operations: metadata = op.get('metadata', {}) if 'ssim' in metadata: ssim_scores.append(metadata['ssim']) if 'snr' in metadata: snr_scores.append(metadata['snr']) if op['status'] == 'failed': quality_issues.append({ 'timestamp': op['timestamp'], 'error': op.get('error', 'Unknown error'), 'metadata': metadata }) total_qa = len(qa_operations) passed_qa = len([op for op in qa_operations if op['status'] == 'completed']) return { 'total_qa_checks': total_qa, 'pass_rate': (passed_qa / total_qa * 100) if total_qa > 0 else 0.0, 'avg_ssim': float(np.mean(ssim_scores)) if ssim_scores else 0.0, 'avg_snr': float(np.mean(snr_scores)) if snr_scores else 0.0, 'quality_issues': quality_issues, 'time_range_hours': hours } except Exception as e: logger.error(f" QA 품질 메트릭 계산 실패: {e}") return {} def log_metrics(self, worker: str, metrics: Dict, stage: str = None) -> bool: """메트릭 로그 기록""" try: log_entry = { "timestamp": datetime.now().isoformat(), "worker": worker, "stage": stage, "metrics": metrics } # JSONL 형식으로 저장 with open(self.metrics_log_path, 'a', encoding='utf-8') as f: f.write(json.dumps(log_entry, ensure_ascii=False) + '\n') logger.info(f" 메트릭 로그 기록: {worker}") return True except Exception as e: logger.error(f" 메트릭 로그 기록 실패: {e}") return False def log_quality_metrics(self, part_id: str, metrics: Dict) -> bool: """품질 메트릭 로그""" try: quality_log = { "timestamp": datetime.now().isoformat(), "part_id": part_id, "quality_metrics": { "ssim": metrics.get("ssim", 0.0), "snr": metrics.get("snr", 0.0), "sharpness": metrics.get("sharpness", 0.0), "noise_level": metrics.get("noise_level", 0.0), "contrast": metrics.get("contrast", 0.0), "brightness": metrics.get("brightness", 0.0) }, "quality_status": metrics.get("quality_valid", False), "quality_issues": metrics.get("quality_issues", []) } # 품질 로그 파일 quality_log_path = os.path.join(self.log_dir, "quality_logs.jsonl") with open(quality_log_path, 'a', encoding='utf-8') as f: f.write(json.dumps(quality_log, ensure_ascii=False) + '\n') return True except Exception as e: logger.error(f" 품질 메트릭 로그 실패: {e}") return False def log_embedding_metrics(self, part_id: str, embedding_type: str, vector_dim: int, processing_time: float) -> bool: """임베딩 메트릭 로그""" try: embedding_log = { "timestamp": datetime.now().isoformat(), "part_id": part_id, "embedding_type": embedding_type, "vector_dimension": vector_dim, "processing_time_seconds": processing_time, "vector_size_mb": (vector_dim * 4) / (1024 * 1024) # float32 기준 } # 임베딩 로그 파일 embedding_log_path = os.path.join(self.log_dir, "embedding_logs.jsonl") with open(embedding_log_path, 'a', encoding='utf-8') as f: f.write(json.dumps(embedding_log, ensure_ascii=False) + '\n') return True except Exception as e: logger.error(f" 임베딩 메트릭 로그 실패: {e}") return False def log_fusion_metrics(self, detection_count: int, match_count: int, confidence_scores: List[float], processing_time: float) -> bool: """Fusion 메트릭 로그""" try: fusion_log = { "timestamp": datetime.now().isoformat(), "detection_count": detection_count, "match_count": match_count, "match_rate": match_count / detection_count if detection_count > 0 else 0.0, "avg_confidence": sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0, "min_confidence": min(confidence_scores) if confidence_scores else 0.0, "max_confidence": max(confidence_scores) if confidence_scores else 0.0, "processing_time_seconds": processing_time } # Fusion 로그 파일 fusion_log_path = os.path.join(self.log_dir, "fusion_logs.jsonl") with open(fusion_log_path, 'a', encoding='utf-8') as f: f.write(json.dumps(fusion_log, ensure_ascii=False) + '\n') return True except Exception as e: logger.error(f" Fusion 메트릭 로그 실패: {e}") return False def get_operation_stats(self, worker: str = None, start_time: str = None, end_time: str = None) -> Dict: """운영 통계 조회""" try: stats = { "total_operations": 0, "successful_operations": 0, "failed_operations": 0, "workers": {}, "operations": {} } if not os.path.exists(self.operation_log_path): return stats with open(self.operation_log_path, 'r', encoding='utf-8') as f: for line in f: try: entry = json.loads(line.strip()) # 필터링 if worker and entry.get("worker") != worker: continue if start_time and entry.get("timestamp") < start_time: continue if end_time and entry.get("timestamp") > end_time: continue # 통계 계산 stats["total_operations"] += 1 if entry.get("status") == "success": stats["successful_operations"] += 1 elif entry.get("status") == "failed": stats["failed_operations"] += 1 # 워커별 통계 worker_name = entry.get("worker", "unknown") if worker_name not in stats["workers"]: stats["workers"][worker_name] = {"total": 0, "success": 0, "failed": 0} stats["workers"][worker_name]["total"] += 1 if entry.get("status") == "success": stats["workers"][worker_name]["success"] += 1 elif entry.get("status") == "failed": stats["workers"][worker_name]["failed"] += 1 # 작업별 통계 operation = entry.get("operation", "unknown") if operation not in stats["operations"]: stats["operations"][operation] = {"total": 0, "success": 0, "failed": 0} stats["operations"][operation]["total"] += 1 if entry.get("status") == "success": stats["operations"][operation]["success"] += 1 elif entry.get("status") == "failed": stats["operations"][operation]["failed"] += 1 except json.JSONDecodeError: continue return stats except Exception as e: logger.error(f" 운영 통계 조회 실패: {e}") return {} def get_quality_summary(self) -> Dict: """품질 요약 조회""" try: quality_log_path = os.path.join(self.log_dir, "quality_logs.jsonl") if not os.path.exists(quality_log_path): return {} quality_stats = { "total_parts": 0, "passed_parts": 0, "failed_parts": 0, "avg_ssim": 0.0, "avg_snr": 0.0, "avg_sharpness": 0.0, "quality_issues": {} } ssim_scores = [] snr_scores = [] sharpness_scores = [] with open(quality_log_path, 'r', encoding='utf-8') as f: for line in f: try: entry = json.loads(line.strip()) quality_stats["total_parts"] += 1 if entry.get("quality_status"): quality_stats["passed_parts"] += 1 else: quality_stats["failed_parts"] += 1 metrics = entry.get("quality_metrics", {}) ssim_scores.append(metrics.get("ssim", 0.0)) snr_scores.append(metrics.get("snr", 0.0)) sharpness_scores.append(metrics.get("sharpness", 0.0)) # 품질 이슈 통계 issues = entry.get("quality_issues", []) for issue in issues: if issue not in quality_stats["quality_issues"]: quality_stats["quality_issues"][issue] = 0 quality_stats["quality_issues"][issue] += 1 except json.JSONDecodeError: continue # 평균 계산 if ssim_scores: quality_stats["avg_ssim"] = sum(ssim_scores) / len(ssim_scores) if snr_scores: quality_stats["avg_snr"] = sum(snr_scores) / len(snr_scores) if sharpness_scores: quality_stats["avg_sharpness"] = sum(sharpness_scores) / len(sharpness_scores) return quality_stats except Exception as e: logger.error(f" 품질 요약 조회 실패: {e}") return {} def main(): """테스트 함수""" try: # Operation Logger 초기화 op_logger = OperationLogger("test_logs") # 운영 로그 테스트 op_logger.log_operation("render_image", "success", "render_worker", {"part_id": "test_001", "image_size": "1024x1024"}, 2.5) # 메트릭 로그 테스트 op_logger.log_metrics("qa_worker", {"ssim": 0.97, "snr": 38.5}, "quality_check") # 통계 조회 stats = op_logger.get_operation_stats() print(f"총 작업: {stats['total_operations']}") print(f"성공: {stats['successful_operations']}") print(f"실패: {stats['failed_operations']}") return True except Exception as e: logger.error(f" 테스트 실패: {e}") return False if __name__ == "__main__": main() 