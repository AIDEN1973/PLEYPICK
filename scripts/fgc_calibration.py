#!/usr/bin/env python3 """ BrickBox FGC ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìë™í™” ì›Œì»¤ margin ê¸°ë°˜ ìë™ A/B ì‹¤í—˜ ë° metric ê¸°ë¡ """ import os import sys import json import time import logging from datetime import datetime from typing import Dict, List, Optional, Tuple import numpy as np from dataclasses import dataclass # Supabase í´ë¼ì´ì–¸íŠ¸ import try: from supabase import create_client, Client SUPABASE_URL = os.environ.get("SUPABASE_URL") SUPABASE_KEY = os.environ.get("SUPABASE_KEY") if SUPABASE_URL and SUPABASE_KEY: supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY) else: supabase = None print(" Supabase í™˜ê²½ ë³€ìˆ˜ ì—†ìŒ - DB ë¡œê¹… ë¹„í™œì„±í™”") except ImportError: supabase = None print(" Supabase í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ - DB ë¡œê¹… ë¹„í™œì„±í™”") logger = logging.getLogger(__name__) @dataclass class CalibrationConfig: """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„¤ì •""" slope_values: List[float] = None pivot_values: List[float] = None margin_threshold: float = 0.1 min_samples: int = 100 max_iterations: int = 10 confidence_level: float = 0.95 def __post_init__(self): if self.slope_values is None: self.slope_values = [1.0, 1.2, 1.5] if self.pivot_values is None: self.pivot_values = [0.15, 0.20, 0.25] @dataclass class CalibrationResult: """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼""" best_slope: float best_pivot: float best_score: float margin_cases: int top1_improvement: float p95_latency: float stage2_rate: float confidence: float experiment_id: str timestamp: str class FGCCalibrationWorker: """FGC ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìë™í™” ì›Œì»¤""" def __init__(self, supabase_client=None): self.supabase = supabase_client or supabase self.config = CalibrationConfig() self.experiment_results = [] def run_calibration_experiment(self, test_data: List[Dict], current_weights: Dict = None) -> CalibrationResult: """FGC ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤í—˜ ì‹¤í–‰""" try: logger.info(" FGC ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤í—˜ ì‹œì‘") # í˜„ì¬ ê°€ì¤‘ì¹˜ ì„¤ì • if current_weights is None: current_weights = {"w_img": 0.5, "w_meta": 0.3, "w_txt": 0.2} # ì‹¤í—˜ ID ìƒì„± experiment_id = f"fgc_calibration_{datetime.now().strftime('%Y%m%d_%H%M%S')}" best_result = None best_score = -1.0 # ëª¨ë“  slope/pivot ì¡°í•© í…ŒìŠ¤íŠ¸ for slope in self.config.slope_values: for pivot in self.config.pivot_values: logger.info(f"ğŸ”¬ ì‹¤í—˜ ì¤‘: slope={slope}, pivot={pivot}") # ê°€ì¤‘ì¹˜ ì¡°ì • adjusted_weights = self._adjust_weights(current_weights, slope, pivot) # ì„±ëŠ¥ í‰ê°€ performance = self._evaluate_performance(test_data, adjusted_weights) # ì ìˆ˜ ê³„ì‚° score = self._calculate_score(performance) # ìµœê³  ê²°ê³¼ ì—…ë°ì´íŠ¸ if score > best_score: best_score = score best_result = CalibrationResult( best_slope=slope, best_pivot=pivot, best_score=score, margin_cases=performance.get("margin_cases", 0), top1_improvement=performance.get("top1_improvement", 0.0), p95_latency=performance.get("p95_latency", 0.0), stage2_rate=performance.get("stage2_rate", 0.0), confidence=performance.get("confidence", 0.0), experiment_id=experiment_id, timestamp=datetime.now().isoformat() ) # ì‹¤í—˜ ê²°ê³¼ ì €ì¥ self._save_experiment_result(experiment_id, slope, pivot, performance, score) if best_result: # ìµœì  ê²°ê³¼ DB ì €ì¥ self._save_calibration_result(best_result) logger.info(f" ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ: slope={best_result.best_slope}, pivot={best_result.best_pivot}") return best_result else: logger.error(" ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨: ìœ íš¨í•œ ê²°ê³¼ ì—†ìŒ") return None except Exception as e: logger.error(f" ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤í—˜ ì‹¤íŒ¨: {e}") return None def _adjust_weights(self, current_weights: Dict, slope: float, pivot: float) -> Dict: """ê°€ì¤‘ì¹˜ ì¡°ì • (slope/pivot ê¸°ë°˜)""" try: # í˜„ì¬ ê°€ì¤‘ì¹˜ ë³µì‚¬ adjusted = current_weights.copy() # slope ì ìš©: ì´ë¯¸ì§€ ê°€ì¤‘ì¹˜ ì¡°ì • adjusted["w_img"] = min(1.0, adjusted["w_img"] * slope) # pivot ì ìš©: ë©”íƒ€/í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ì¬ë¶„ë°° remaining_weight = 1.0 - adjusted["w_img"] if remaining_weight > 0: # pivotì„ ê¸°ì¤€ìœ¼ë¡œ ë©”íƒ€/í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ë¶„ë°° meta_ratio = pivot txt_ratio = 1.0 - pivot adjusted["w_meta"] = remaining_weight * meta_ratio adjusted["w_txt"] = remaining_weight * txt_ratio # ì •ê·œí™” total = sum(adjusted.values()) if total > 0: for key in adjusted: adjusted[key] /= total return adjusted except Exception as e: logger.error(f" ê°€ì¤‘ì¹˜ ì¡°ì • ì‹¤íŒ¨: {e}") return current_weights def _evaluate_performance(self, test_data: List[Dict], weights: Dict) -> Dict: """ì„±ëŠ¥ í‰ê°€ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‹¤ì œ ëª¨ë¸ ì‹¤í–‰)""" try: # ë”ë¯¸ ì„±ëŠ¥ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ëª¨ë¸ ì‹¤í–‰) performance = { "top1_accuracy": np.random.uniform(0.85, 0.95), "top5_accuracy": np.random.uniform(0.92, 0.98), "p95_latency": np.random.uniform(10.0, 20.0), "stage2_rate": np.random.uniform(0.15, 0.30), "margin_cases": np.random.randint(50, 200), "confidence": np.random.uniform(0.8, 0.95) } # ê°€ì¤‘ì¹˜ì— ë”°ë¥¸ ì„±ëŠ¥ ì¡°ì • (ì‹œë®¬ë ˆì´ì…˜) w_img = weights.get("w_img", 0.5) w_meta = weights.get("w_meta", 0.3) w_txt = weights.get("w_txt", 0.2) # ì´ë¯¸ì§€ ê°€ì¤‘ì¹˜ê°€ ë†’ì„ìˆ˜ë¡ ì •í™•ë„ í–¥ìƒ, ì§€ì—°ì‹œê°„ ì¦ê°€ performance["top1_accuracy"] += (w_img - 0.5) * 0.1 performance["p95_latency"] += (w_img - 0.5) * 5.0 # ë©”íƒ€ ê°€ì¤‘ì¹˜ê°€ ë†’ì„ìˆ˜ë¡ Stage-2 ì§„ì…ë¥  ê°ì†Œ performance["stage2_rate"] -= (w_meta - 0.3) * 0.2 # í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ê°€ ë†’ì„ìˆ˜ë¡ margin ì¼€ì´ìŠ¤ ê°ì†Œ performance["margin_cases"] = int(performance["margin_cases"] * (1.0 - w_txt * 0.3)) # top1 ê°œì„ ìœ¨ ê³„ì‚° baseline_accuracy = 0.90 # ê¸°ì¤€ ì •í™•ë„ performance["top1_improvement"] = performance["top1_accuracy"] - baseline_accuracy return performance except Exception as e: logger.error(f" ì„±ëŠ¥ í‰ê°€ ì‹¤íŒ¨: {e}") return {} def _calculate_score(self, performance: Dict) -> float: """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìˆ˜ ê³„ì‚°""" try: # ê°€ì¤‘ì¹˜ ì„¤ì • weights = { "top1_improvement": 0.4, "p95_latency": -0.2, # ì§€ì—°ì‹œê°„ì€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ "stage2_rate": -0.2, # Stage-2 ì§„ì…ë¥ ì€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ "margin_cases": -0.2 # margin ì¼€ì´ìŠ¤ëŠ” ì ì„ìˆ˜ë¡ ì¢‹ìŒ } # ì ìˆ˜ ê³„ì‚° score = 0.0 for metric, weight in weights.items(): value = performance.get(metric, 0.0) score += value * weight # ì •ê·œí™” (0-1 ë²”ìœ„) score = max(0.0, min(1.0, (score + 1.0) / 2.0)) return score except Exception as e: logger.error(f" ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}") return 0.0 def _save_experiment_result(self, experiment_id: str, slope: float, pivot: float, performance: Dict, score: float) -> bool: """ì‹¤í—˜ ê²°ê³¼ ì €ì¥""" try: if not self.supabase: return False result_data = { "experiment_id": experiment_id, "slope": slope, "pivot": pivot, "performance": performance, "score": score, "timestamp": datetime.now().isoformat() } # operation_logsì— ì €ì¥ log_entry = { "timestamp": datetime.now().isoformat(), "operation_type": "FGC_CALIBRATION_EXPERIMENT", "status": "SUCCESS", "worker": "fgc_calibration", "metadata": result_data, "duration_seconds": 0.0, "error": None } result = self.supabase.table('operation_logs').insert(log_entry).execute() return bool(result.data) except Exception as e: logger.error(f" ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}") return False def _save_calibration_result(self, result: CalibrationResult) -> bool: """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ì €ì¥""" try: if not self.supabase: return False # ìµœì¢… ê²°ê³¼ ì €ì¥ result_data = { "experiment_id": result.experiment_id, "best_slope": result.best_slope, "best_pivot": result.best_pivot, "best_score": result.best_score, "margin_cases": result.margin_cases, "top1_improvement": result.top1_improvement, "p95_latency": result.p95_latency, "stage2_rate": result.stage2_rate, "confidence": result.confidence, "timestamp": result.timestamp } log_entry = { "timestamp": datetime.now().isoformat(), "operation_type": "FGC_CALIBRATION_RESULT", "status": "SUCCESS", "worker": "fgc_calibration", "metadata": result_data, "duration_seconds": 0.0, "error": None } result_db = self.supabase.table('operation_logs').insert(log_entry).execute() return bool(result_db.data) except Exception as e: logger.error(f" ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}") return False def get_calibration_history(self, limit: int = 10) -> List[Dict]: """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì´ë ¥ ì¡°íšŒ""" try: if not self.supabase: return [] result = self.supabase.table('operation_logs')\ .select('*')\ .eq('operation_type', 'FGC_CALIBRATION_RESULT')\ .order('timestamp', desc=True)\ .limit(limit)\ .execute() return result.data if result.data else [] except Exception as e: logger.error(f" ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨: {e}") return [] def main(): """FGC ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë©”ì¸ í•¨ìˆ˜""" try: print("ğŸ”¬ FGC ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìë™í™” ì‹œì‘") # ì›Œì»¤ ì´ˆê¸°í™” worker = FGCCalibrationWorker() # ë”ë¯¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± test_data = [ {"part_id": f"test_part_{i}", "features": np.random.rand(512)} for i in range(100) ] # í˜„ì¬ ê°€ì¤‘ì¹˜ ì„¤ì • current_weights = {"w_img": 0.5, "w_meta": 0.3, "w_txt": 0.2} # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤í–‰ result = worker.run_calibration_experiment(test_data, current_weights) if result: print(f" ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ:") print(f"ìµœì  slope: {result.best_slope}") print(f"ìµœì  pivot: {result.best_pivot}") print(f"ìµœê³  ì ìˆ˜: {result.best_score:.3f}") print(f"Top-1 ê°œì„ : {result.top1_improvement:.3f}") print(f"Margin ì¼€ì´ìŠ¤: {result.margin_cases}") print(f"P95 ì§€ì—°ì‹œê°„: {result.p95_latency:.2f}ms") print(f"Stage-2 ì§„ì…ë¥ : {result.stage2_rate:.2f}") print(f"ì‹ ë¢°ë„: {result.confidence:.3f}") # ì´ë ¥ ì¡°íšŒ history = worker.get_calibration_history(5) print(f"\n ìµœê·¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì´ë ¥: {len(history)}ê±´") return True else: print(" ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨") return False except Exception as e: logger.error(f" FGC ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨: {e}") return False if __name__ == "__main__": success = main() sys.exit(0 if success else 1) 