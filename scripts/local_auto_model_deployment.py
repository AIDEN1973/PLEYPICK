#!/usr/bin/env python3
"""
ğŸ¤– BrickBox ë¡œì»¬ PC ìë™ ëª¨ë¸ ë°°í¬ ì‹œìŠ¤í…œ

- ë¡œì»¬ í›ˆë ¨ ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ëª¨ë¸ ë°°í¬
- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë°˜ ìë™ ìŠ¹ì¸/ê±°ë¶€
- Supabase Storage ìë™ ì—…ë¡œë“œ
- ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìë™ ì—…ë°ì´íŠ¸
"""

import os
import sys
import json
import logging
import requests
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import hashlib
import glob

# ë¡œê¹… ì„¤ì •
os.makedirs('logs', exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/local_auto_deployment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class LocalAutoModelDeployment:
    def __init__(self):
        # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
        self.load_env_vars()
        
        self.models_bucket = 'models'
        
        # ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        self.local_model_paths = {
            'best_onnx': 'runs/detect/train/best.onnx',
            'best_pt': 'runs/detect/train/best.pt',
            'last_pt': 'runs/detect/train/last.pt'
        }
        
        # ë°°í¬ ì„¤ì •
        self.deployment_config = {
            'auto_approve_threshold': 0.05,  # 5% ì„±ëŠ¥ í–¥ìƒ ì‹œ ìë™ ìŠ¹ì¸
            'min_performance_metrics': {
                'mAP50': 0.7,
                'mAP50_95': 0.5,
                'precision': 0.8,
                'recall': 0.7
            },
            'rolling_deployment': True,
            'rollback_threshold': 0.1  # 10% ì„±ëŠ¥ ì €í•˜ ì‹œ ë¡¤ë°±
        }
    
    def load_env_vars(self):
        """í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"""
        try:
            with open('.env', 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key] = value
        except FileNotFoundError:
            logger.warning("âš ï¸ .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        self.supabase_url = os.getenv('VITE_SUPABASE_URL', 'https://npferbxuxocbfnfbpcnz.supabase.co')
        self.supabase_key = os.getenv('VITE_SUPABASE_SERVICE_ROLE')
        
        if not self.supabase_key:
            logger.error("âŒ VITE_SUPABASE_SERVICE_ROLE í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            sys.exit(1)
    
    def find_latest_training_results(self) -> Optional[Dict]:
        """ìµœì‹  í›ˆë ¨ ê²°ê³¼ ì°¾ê¸°"""
        try:
            logger.info("ğŸ” ìµœì‹  í›ˆë ¨ ê²°ê³¼ í™•ì¸ ì¤‘...")
            
            # runs/detect/train í´ë”ì—ì„œ ìµœì‹  ê²°ê³¼ ì°¾ê¸°
            train_dirs = glob.glob('runs/detect/train*')
            if not train_dirs:
                logger.info("ğŸ“­ í›ˆë ¨ ê²°ê³¼ í´ë” ì—†ìŒ")
                return None
            
            # ê°€ì¥ ìµœê·¼ í´ë” ì„ íƒ
            latest_dir = max(train_dirs, key=os.path.getctime)
            logger.info(f"ğŸ“ ìµœì‹  í›ˆë ¨ í´ë”: {latest_dir}")
            
            # ëª¨ë¸ íŒŒì¼ í™•ì¸
            model_files = {
                'best_onnx': os.path.join(latest_dir, 'best.onnx'),
                'best_pt': os.path.join(latest_dir, 'best.pt'),
                'last_pt': os.path.join(latest_dir, 'last.pt')
            }
            
            existing_files = {k: v for k, v in model_files.items() if os.path.exists(v)}
            
            if not existing_files:
                logger.warning("âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # results.csvì—ì„œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì½ê¸°
            results_csv = os.path.join(latest_dir, 'results.csv')
            performance_metrics = self.parse_results_csv(results_csv)
            
            # í›ˆë ¨ ì •ë³´ ìˆ˜ì§‘
            training_info = {
                'training_dir': latest_dir,
                'model_files': existing_files,
                'performance_metrics': performance_metrics,
                'created_at': datetime.fromtimestamp(os.path.getctime(latest_dir)).isoformat(),
                'training_name': os.path.basename(latest_dir)
            }
            
            logger.info(f"âœ… í›ˆë ¨ ê²°ê³¼ ë°œê²¬: {training_info['training_name']}")
            logger.info(f"ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­: {performance_metrics}")
            
            return training_info
            
        except Exception as e:
            logger.error(f"âŒ í›ˆë ¨ ê²°ê³¼ í™•ì¸ ì‹¤íŒ¨: {e}")
            return None
    
    def parse_results_csv(self, results_csv: str) -> Dict:
        """results.csvì—ì„œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ íŒŒì‹±"""
        try:
            if not os.path.exists(results_csv):
                logger.warning(f"âš ï¸ results.csv ì—†ìŒ: {results_csv}")
                return {}
            
            import pandas as pd
            
            # CSV íŒŒì¼ ì½ê¸°
            df = pd.read_csv(results_csv)
            
            # ë§ˆì§€ë§‰ í–‰ì˜ ë©”íŠ¸ë¦­ ì‚¬ìš©
            last_row = df.iloc[-1]
            
            metrics = {
                'mAP50': last_row.get('metrics/mAP50(B)', 0.0),
                'mAP50_95': last_row.get('metrics/mAP50-95(B)', 0.0),
                'precision': last_row.get('metrics/precision(B)', 0.0),
                'recall': last_row.get('metrics/recall(B)', 0.0)
            }
            
            logger.info(f"ğŸ“ˆ íŒŒì‹±ëœ ë©”íŠ¸ë¦­: {metrics}")
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ results.csv íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {}
    
    def evaluate_model_performance(self, metrics: Dict) -> Dict:
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        try:
            logger.info("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
            
            # ìµœì†Œ ì„±ëŠ¥ ê¸°ì¤€ í™•ì¸
            min_metrics = self.deployment_config['min_performance_metrics']
            performance_check = {
                'mAP50': metrics.get('mAP50', 0) >= min_metrics['mAP50'],
                'mAP50_95': metrics.get('mAP50_95', 0) >= min_metrics['mAP50_95'],
                'precision': metrics.get('precision', 0) >= min_metrics['precision'],
                'recall': metrics.get('recall', 0) >= min_metrics['recall']
            }
            
            all_metrics_pass = all(performance_check.values())
            
            # í˜„ì¬ í™œì„± ëª¨ë¸ê³¼ ì„±ëŠ¥ ë¹„êµ
            current_model = self.get_current_active_model()
            performance_improvement = 0
            
            if current_model and current_model.get('performance_metrics'):
                current_metrics = current_model['performance_metrics']
                improvement = {
                    'mAP50': metrics.get('mAP50', 0) - current_metrics.get('mAP50', 0),
                    'mAP50_95': metrics.get('mAP50_95', 0) - current_metrics.get('mAP50_95', 0),
                    'precision': metrics.get('precision', 0) - current_metrics.get('precision', 0),
                    'recall': metrics.get('recall', 0) - current_metrics.get('recall', 0)
                }
                performance_improvement = sum(improvement.values()) / len(improvement)
            
            evaluation = {
                'all_metrics_pass': all_metrics_pass,
                'performance_improvement': performance_improvement,
                'auto_approve': all_metrics_pass and performance_improvement >= self.deployment_config['auto_approve_threshold'],
                'performance_check': performance_check,
                'current_model': current_model,
                'improvement_details': performance_improvement
            }
            
            logger.info(f"ğŸ“ˆ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼: {evaluation}")
            return evaluation
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {'all_metrics_pass': False, 'auto_approve': False}
    
    def get_current_active_model(self) -> Optional[Dict]:
        """í˜„ì¬ í™œì„± ëª¨ë¸ ì¡°íšŒ"""
        try:
            response = requests.get(
                f"{self.supabase_url}/rest/v1/model_registry",
                headers={
                    'apikey': self.supabase_key,
                    'Authorization': f'Bearer {self.supabase_key}',
                    'Content-Type': 'application/json'
                },
                params={
                    'is_active': 'eq.true',
                    'order': 'created_at.desc',
                    'limit': '1'
                }
            )
            
            if response.status_code == 200:
                models = response.json()
                return models[0] if models else None
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ í˜„ì¬ í™œì„± ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def upload_model_to_storage(self, local_model_path: str, model_name: str) -> Optional[str]:
        """ëª¨ë¸ì„ Supabase Storageì— ì—…ë¡œë“œ"""
        try:
            logger.info(f"ğŸ“¤ ëª¨ë¸ ì—…ë¡œë“œ ì¤‘: {model_name}")
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(local_model_path):
                logger.error(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {local_model_path}")
                return None
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(local_model_path)
            logger.info(f"ğŸ“ ëª¨ë¸ íŒŒì¼ í¬ê¸°: {file_size / 1024 / 1024:.1f} MB")
            
            # íŒŒì¼ í•´ì‹œ ìƒì„± (ì¤‘ë³µ í™•ì¸ìš©)
            with open(local_model_path, 'rb') as f:
                file_hash = hashlib.md5(f.read()).hexdigest()
            
            # ì—…ë¡œë“œ ê²½ë¡œ ìƒì„±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            upload_path = f"brickbox_s_seg_{timestamp}/{model_name}"
            
            # Supabase Storageì— ì—…ë¡œë“œ
            with open(local_model_path, 'rb') as f:
                files = {'file': (model_name, f, 'application/octet-stream')}
                
                response = requests.post(
                    f"{self.supabase_url}/storage/v1/object/{self.models_bucket}/{upload_path}",
                    headers={
                        'Authorization': f'Bearer {self.supabase_key}',
                        'Content-Type': 'multipart/form-data'
                    },
                    files=files
                )
            
            if response.status_code in [200, 201]:
                public_url = f"{self.supabase_url}/storage/v1/object/public/{self.models_bucket}/{upload_path}"
                logger.info(f"âœ… ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ: {public_url}")
                return public_url
            else:
                logger.error(f"âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def update_model_registry(self, model_data: Dict) -> bool:
        """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸"""
        try:
            logger.info("ğŸ“‹ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì¤‘...")
            
            # ê¸°ì¡´ í™œì„± ëª¨ë¸ ë¹„í™œì„±í™”
            if model_data.get('current_model_id'):
                requests.patch(
                    f"{self.supabase_url}/rest/v1/model_registry",
                    headers={
                        'apikey': self.supabase_key,
                        'Authorization': f'Bearer {self.supabase_key}',
                        'Content-Type': 'application/json'
                    },
                    json={'is_active': False},
                    params={'id': 'eq.' + str(model_data['current_model_id'])}
                )
            
            # ìƒˆ ëª¨ë¸ ë“±ë¡
            response = requests.post(
                f"{self.supabase_url}/rest/v1/model_registry",
                headers={
                    'apikey': self.supabase_key,
                    'Authorization': f'Bearer {self.supabase_key}',
                    'Content-Type': 'application/json'
                },
                json=model_data
            )
            
            if response.status_code in [200, 201]:
                logger.info("âœ… ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                return True
            else:
                logger.error(f"âŒ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def deploy_model(self, training_info: Dict) -> bool:
        """ëª¨ë¸ ë°°í¬ ì‹¤í–‰"""
        try:
            logger.info("ğŸš€ ëª¨ë¸ ë°°í¬ ì‹œì‘...")
            
            # 1. ì„±ëŠ¥ ë©”íŠ¸ë¦­ í™•ì¸
            metrics = training_info.get('performance_metrics', {})
            evaluation = self.evaluate_model_performance(metrics)
            
            if not evaluation['all_metrics_pass']:
                logger.warning("âš ï¸ ìµœì†Œ ì„±ëŠ¥ ê¸°ì¤€ ë¯¸ë‹¬ë¡œ ë°°í¬ ì¤‘ë‹¨")
                logger.warning(f"   ì„±ëŠ¥ ì²´í¬: {evaluation['performance_check']}")
                return False
            
            # 2. ONNX ëª¨ë¸ ì—…ë¡œë“œ (ìš°ì„ ìˆœìœ„)
            onnx_path = training_info['model_files'].get('best_onnx')
            if not onnx_path:
                logger.error("âŒ ONNX ëª¨ë¸ íŒŒì¼ ì—†ìŒ")
                return False
            
            model_name = f"set_76917-1_best.onnx"
            public_url = self.upload_model_to_storage(onnx_path, model_name)
            
            if not public_url:
                logger.error("âŒ ONNX ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨")
                return False
            
            # 3. PyTorch ëª¨ë¸ë„ ì—…ë¡œë“œ (ë°±ì—…ìš©)
            pt_path = training_info['model_files'].get('best_pt')
            if pt_path:
                pt_model_name = f"set_76917-1_best.pt"
                pt_public_url = self.upload_model_to_storage(pt_path, pt_model_name)
                if pt_public_url:
                    logger.info(f"âœ… PyTorch ëª¨ë¸ë„ ì—…ë¡œë“œ ì™„ë£Œ: {pt_public_url}")
            
            # 4. ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
            model_data = {
                'model_name': f"brickbox_yolo_local_{training_info['training_name']}",
                'model_version': datetime.now().strftime('%Y%m%d_%H%M%S'),
                'model_type': 'yolo11n-seg',
                'model_path': public_url,
                'performance_metrics': metrics,
                'is_active': True,
                'training_job_id': training_info['training_name'],
                'auto_deployed': True,
                'deployment_timestamp': datetime.now().isoformat(),
                'deployment_source': 'local_pc'
            }
            
            success = self.update_model_registry(model_data)
            
            if success:
                logger.info("ğŸ‰ ë¡œì»¬ ëª¨ë¸ ë°°í¬ ì™„ë£Œ!")
                
                # 5. ë°°í¬ ì•Œë¦¼
                self.send_deployment_notification(model_data)
                
                return True
            else:
                logger.error("âŒ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë°°í¬ ì‹¤íŒ¨: {e}")
            return False
    
    def send_deployment_notification(self, model_data: Dict):
        """ë°°í¬ ì™„ë£Œ ì•Œë¦¼"""
        try:
            logger.info("ğŸ“¢ ë°°í¬ ì•Œë¦¼ ì „ì†¡ ì¤‘...")
            
            notification = {
                'message': f"ğŸ¤– ë¡œì»¬ PCì—ì„œ ìƒˆ ëª¨ë¸ ë°°í¬ ì™„ë£Œ: {model_data['model_name']}",
                'version': model_data['model_version'],
                'performance': model_data['performance_metrics'],
                'timestamp': model_data['deployment_timestamp'],
                'source': 'local_pc'
            }
            
            logger.info(f"ğŸ“¢ ë°°í¬ ì•Œë¦¼: {notification}")
            
        except Exception as e:
            logger.error(f"âŒ ë°°í¬ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    def run_auto_deployment(self):
        """ìë™ ë°°í¬ ì‹¤í–‰"""
        try:
            logger.info("ğŸ¤– ë¡œì»¬ PC ìë™ ëª¨ë¸ ë°°í¬ ì‹œì‘...")
            
            # 1. ìµœì‹  í›ˆë ¨ ê²°ê³¼ í™•ì¸
            training_info = self.find_latest_training_results()
            if not training_info:
                logger.info("ğŸ“­ ë°°í¬í•  í›ˆë ¨ ê²°ê³¼ ì—†ìŒ")
                return
            
            # 2. ëª¨ë¸ ë°°í¬
            success = self.deploy_model(training_info)
            
            if success:
                logger.info("ğŸ‰ ë¡œì»¬ PC ìë™ ë°°í¬ ì™„ë£Œ!")
            else:
                logger.error("âŒ ë¡œì»¬ PC ìë™ ë°°í¬ ì‹¤íŒ¨")
                
        except Exception as e:
            logger.error(f"âŒ ìë™ ë°°í¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    deployment = LocalAutoModelDeployment()
    deployment.run_auto_deployment()

if __name__ == "__main__":
    main()
