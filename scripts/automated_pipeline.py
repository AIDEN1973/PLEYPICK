#!/usr/bin/env python3 """ BrickBox Automated Pipeline ìë™í™”ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (í¬ë¡ /ì›Œí¬í”Œë¡œ) """ import os import sys import json import time import logging import schedule from datetime import datetime, timedelta from typing import Dict, List, Optional # ë¡œê¹… ì„¤ì • logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') logger = logging.getLogger(__name__) class AutomatedPipeline: """ìë™í™”ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ê¸°""" def __init__(self, supabase_client=None): self.supabase = supabase_client self.performance_monitor = None self.operation_logger = None self.manifest_manager = None self.retrain_trigger = None # ìŠ¤ì¼€ì¤„ ì„¤ì • self.schedule_config = { 'performance_check_interval': 15, # 15ë¶„ë§ˆë‹¤ 'quality_check_interval': 30, # 30ë¶„ë§ˆë‹¤ 'retrain_evaluation_interval': 60, # 1ì‹œê°„ë§ˆë‹¤ 'manifest_update_interval': 5, # 5ë¶„ë§ˆë‹¤ 'cleanup_interval': 1440 # 24ì‹œê°„ë§ˆë‹¤ } def initialize_components(self): """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”""" try: # PerformanceMonitor ì´ˆê¸°í™” from performance_monitor import PerformanceMonitor self.performance_monitor = PerformanceMonitor(self.supabase) self.performance_monitor.initialize_components() # OperationLogger ì´ˆê¸°í™” from operation_logger import OperationLogger self.operation_logger = OperationLogger() # ManifestManager ì´ˆê¸°í™” from manifest_manager import ManifestManager self.manifest_manager = ManifestManager(self.supabase) # RetrainTrigger ì´ˆê¸°í™” from retrain_trigger import RetrainTriggerManager self.retrain_trigger = RetrainTriggerManager(self.supabase) logger.info(" ìë™í™” íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ") return True except Exception as e: logger.error(f" ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}") return False def setup_schedules(self): """ìŠ¤ì¼€ì¤„ ì„¤ì •""" try: # ì„±ëŠ¥ ì²´í¬ (15ë¶„ë§ˆë‹¤) schedule.every(self.schedule_config['performance_check_interval']).minutes.do( self._run_performance_check ) # í’ˆì§ˆ ì²´í¬ (30ë¶„ë§ˆë‹¤) schedule.every(self.schedule_config['quality_check_interval']).minutes.do( self._run_quality_check ) # ì¬í•™ìŠµ í‰ê°€ (1ì‹œê°„ë§ˆë‹¤) schedule.every(self.schedule_config['retrain_evaluation_interval']).minutes.do( self._run_retrain_evaluation ) # ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (5ë¶„ë§ˆë‹¤) schedule.every(self.schedule_config['manifest_update_interval']).minutes.do( self._run_manifest_update ) # ì •ë¦¬ ì‘ì—… (24ì‹œê°„ë§ˆë‹¤) schedule.every(self.schedule_config['cleanup_interval']).minutes.do( self._run_cleanup ) logger.info(" ìŠ¤ì¼€ì¤„ ì„¤ì • ì™„ë£Œ") return True except Exception as e: logger.error(f" ìŠ¤ì¼€ì¤„ ì„¤ì • ì‹¤íŒ¨: {e}") return False def run_scheduler(self): """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰""" try: logger.info(" ìë™í™” íŒŒì´í”„ë¼ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘") while True: schedule.run_pending() time.sleep(60) # 1ë¶„ë§ˆë‹¤ ì²´í¬ except KeyboardInterrupt: logger.info("â¹ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€") except Exception as e: logger.error(f" ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}") def _run_performance_check(self): """ì„±ëŠ¥ ì²´í¬ ì‹¤í–‰""" try: logger.info(" ì„±ëŠ¥ ì²´í¬ ì‹¤í–‰") if not self.performance_monitor: logger.error(" PerformanceMonitor ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ") return result = self.performance_monitor.run_performance_check() # ê²°ê³¼ ë¡œê¹… if result.get('slo_violations'): logger.warning(f" SLO ìœ„ë°˜ ê°ì§€: {len(result['slo_violations'])}ê°œ") if result.get('retrain_recommendations'): logger.info(f" ì¬í•™ìŠµ ì¶”ì²œ: {len(result['retrain_recommendations'])}ê°œ") logger.info(" ì„±ëŠ¥ ì²´í¬ ì™„ë£Œ") except Exception as e: logger.error(f" ì„±ëŠ¥ ì²´í¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}") def _run_quality_check(self): """í’ˆì§ˆ ì²´í¬ ì‹¤í–‰""" try: logger.info(" í’ˆì§ˆ ì²´í¬ ì‹¤í–‰") if not self.operation_logger: logger.error(" OperationLogger ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ") return # QA í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ qa_metrics = self.operation_logger.get_qa_quality_metrics(hours=24) # í’ˆì§ˆ ì„ê³„ì¹˜ ì²´í¬ quality_issues = [] if qa_metrics.get('avg_ssim', 0) < 0.965: quality_issues.append("SSIM í’ˆì§ˆ ì €í•˜") if qa_metrics.get('avg_snr', 0) < 30: quality_issues.append("SNR í’ˆì§ˆ ì €í•˜") if qa_metrics.get('pass_rate', 0) < 95: quality_issues.append("QA í†µê³¼ìœ¨ ì €í•˜") if quality_issues: logger.warning(f" í’ˆì§ˆ ì´ìŠˆ ê°ì§€: {', '.join(quality_issues)}") else: logger.info(" í’ˆì§ˆ ìƒíƒœ ì–‘í˜¸") logger.info(" í’ˆì§ˆ ì²´í¬ ì™„ë£Œ") except Exception as e: logger.error(f" í’ˆì§ˆ ì²´í¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}") def _run_retrain_evaluation(self): """ì¬í•™ìŠµ í‰ê°€ ì‹¤í–‰""" try: logger.info(" ì¬í•™ìŠµ í‰ê°€ ì‹¤í–‰") if not self.retrain_trigger: logger.error(" RetrainTrigger ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ") return # ëª¨ë“  íŠ¸ë¦¬ê±° í‰ê°€ + ì•Œë¦¼ ì „ì†¡ result = self.retrain_trigger.evaluate_all_triggers_with_notification() triggers = result.get('triggers', []) recommendations = result.get('recommendation', {}) if recommendations: logger.info(f" ì¬í•™ìŠµ ì¶”ì²œ: {recommendations.get('reason', 'Unknown')} (ìš°ì„ ìˆœìœ„: {recommendations.get('priority', 'MEDIUM')})") if result.get('notification_sent'): logger.info("ğŸ“± Slack ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ") else: logger.info(" ì¬í•™ìŠµ ë¶ˆí•„ìš”") logger.info(" ì¬í•™ìŠµ í‰ê°€ ì™„ë£Œ") except Exception as e: logger.error(f" ì¬í•™ìŠµ í‰ê°€ ì‹¤í–‰ ì‹¤íŒ¨: {e}") def _run_manifest_update(self): """ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤í–‰""" try: logger.info(" ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤í–‰") if not self.manifest_manager: logger.error(" ManifestManager ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ") return # í˜„ì¬ ìƒíƒœ ìˆ˜ì§‘ current_status = { 'timestamp': datetime.now().isoformat(), 'pipeline_status': 'running', 'last_health_check': datetime.now().isoformat() } # ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ self.manifest_manager.update_multi_layer_stage( 'automated_pipeline', 'completed', current_status ) logger.info(" ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ") except Exception as e: logger.error(f" ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}") def _run_cleanup(self): """ì •ë¦¬ ì‘ì—… ì‹¤í–‰""" try: logger.info(" ì •ë¦¬ ì‘ì—… ì‹¤í–‰") # ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì •ë¦¬ self._cleanup_old_logs() # ì™„ë£Œëœ ì‘ì—… ì •ë¦¬ self._cleanup_completed_tasks() # ì„ì‹œ íŒŒì¼ ì •ë¦¬ self._cleanup_temp_files() logger.info(" ì •ë¦¬ ì‘ì—… ì™„ë£Œ") except Exception as e: logger.error(f" ì •ë¦¬ ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨: {e}") def _cleanup_old_logs(self): """ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì •ë¦¬""" try: log_dir = "logs" if not os.path.exists(log_dir): return cutoff_time = datetime.now() - timedelta(days=7) for filename in os.listdir(log_dir): filepath = os.path.join(log_dir, filename) if os.path.isfile(filepath): file_time = datetime.fromtimestamp(os.path.getmtime(filepath)) if file_time < cutoff_time: os.remove(filepath) logger.info(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì‚­ì œ: {filename}") except Exception as e: logger.error(f" ë¡œê·¸ ì •ë¦¬ ì‹¤íŒ¨: {e}") def _cleanup_completed_tasks(self): """ì™„ë£Œëœ ì‘ì—… ì •ë¦¬""" try: # QueueManagerì—ì„œ ì™„ë£Œëœ ì‘ì—… ì •ë¦¬ from queue_manager import QueueManager queue_manager = QueueManager() # ê° íì—ì„œ ì™„ë£Œëœ ì‘ì—… ì •ë¦¬ for queue_name in ['rendering', 'embedding', 'fusion', 'qa']: queue_manager.cleanup_completed_tasks(queue_name) logger.info(" ì™„ë£Œëœ ì‘ì—… ì •ë¦¬ ì™„ë£Œ") except Exception as e: logger.error(f" ì‘ì—… ì •ë¦¬ ì‹¤íŒ¨: {e}") def _cleanup_temp_files(self): """ì„ì‹œ íŒŒì¼ ì •ë¦¬""" try: temp_dirs = ['temp', 'cache', 'tmp'] for temp_dir in temp_dirs: if os.path.exists(temp_dir): for filename in os.listdir(temp_dir): filepath = os.path.join(temp_dir, filename) if os.path.isfile(filepath): # 1ì‹œê°„ ì´ìƒ ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ file_time = datetime.fromtimestamp(os.path.getmtime(filepath)) if datetime.now() - file_time > timedelta(hours=1): os.remove(filepath) logger.info(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ: {filename}") except Exception as e: logger.error(f" ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}") def main(): """ë©”ì¸ ì‹¤í–‰""" try: # Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” from dotenv import load_dotenv from supabase import create_client load_dotenv() supabase_url = os.getenv('VITE_SUPABASE_URL') supabase_key = os.getenv('VITE_SUPABASE_ANON_KEY') if not supabase_url or not supabase_key: logger.error("Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.") return supabase = create_client(supabase_url, supabase_key) # ìë™í™” íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” pipeline = AutomatedPipeline(supabase) if not pipeline.initialize_components(): logger.error("ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨") return # ìŠ¤ì¼€ì¤„ ì„¤ì • if not pipeline.setup_schedules(): logger.error("ìŠ¤ì¼€ì¤„ ì„¤ì • ì‹¤íŒ¨") return # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ pipeline.run_scheduler() except Exception as e: logger.error(f" ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}") if __name__ == "__main__": main() 