#!/usr/bin/env python3 """ ëª¨ë“  ë¶€í’ˆ ì´ë¯¸ì§€ë¥¼ Supabase Storageë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ - CDN ë§í¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ë¶€í’ˆë“¤ì„ Supabase Storageë¡œ ì—…ë¡œë“œ - part_images í…Œì´ë¸”ì— ë“±ë¡ - ì¼ê´€ëœ ì´ë¯¸ì§€ ì†ŒìŠ¤ ë³´ì¥ """ import os import sys import json import requests from datetime import datetime from supabase import create_client, Client from PIL import Image import io # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ def load_env(): env_vars = {} try: with open('.env', 'r', encoding='utf-8') as f: for line in f: line = line.strip() if line and not line.startswith('#') and '=' in line: key, value = line.split('=', 1) env_vars[key] = value except FileNotFoundError: print(" .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.") sys.exit(1) return env_vars def main(): print(" ëª¨ë“  ë¶€í’ˆ ì´ë¯¸ì§€ë¥¼ Supabase Storageë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘") print("=" * 60) # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ env = load_env() SUPABASE_URL = env.get('VITE_SUPABASE_URL') SUPABASE_KEY = env.get('VITE_SUPABASE_ANON_KEY') if not SUPABASE_URL or not SUPABASE_KEY: print(" Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.") sys.exit(1) # Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY) try: # 1. CDN ë§í¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ë¶€í’ˆ ì¡°íšŒ print(" CDN ë§í¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ë¶€í’ˆ ì¡°íšŒ ì¤‘...") query = """ SELECT DISTINCT sp.part_id, sp.color_id, lp.part_img_url, lc.name as color_name FROM set_parts sp JOIN lego_parts lp ON sp.part_id = lp.part_num JOIN lego_colors lc ON sp.color_id = lc.color_id LEFT JOIN part_images pi ON sp.part_id = pi.part_id AND sp.color_id = pi.color_id WHERE lp.part_img_url IS NOT NULL AND lp.part_img_url LIKE '%cdn.rebrickable.com%' AND pi.part_id IS NULL ORDER BY sp.part_id, sp.color_id LIMIT 1000 """ result = supabase.rpc('execute_sql', {'sql': query}).execute() if not result.data: print(" ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë¶€í’ˆì´ ì—†ìŠµë‹ˆë‹¤.") return parts_to_migrate = result.data print(f" ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ: {len(parts_to_migrate)}ê°œ ë¶€í’ˆ") # 2. ê° ë¶€í’ˆ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì—…ë¡œë“œ success_count = 0 error_count = 0 errors = [] for i, part in enumerate(parts_to_migrate, 1): part_id = part['part_id'] color_id = part['color_id'] image_url = part['part_img_url'] color_name = part['color_name'] print(f"\n[{i}/{len(parts_to_migrate)}] ì²˜ë¦¬ ì¤‘: {part_id} (ìƒ‰ìƒ: {color_name})") try: # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ print(f" ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {image_url}") response = requests.get(image_url, timeout=30) response.raise_for_status() # WebPë¡œ ë³€í™˜ print(f" WebP ë³€í™˜ ì¤‘...") img = Image.open(io.BytesIO(response.content)) # ì´ë¯¸ì§€ ìµœì í™” (ìµœëŒ€ 800px) max_size = 800 if img.width > max_size or img.height > max_size: img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS) # WebPë¡œ ë³€í™˜ webp_buffer = io.BytesIO() img.save(webp_buffer, format='WebP', quality=80, optimize=True) webp_data = webp_buffer.getvalue() # Supabase Storageì— ì—…ë¡œë“œ print(f" Supabase Storage ì—…ë¡œë“œ ì¤‘...") file_name = f"{part_id}_{color_id}.webp" file_path = f"images/{file_name}" # ê¸°ì¡´ íŒŒì¼ ì‚­ì œ (ìˆë‹¤ë©´) try: supabase.storage.from_('lego_parts_images').remove([file_path]) except: pass # ìƒˆ íŒŒì¼ ì—…ë¡œë“œ upload_result = supabase.storage.from_('lego_parts_images').upload( file_path, webp_data, file_options={"content-type": "image/webp"} ) if upload_result.error: raise Exception(f"Upload failed: {upload_result.error}") # part_images í…Œì´ë¸”ì— ë“±ë¡ print(f" ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡ ì¤‘...") public_url = f"{SUPABASE_URL}/storage/v1/object/public/lego_parts_images/{file_path}" insert_result = supabase.table('part_images').insert({ 'part_id': part_id, 'color_id': color_id, 'original_url': image_url, 'uploaded_url': public_url, 'filename': file_name, 'upload_status': 'completed', 'created_at': datetime.now().isoformat() }).execute() if insert_result.error: raise Exception(f"Database insert failed: {insert_result.error}") success_count += 1 print(f" ì™„ë£Œ: {file_name}") except Exception as e: error_count += 1 error_msg = f"ë¶€í’ˆ {part_id} (ìƒ‰ìƒ: {color_name}) ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}" errors.append(error_msg) print(f" ì‹¤íŒ¨: {error_msg}") # ì˜¤ë¥˜ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì¤‘ë‹¨ if error_count > 50: print(f"\n ì˜¤ë¥˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤ ({error_count}ê°œ). ì¤‘ë‹¨í•©ë‹ˆë‹¤.") break # 3. ê²°ê³¼ ìš”ì•½ print("\n" + "=" * 60) print(" ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ìš”ì•½") print("=" * 60) print(f" ì„±ê³µ: {success_count}ê°œ") print(f" ì‹¤íŒ¨: {error_count}ê°œ") print(f" ì„±ê³µë¥ : {success_count/(success_count+error_count)*100:.1f}%") if errors: print(f"\n ì˜¤ë¥˜ ëª©ë¡ (ìµœëŒ€ 10ê°œ):") for error in errors[:10]: print(f" - {error}") # 4. ë¡œê·¸ ì €ì¥ log_data = { 'timestamp': datetime.now().isoformat(), 'total_parts': len(parts_to_migrate), 'success_count': success_count, 'error_count': error_count, 'success_rate': success_count/(success_count+error_count)*100 if (success_count+error_count) > 0 else 0, 'errors': errors } log_filename = f"migration_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json" with open(log_filename, 'w', encoding='utf-8') as f: json.dump(log_data, f, ensure_ascii=False, indent=2) print(f"\nğŸ“„ ìƒì„¸ ë¡œê·¸ ì €ì¥ë¨: {log_filename}") except Exception as e: print(f" ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}") sys.exit(1) if __name__ == "__main__": main() 