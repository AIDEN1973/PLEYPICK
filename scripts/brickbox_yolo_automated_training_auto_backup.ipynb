{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#   BrickBox YOLO11n ìë™í™” í•™ìŠµ ë…¸íŠ¸ë¶ (ìë™ ì‹¤í–‰ ë²„ì „)\n",
        "\n",
        "**BrickBox íŠ¹ì„±ì— ìµœì í™”ëœ YOLO11n ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸**\n",
        "\n",
        "##   ğŸš€ ìë™ ì‹¤í–‰ ê¸°ëŠ¥\n",
        "- **Cell 4 ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ Cell 5, 6 ì‹¤í–‰**\n",
        "- **í•™ìŠµ â†’ ë¶„ì„ â†’ ë³€í™˜ â†’ ì—…ë¡œë“œ** ì „ì²´ íŒŒì´í”„ë¼ì¸ ìë™í™”\n",
        "- **ìˆ˜ë™ ê°œì… ì—†ì´** ì™„ì „ ìë™í™”ëœ í•™ìŠµ í”„ë¡œì„¸ìŠ¤\n",
        "\n",
        "##   BrickBox ìµœì í™” ì „ëµ\n",
        "- **í•™ìŠµìš©**: YOLO11n.pt (Colab)\n",
        "- **ì¶”ë¡ ìš©**: YOLO11n.onnx (í”„ë¡ íŠ¸ì—”ë“œ)\n",
        "- **ëª¨ë¸ ì¼ì¹˜**: í•™ìŠµê³¼ ì¶”ë¡ ì´ ë™ì¼í•œ ì•„í‚¤í…ì²˜\n",
        "- **ì„±ëŠ¥ ë³´ì¥**: í•™ìŠµëœ ì„±ëŠ¥ ê·¸ëŒ€ë¡œ í™œìš©\n",
        "\n",
        "##   ìë™í™” ê¸°ëŠ¥\n",
        "- Supabaseì—ì„œ ë°ì´í„°ì…‹ ìë™ ë‹¤ìš´ë¡œë“œ\n",
        "- YOLO11n ëª¨ë¸ ìë™ í•™ìŠµ\n",
        "- **ìë™ ì‹¤í–‰**: Cell 5 (í•™ìŠµ ê²°ê³¼ ë¶„ì„)\n",
        "- **ìë™ ì‹¤í–‰**: Cell 6 (ONNX ë³€í™˜ ë° ì—…ë¡œë“œ)\n",
        "- Supabase Storage ìë™ ì—…ë¡œë“œ\n",
        "- ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìë™ ì—…ë°ì´íŠ¸\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##   1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”§ Supabase ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)\n",
        "import os\n",
        "from supabase import create_client, Client\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (Colabì—ì„œ ì„¤ì • ê°€ëŠ¥)\n",
        "SUPABASE_URL = os.getenv('SUPABASE_URL', 'https://npferbxuxocbfnfbpcnz.supabase.co')\n",
        "SUPABASE_ANON_KEY = os.getenv('SUPABASE_ANON_KEY', 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTk0NzQ5ODUsImV4cCI6MjA3NTA1MDk4NX0.eqKQh_o1k2VmP-_v__gUMHVOgvdIzml-zDhZyzfxUmk')\n",
        "SUPABASE_SERVICE_KEY = os.getenv('SUPABASE_SERVICE_KEY', '')\n",
        "\n",
        "# ì„œë¹„ìŠ¤ í‚¤ê°€ ìˆìœ¼ë©´ ì„œë¹„ìŠ¤ í‚¤ ì‚¬ìš©, ì—†ìœ¼ë©´ anon í‚¤ ì‚¬ìš©\n",
        "if SUPABASE_SERVICE_KEY:\n",
        "    supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)\n",
        "    print(\"âœ… Supabase ì—°ê²° ì™„ë£Œ (Service Key)\")\n",
        "else:\n",
        "    supabase: Client = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)\n",
        "    print(\"âœ… Supabase ì—°ê²° ì™„ë£Œ (Anon Key)\")\n",
        "\n",
        "print(f\"ğŸ“Š URL: {SUPABASE_URL}\")\n",
        "print(f\"ğŸ”‘ Key: {SUPABASE_SERVICE_KEY[:20] if SUPABASE_SERVICE_KEY else SUPABASE_ANON_KEY[:20]}...\")\n",
        "\n",
        "# ì—°ê²° í…ŒìŠ¤íŠ¸\n",
        "try:\n",
        "    test = supabase.table('model_registry').select('id').limit(1).execute()\n",
        "    print(\"âœ… Supabase ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Supabase ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ğŸ’¡ í™˜ê²½ë³€ìˆ˜ SUPABASE_SERVICE_KEY ë˜ëŠ” SUPABASE_ANON_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##   2. Supabase ì—°ê²° ì„¤ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì´ ì…€ì€ ì œê±°ë¨ - Cell 2ì—ì„œ Supabase ì„¤ì •ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤\n",
        "print(\"â„¹ï¸ Supabase ì„¤ì •ì€ Cell 2ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##   3. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "\n",
        "# ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "dataset_dir = Path('/content/brickbox_dataset')\n",
        "dataset_dir.mkdir(exist_ok=True)\n",
        "images_dir = dataset_dir / 'images'\n",
        "labels_dir = dataset_dir / 'labels'\n",
        "images_dir.mkdir(exist_ok=True)\n",
        "labels_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ“ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ìƒì„±: {dataset_dir}\")\n",
        "\n",
        "# ì„¸íŠ¸ë³„ ë°ì´í„° í•„í„°ë§ (ì„¸íŠ¸ ë‹¨ìœ„ í•™ìŠµ ì§€ì›)\n",
        "import sys\n",
        "\n",
        "# ì„¸íŠ¸ ë²ˆí˜¸ íŒŒë¼ë¯¸í„° í™•ì¸ (training_jobsì—ì„œ ì „ë‹¬ë°›ì€ config í™•ì¸)\n",
        "set_num = None\n",
        "try:\n",
        "    # ìµœê·¼ training_jobsì—ì„œ set_num íŒŒë¼ë¯¸í„° í™•ì¸\n",
        "    jobs_response = supabase.table('training_jobs').select('config').order('created_at', desc=True).limit(1).execute()\n",
        "    if jobs_response.data and len(jobs_response.data) > 0:\n",
        "        config = jobs_response.data[0].get('config', {})\n",
        "        set_num = config.get('set_num')\n",
        "        print(f\"ğŸ¯ ì„¸íŠ¸ ë²ˆí˜¸ ê°ì§€: {set_num}\")\n",
        "        \n",
        "        # ì„¸íŠ¸ë³„ í•™ìŠµ ëª¨ë“œ í™•ì¸\n",
        "        if set_num:\n",
        "            print(f\"ğŸ¯ ì„¸íŠ¸ ë‹¨ìœ„ í•™ìŠµ ëª¨ë“œ: {set_num}\")\n",
        "            print(f\"ğŸ“¦ ì„¸íŠ¸ {set_num}ì˜ ë¶€í’ˆë“¤ë§Œ í•™ìŠµí•©ë‹ˆë‹¤\")\n",
        "        else:\n",
        "            print(\"ğŸ“Š ì „ì²´ ë°ì´í„° í•™ìŠµ ëª¨ë“œ\")\n",
        "    else:\n",
        "        print(\"âš ï¸ training_jobs ë°ì´í„° ì—†ìŒ - ì „ì²´ ë°ì´í„° í•™ìŠµ ëª¨ë“œ\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ ì„¸íŠ¸ ë²ˆí˜¸ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ğŸ“Š ì „ì²´ ë°ì´í„° í•™ìŠµ ëª¨ë“œë¡œ ì§„í–‰\")\n",
        "\n",
        "# ì„¸íŠ¸ë³„ ë°ì´í„° ì¡°íšŒ\n",
        "if set_num:\n",
        "    print(f\"ğŸ“¦ ì„¸íŠ¸ {set_num} ë°ì´í„° ì¡°íšŒ ì¤‘...\")\n",
        "    # ì„¸íŠ¸ë³„ ë°ì´í„°ë§Œ ì¡°íšŒ\n",
        "    response = supabase.table('synthetic_dataset').select('*').eq('set_num', set_num).limit(200).execute()\n",
        "    print(f\"ğŸ¯ ì„¸íŠ¸ {set_num} ë°ì´í„° ê°œìˆ˜: {len(response.data)}\")\n",
        "else:\n",
        "    print(\"ğŸ“Š ì „ì²´ ë°ì´í„° ì¡°íšŒ ì¤‘...\")\n",
        "    # ì „ì²´ ë°ì´í„° ì¡°íšŒ (ê¸°ì¡´ ë°©ì‹)\n",
        "    response = supabase.table('synthetic_dataset').select('*').limit(100).execute()\n",
        "    print(f\"ğŸ“Š ì „ì²´ ë°ì´í„° ê°œìˆ˜: {len(response.data)}\")\n",
        "\n",
        "data = response.data\n",
        "\n",
        "# ì´ë¯¸ í•™ìŠµëœ ë¶€í’ˆ ì œì™¸ (ì¤‘ë³µ ë°©ì§€) - ì„¸íŠ¸ ë‹¨ìœ„ í•™ìŠµ ìµœì í™”\n",
        "if set_num:\n",
        "    print(f\"ğŸ”„ ì„¸íŠ¸ {set_num} ì¤‘ë³µ ì œê±° ì²˜ë¦¬ ì¤‘...\")\n",
        "    \n",
        "    # 1. ì´ë¯¸ í•™ìŠµëœ ë¶€í’ˆ ëª©ë¡ ì¡°íšŒ (model_registryì—ì„œ í™•ì¸)\n",
        "    try:\n",
        "        # ìµœê·¼ ì™„ë£Œëœ í•™ìŠµ ì‘ì—…ì—ì„œ í•™ìŠµëœ ë¶€í’ˆ ëª©ë¡ í™•ì¸\n",
        "        completed_jobs = supabase.table('training_jobs').select('config').eq('status', 'completed').order('completed_at', desc=True).limit(5).execute()\n",
        "        \n",
        "        trained_parts = set()\n",
        "        for job in completed_jobs.data:\n",
        "            job_config = job.get('config', {})\n",
        "            if 'trained_parts' in job_config:\n",
        "                trained_parts.update(job_config['trained_parts'])\n",
        "        \n",
        "        print(f\"ğŸ“Š ì´ì „ì— í•™ìŠµëœ ë¶€í’ˆ ìˆ˜: {len(trained_parts)}ê°œ\")\n",
        "        \n",
        "        # 2. ì„¸íŠ¸ ë‚´ì—ì„œ ìƒˆë¡œ í•™ìŠµí•  ë¶€í’ˆë§Œ í•„í„°ë§\n",
        "        new_data = []\n",
        "        excluded_parts = set()\n",
        "        \n",
        "        for item in data:\n",
        "            part_id = item['part_id']\n",
        "            if part_id not in trained_parts:\n",
        "                new_data.append(item)\n",
        "            else:\n",
        "                excluded_parts.add(part_id)\n",
        "                print(f\"â­ï¸ ì´ë¯¸ í•™ìŠµëœ ë¶€í’ˆ ì œì™¸: {part_id}\")\n",
        "        \n",
        "        data = new_data\n",
        "        print(f\"âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ:\")\n",
        "        print(f\"   - ì›ë³¸ ë°ì´í„°: {len(data) + len(excluded_parts)}ê°œ\")\n",
        "        print(f\"   - ì œì™¸ëœ ë¶€í’ˆ: {len(excluded_parts)}ê°œ\")\n",
        "        print(f\"   - ìƒˆë¡œ í•™ìŠµí•  ë°ì´í„°: {len(data)}ê°œ\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ ì¤‘ë³µ ì œê±° ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
        "        print(\"ğŸ“Š ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ ì§„í–‰\")\n",
        "else:\n",
        "    print(\"ğŸ“Š ì „ì²´ ë°ì´í„° í•™ìŠµ ëª¨ë“œ - ì¤‘ë³µ ì œê±° ì—†ìŒ\")\n",
        "\n",
        "# ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° YOLO í˜•ì‹ ë³€í™˜\n",
        "for i, item in enumerate(data):\n",
        "    try:\n",
        "        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
        "        image_url = item['image_url']\n",
        "        image_response = requests.get(image_url)\n",
        "        \n",
        "        # íŒŒì¼ëª… ìƒì„± (part_id_sequence í˜•ì‹)\n",
        "        part_id = item['part_id']\n",
        "        sequence = str(i).zfill(3)\n",
        "        filename = f\"{part_id}_{sequence}\"\n",
        "        \n",
        "        # ì´ë¯¸ì§€ ì €ì¥\n",
        "        image_path = images_dir / f\"{filename}.webp\"\n",
        "        with open(image_path, 'wb') as f:\n",
        "            f.write(image_response.content)\n",
        "        \n",
        "        # YOLO í˜•ì‹ ë¼ë²¨ ìƒì„± (ë‹¨ì¼ í´ë˜ìŠ¤: lego_part)\n",
        "        # ì´ë¯¸ì§€ í¬ê¸° (640x640ìœ¼ë¡œ ê°€ì •)\n",
        "        img_width, img_height = 640, 640\n",
        "        \n",
        "        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (ì „ì²´ ì´ë¯¸ì§€)\n",
        "        x_center = 0.5  # ì´ë¯¸ì§€ ì¤‘ì•™\n",
        "        y_center = 0.5  # ì´ë¯¸ì§€ ì¤‘ì•™\n",
        "        width = 1.0     # ì „ì²´ ë„ˆë¹„\n",
        "        height = 1.0    # ì „ì²´ ë†’ì´\n",
        "        \n",
        "        # YOLO í˜•ì‹ ë¼ë²¨ íŒŒì¼ ìƒì„±\n",
        "        label_path = labels_dir / f\"{filename}.txt\"\n",
        "        with open(label_path, 'w') as f:\n",
        "            f.write(f\"0 {x_center} {y_center} {width} {height}\\n\")\n",
        "        \n",
        "        print(f\"âœ… ì²˜ë¦¬ ì™„ë£Œ: {filename}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {filename} - {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"ğŸ“Š ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(data)}ê°œ ì´ë¯¸ì§€\")\n",
        "\n",
        "# dataset.yaml íŒŒì¼ ìƒì„±\n",
        "yaml_path = dataset_dir / 'dataset.yaml'\n",
        "dataset_config = {\n",
        "    'path': str(dataset_dir),\n",
        "    'train': 'images',\n",
        "    'val': 'images',\n",
        "    'nc': 1,  # í´ë˜ìŠ¤ ê°œìˆ˜\n",
        "    'names': ['lego_part']  # í´ë˜ìŠ¤ ì´ë¦„\n",
        "}\n",
        "\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(dataset_config, f, default_flow_style=False)\n",
        "\n",
        "print(f\"âœ… dataset.yaml ìƒì„±: {yaml_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##   4. YOLO11n ëª¨ë¸ í•™ìŠµ (BrickBox ìµœì í™”) + ìë™ ì‹¤í–‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOLO11n ëª¨ë¸ ì´ˆê¸°í™” (BrickBox íŠ¹ì„±ì— ìµœì í™”)\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import datetime\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
        "\n",
        "# YOLO11n ëª¨ë¸ ì´ˆê¸°í™” (ê°ì²´ íƒì§€ + ê²½ëŸ‰í™”)\n",
        "model = YOLO('yolo11n.pt')  # BrickBox ìµœì  ëª¨ë¸!\n",
        "\n",
        "# í•™ìŠµ ì„¤ì • (BrickBox íŠ¹ì„± ê³ ë ¤)\n",
        "epochs = 100\n",
        "batch_size = 16\n",
        "imgsz = 640\n",
        "\n",
        "# ê³ ìœ í•œ í•™ìŠµ ì´ë¦„ ìƒì„±\n",
        "training_name = f'brickbox_n_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
        "\n",
        "print(f\"ğŸš€ YOLO11n í•™ìŠµ ì‹œì‘:\")\n",
        "print(f\"  - Epochs: {epochs}\")\n",
        "print(f\"  - Batch Size: {batch_size}\")\n",
        "print(f\"  - Image Size: {imgsz}\")\n",
        "print(f\"  - Device: {device}\")\n",
        "print(f\"  - Training Name: {training_name}\")\n",
        "print(f\"  - ëª¨ë¸: YOLO11n (ê°ì²´ íƒì§€ + ê²½ëŸ‰í™”)\")\n",
        "print(f\"  - í•™ìŠµ-ì¶”ë¡  ì¼ì¹˜: âœ… ë™ì¼í•œ ì•„í‚¤í…ì²˜\")\n",
        "\n",
        "# ì—í­ë³„ ë©”íŠ¸ë¦­ ì €ì¥ í•¨ìˆ˜ (í•™ìŠµ ì‹œì‘ ì „ì— ì •ì˜)\n",
        "def save_epoch_metrics(trainer, job_id):\n",
        "    if not job_id:\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        metrics = trainer.metrics\n",
        "        epoch = trainer.epoch\n",
        "        \n",
        "        # training_metrics í…Œì´ë¸”ì— ì €ì¥\n",
        "        supabase.table('training_metrics').insert({\n",
        "            'training_job_id': job_id,\n",
        "            'epoch': epoch,\n",
        "            'metrics': {\n",
        "                'loss': metrics.get('loss', 0.0),\n",
        "                'mAP50': metrics.get('metrics/mAP50(B)', 0.0),\n",
        "                'mAP50_95': metrics.get('metrics/mAP50-95(B)', 0.0),\n",
        "                'precision': metrics.get('metrics/precision(B)', 0.0),\n",
        "                'recall': metrics.get('metrics/recall(B)', 0.0)\n",
        "            },\n",
        "            'created_at': datetime.datetime.now().isoformat()\n",
        "        }).execute()\n",
        "        \n",
        "        print(f\"ğŸ“Š ì—í­ {epoch} ë©”íŠ¸ë¦­ ì €ì¥ ì™„ë£Œ\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ ì—í­ ë©”íŠ¸ë¦­ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "# ì‹¤ì œ í•™ìŠµ ì‹¤í–‰\n",
        "print(\"ğŸ“Š í•™ìŠµ ì‹œì‘...\")\n",
        "\n",
        "# í•™ìŠµ ì‹œì‘ ì‹œ training_jobs ìƒíƒœ ì—…ë°ì´íŠ¸\n",
        "try:\n",
        "    # ìµœê·¼ ìƒì„±ëœ pending ì‘ì—…ì„ runningìœ¼ë¡œ ë³€ê²½\n",
        "    pending_jobs = supabase.table('training_jobs').select('id').eq('status', 'pending').order('created_at', desc=True).limit(1).execute()\n",
        "    if pending_jobs.data and len(pending_jobs.data) > 0:\n",
        "        job_id = pending_jobs.data[0]['id']\n",
        "        supabase.table('training_jobs').update({\n",
        "            'status': 'running',\n",
        "            'started_at': datetime.datetime.now().isoformat(),\n",
        "            'colab_session_id': f'colab_session_{int(datetime.datetime.now().timestamp() * 1000)}'\n",
        "        }).eq('id', job_id).execute()\n",
        "        print(f\"âœ… í•™ìŠµ ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸: {job_id} â†’ running\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ í•™ìŠµ ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "# í•™ìŠµ ì‹œì‘\n",
        "results = model.train(\n",
        "    data='/content/brickbox_dataset/dataset.yaml',\n",
        "    epochs=epochs,\n",
        "    batch=batch_size,\n",
        "    imgsz=imgsz,\n",
        "    device=device,\n",
        "    project='brickbox_yolo',\n",
        "    name=training_name,\n",
        "    save=True,\n",
        "    plots=True,\n",
        "    val=True,\n",
        "    # ì‹¤ì‹œê°„ ì½œë°± ì¶”ê°€\n",
        "    callbacks={\n",
        "        'on_epoch_end': lambda trainer: save_epoch_metrics(trainer, job_id if 'job_id' in locals() else None)\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"âœ… í•™ìŠµ ì™„ë£Œ!\")\n",
        "\n",
        "# í•™ìŠµ ì™„ë£Œ ì‹œ training_jobs ìƒíƒœ ì—…ë°ì´íŠ¸\n",
        "try:\n",
        "    if 'job_id' in locals():\n",
        "        supabase.table('training_jobs').update({\n",
        "            'status': 'completed',\n",
        "            'completed_at': datetime.datetime.now().isoformat(),\n",
        "            'progress': {\n",
        "                'final_epoch': epochs,\n",
        "                'final_metrics': {\n",
        "                    'mAP50': results.results_dict.get('metrics/mAP50(B)', 0.0),\n",
        "                    'mAP50_95': results.results_dict.get('metrics/mAP50-95(B)', 0.0),\n",
        "                    'precision': results.results_dict.get('metrics/precision(B)', 0.0),\n",
        "                    'recall': results.results_dict.get('metrics/recall(B)', 0.0)\n",
        "                }\n",
        "            }\n",
        "        }).eq('id', job_id).execute()\n",
        "        print(f\"âœ… í•™ìŠµ ì‘ì—… ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸: {job_id} â†’ completed\")\n",
        "        \n",
        "        # ì„¸íŠ¸ ë‹¨ìœ„ í•™ìŠµ ì™„ë£Œ ì‹œ set_training_status ì—…ë°ì´íŠ¸\n",
        "        if set_num:\n",
        "            print(f\"ğŸ¯ ì„¸íŠ¸ {set_num} í•™ìŠµ ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘...\")\n",
        "            \n",
        "            # í•™ìŠµëœ ë¶€í’ˆ ëª©ë¡ ì¶”ì¶œ\n",
        "            trained_parts = [item['part_id'] for item in data]\n",
        "            \n",
        "            # set_training_status ì—…ë°ì´íŠ¸\n",
        "            set_status_response = supabase.table('set_training_status').update({\n",
        "                'status': 'completed',\n",
        "                'trained_at': datetime.datetime.now().isoformat(),\n",
        "                'unique_parts_trained': len(trained_parts),\n",
        "                'is_available_for_inspection': True\n",
        "            }).eq('set_num', set_num).execute()\n",
        "            \n",
        "            if set_status_response.data:\n",
        "                print(f\"âœ… ì„¸íŠ¸ {set_num} í•™ìŠµ ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì„±ê³µ\")\n",
        "                print(f\"   - í•™ìŠµëœ ê³ ìœ  ë¶€í’ˆ ìˆ˜: {len(trained_parts)}ê°œ\")\n",
        "                print(f\"   - ê²€ìˆ˜ ê°€ëŠ¥ ìƒíƒœ: í™œì„±í™”\")\n",
        "            else:\n",
        "                print(f\"âš ï¸ ì„¸íŠ¸ {set_num} ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨\")\n",
        "                \n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ í•™ìŠµ ì‘ì—… ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "# ğŸš€ ìë™ ì‹¤í–‰: Cell 5, 6 ì‹¤í–‰\n",
        "print(\"ğŸ”„ ìë™ ì‹¤í–‰: Cell 5 (í•™ìŠµ ê²°ê³¼ ë¶„ì„) ì‹œì‘...\")\n",
        "\n",
        "# Cell 5: í•™ìŠµ ê²°ê³¼ ë¶„ì„\n",
        "print(\"ğŸ“Š í•™ìŠµ ê²°ê³¼ ë¶„ì„:\")\n",
        "print(f\"  - ìµœì¢… mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
        "print(f\"  - ìµœì¢… mAP50-95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
        "print(f\"  - ìµœì¢… Precision: {results.results_dict.get('metrics/precision(B)', 'N/A')}\")\n",
        "print(f\"  - ìµœì¢… Recall: {results.results_dict.get('metrics/recall(B)', 'N/A')}\")\n",
        "\n",
        "# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸\n",
        "best_model_path = f'/content/brickbox_yolo/{training_name}/weights/best.pt'\n",
        "print(f\"âœ… ìµœì  ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {best_model_path}\")\n",
        "\n",
        "# ëª¨ë¸ ê²€ì¦\n",
        "print(\"ğŸ” ëª¨ë¸ ê²€ì¦ ì¤‘...\")\n",
        "validation_results = model.val(data='/content/brickbox_dataset/dataset.yaml')\n",
        "print(\"âœ… ëª¨ë¸ ê²€ì¦ ì™„ë£Œ!\")\n",
        "\n",
        "# ğŸš€ ìë™ ì‹¤í–‰: Cell 6 (ONNX ë³€í™˜ ë° ì—…ë¡œë“œ) ì‹œì‘\n",
        "print(\"ğŸ”„ ìë™ ì‹¤í–‰: Cell 6 (ONNX ë³€í™˜ ë° ì—…ë¡œë“œ) ì‹œì‘...\")\n",
        "\n",
        "# Cell 6: ONNX ë³€í™˜ ë° Supabase ì—…ë¡œë“œ\n",
        "print(\"ğŸš€ ONNX ë³€í™˜ ì¤‘...\")\n",
        "onnx_model_path = f'/content/brickbox_yolo/{training_name}/weights/best.onnx'\n",
        "model.export(format='onnx', imgsz=640, optimize=True)\n",
        "print(f\"âœ… ONNX ë³€í™˜ ì™„ë£Œ: {onnx_model_path}\")\n",
        "\n",
        "# Supabaseì— ëª¨ë¸ ì—…ë¡œë“œ\n",
        "print(\"ğŸ“¤ Supabaseì— ëª¨ë¸ ì—…ë¡œë“œ ì¤‘...\")\n",
        "\n",
        "# ëª¨ë¸ íŒŒì¼ì„ Supabase Storageì— ì—…ë¡œë“œ\n",
        "try:\n",
        "    # PyTorch ëª¨ë¸ ì—…ë¡œë“œ\n",
        "    with open(best_model_path, 'rb') as f:\n",
        "        pt_model_data = f.read()\n",
        "    \n",
        "    # ONNX ëª¨ë¸ ì—…ë¡œë“œ  \n",
        "    with open(onnx_model_path, 'rb') as f:\n",
        "        onnx_model_data = f.read()\n",
        "    \n",
        "    # Supabase Storageì— ì—…ë¡œë“œ\n",
        "    pt_response = supabase.storage.from_('model-storage').upload(\n",
        "        f'models/{training_name}/best.pt', \n",
        "        pt_model_data\n",
        "    )\n",
        "    \n",
        "    onnx_response = supabase.storage.from_('model-storage').upload(\n",
        "        f'models/{training_name}/best.onnx', \n",
        "        onnx_model_data\n",
        "    )\n",
        "    \n",
        "    print(\"âœ… ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "# ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸\n",
        "print(\"ğŸ“‹ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì¤‘...\")\n",
        "try:\n",
        "    # ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ìƒˆ ëª¨ë¸ ë“±ë¡ (ì„¸íŠ¸ ì •ë³´ í¬í•¨)\n",
        "    model_registry_data = {\n",
        "        'model_name': f'brickbox_yolo_{training_name}',\n",
        "        'model_version': '1.0.0',\n",
        "        'model_type': 'yolo11n',\n",
        "        'model_path': f'models/{training_name}/best.onnx',\n",
        "        'pt_model_path': f'models/{training_name}/best.pt',\n",
        "        'training_job_id': job_id if 'job_id' in locals() else None,\n",
        "        'performance_metrics': {\n",
        "            'mAP50': results.results_dict.get('metrics/mAP50(B)', 0.0),\n",
        "            'mAP50_95': results.results_dict.get('metrics/mAP50-95(B)', 0.0),\n",
        "            'precision': results.results_dict.get('metrics/precision(B)', 0.0),\n",
        "            'recall': results.results_dict.get('metrics/recall(B)', 0.0)\n",
        "        },\n",
        "        'is_active': True,\n",
        "        'created_at': datetime.datetime.now().isoformat(),\n",
        "        # ì„¸íŠ¸ ë‹¨ìœ„ í•™ìŠµ ë©”íƒ€ë°ì´í„° ì¶”ê°€\n",
        "        'training_metadata': {\n",
        "            'set_num': set_num if set_num else None,\n",
        "            'training_mode': 'set_based' if set_num else 'full_dataset',\n",
        "            'trained_parts_count': len(data) if 'data' in locals() else 0,\n",
        "            'trained_parts': [item['part_id'] for item in data] if 'data' in locals() else []\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    registry_response = supabase.table('model_registry').insert(model_registry_data).execute()\n",
        "    print(\"âœ… ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "print(\"ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
        "print(\"âœ… Cell 4: YOLO11n í•™ìŠµ ì™„ë£Œ\")\n",
        "print(\"âœ… Cell 5: í•™ìŠµ ê²°ê³¼ ë¶„ì„ ì™„ë£Œ\") \n",
        "print(\"âœ… Cell 6: ONNX ë³€í™˜ ë° ì—…ë¡œë“œ ì™„ë£Œ\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
