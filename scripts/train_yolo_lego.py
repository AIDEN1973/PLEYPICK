#!/usr/bin/env python3
"""
ğŸ§± BrickBox ë ˆê³  ë¶€í’ˆ YOLO ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ë Œë”ë§ ì™„ë£Œ í›„ ë³„ë„ë¡œ ì‹¤í–‰í•˜ëŠ” YOLO í•™ìŠµ íŒŒì´í”„ë¼ì¸
- ë°ì´í„°ì…‹ ê²€ì¦ ë° ì¤€ë¹„
- YOLO ëª¨ë¸ í•™ìŠµ
- ì„±ëŠ¥ í‰ê°€ ë° ê²€ì¦
- ëª¨ë¸ ë°°í¬ ë° êµì²´
"""

import os
import sys
import json
import yaml
import shutil
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import argparse

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

try:
    from ultralytics import YOLO
    import torch
    YOLO_AVAILABLE = True
except ImportError:
    print("âš ï¸ ultralyticsë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install ultralytics")
    YOLO_AVAILABLE = False

try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    print("âš ï¸ supabaseë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install supabase")
    SUPABASE_AVAILABLE = False

class LegoYOLOTrainer:
    """ë ˆê³  ë¶€í’ˆ YOLO ëª¨ë¸ í•™ìŠµ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = None):
        self.project_root = project_root
        self.output_dir = project_root / "output" / "synthetic"
        self.models_dir = project_root / "public" / "models"
        self.training_dir = project_root / "output" / "training"
        
        # ì„¤ì • ë¡œë“œ
        self.config = self.load_config(config_path)
        
        # Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.supabase = self.init_supabase() if SUPABASE_AVAILABLE else None
        
        # ë¡œê¹… ì„¤ì •
        self.setup_logging()
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.create_directories()
    
    def load_config(self, config_path: str = None) -> Dict:
        """í•™ìŠµ ì„¤ì • ë¡œë“œ"""
        default_config = {
            'model': {
                'base_model': 'yolo11n.pt',  # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸
                'input_size': 640,
                'classes': ['lego_part'],
                'num_classes': 1
            },
            'training': {
                'epochs': 100,
                'batch_size': 16,
                'imgsz': 640,
                'device': 'auto',
                'patience': 10,
                'save_period': 10,
                'lr0': 0.01,
                'lrf': 0.01,
                'momentum': 0.937,
                'weight_decay': 0.0005,
                'warmup_epochs': 3,
                'warmup_momentum': 0.8,
                'warmup_bias_lr': 0.1
            },
            'data': {
                'train_split': 0.8,
                'val_split': 0.1,
                'test_split': 0.1,
                'augment': True,
                'hsv_h': 0.015,
                'hsv_s': 0.7,
                'hsv_v': 0.4,
                'degrees': 0.0,
                'translate': 0.1,
                'scale': 0.5,
                'shear': 0.0,
                'perspective': 0.0,
                'flipud': 0.0,
                'fliplr': 0.5,
                'mosaic': 1.0,
                'mixup': 0.0,
                'copy_paste': 0.0
            },
            'validation': {
                'conf_threshold': 0.25,
                'iou_threshold': 0.45,
                'max_det': 300,
                'save_json': True,
                'save_hybrid': False,
                'verbose': True
            }
        }
        
        if config_path and Path(config_path).exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = yaml.safe_load(f)
                # ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ê¸°ë³¸ ì„¤ì • ì—…ë°ì´íŠ¸
                self.update_config(default_config, user_config)
        
        return default_config
    
    def init_supabase(self) -> Optional[Client]:
        """Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            import os
            from dotenv import load_dotenv
            load_dotenv()
            
            supabase_url = os.getenv('VITE_SUPABASE_URL')
            supabase_key = os.getenv('VITE_SUPABASE_ANON_KEY')
            
            if not supabase_url or not supabase_key:
                self.logger.warning("âš ï¸ Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return None
            
            return create_client(supabase_url, supabase_key)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Supabase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    def update_config(self, base_config: Dict, user_config: Dict):
        """ì„¤ì • ì—…ë°ì´íŠ¸ (ì¬ê·€ì )"""
        for key, value in user_config.items():
            if key in base_config and isinstance(base_config[key], dict) and isinstance(value, dict):
                self.update_config(base_config[key], value)
            else:
                base_config[key] = value
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        log_dir = self.training_dir / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_dir / f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        directories = [
            self.training_dir,
            self.training_dir / "datasets",
            self.training_dir / "runs",
            self.training_dir / "logs",
            self.training_dir / "weights"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            self.logger.info(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {directory}")
    
    def log_training_event(self, status: str, message: str, metadata: Dict = None):
        """í•™ìŠµ ì´ë²¤íŠ¸ë¥¼ Supabaseì— ë¡œê¹…"""
        if not self.supabase:
            return
        
        try:
            event_data = {
                'operation_type': 'training',
                'status': status,
                'message': message,
                'metadata': metadata or {}
            }
            
            result = self.supabase.table('operation_logs').insert(event_data).execute()
            self.logger.info(f"ğŸ“Š í•™ìŠµ ì´ë²¤íŠ¸ ë¡œê¹…: {status} - {message}")
            
        except Exception as e:
            self.logger.error(f"âŒ í•™ìŠµ ì´ë²¤íŠ¸ ë¡œê¹… ì‹¤íŒ¨: {e}")
    
    def update_synthetic_part_stats(self, part_id: str, total_images: int, total_annotations: int):
        """synthetic_part_stats í…Œì´ë¸” ì—…ë°ì´íŠ¸"""
        if not self.supabase:
            return
        
        try:
            stats_data = {
                'part_id': part_id,
                'total_images': total_images,
                'total_annotations': total_annotations,
                'last_updated': datetime.now().isoformat()
            }
            
            # UPSERT (ì¡´ì¬í•˜ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…)
            result = self.supabase.table('synthetic_part_stats').upsert(stats_data).execute()
            self.logger.info(f"ğŸ“Š ë¶€í’ˆ í†µê³„ ì—…ë°ì´íŠ¸: {part_id} - {total_images}ê°œ ì´ë¯¸ì§€")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¶€í’ˆ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def update_parts_master_features(self, part_id: str, detection_accuracy: float, precision_score: float, recall_score: float):
        """parts_master_features í…Œì´ë¸”ì˜ ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸"""
        if not self.supabase:
            return
        
        try:
            # score_final ê³„ì‚° (ê°€ì¤‘ í‰ê· )
            score_final = (detection_accuracy * 0.4 + precision_score * 0.3 + recall_score * 0.3)
            
            update_data = {
                'detection_accuracy': detection_accuracy,
                'precision_score': precision_score,
                'recall_score': recall_score,
                'score_final': score_final,
                'updated_at': datetime.now().isoformat()
            }
            
            result = self.supabase.table('parts_master_features').update(update_data).eq('part_id', part_id).execute()
            self.logger.info(f"ğŸ“Š ë¶€í’ˆ ì„±ëŠ¥ ì—…ë°ì´íŠ¸: {part_id} - ì •í™•ë„: {detection_accuracy:.3f}")
            
        except Exception as e:
            self.logger.error(f"âŒ ë¶€í’ˆ ì„±ëŠ¥ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def validate_dataset(self) -> Tuple[bool, Dict]:
        """ë°ì´í„°ì…‹ ê²€ì¦"""
        self.logger.info("ğŸ” ë°ì´í„°ì…‹ ê²€ì¦ ì‹œì‘...")
        
        validation_result = {
            'valid': False,
            'total_images': 0,
            'total_labels': 0,
            'missing_files': [],
            'invalid_annotations': [],
            'class_distribution': {},
            'image_formats': set(),
            'label_formats': set()
        }
        
        try:
            # ì´ë¯¸ì§€ ë° ë¼ë²¨ ë””ë ‰í† ë¦¬ í™•ì¸
            images_dir = self.output_dir / "images"
            labels_dir = self.output_dir / "labels"
            
            if not images_dir.exists() or not labels_dir.exists():
                self.logger.error("âŒ ì´ë¯¸ì§€ ë˜ëŠ” ë¼ë²¨ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False, validation_result
            
            # í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í•  í™•ì¸
            for split in ['train', 'val', 'test']:
                split_images_dir = images_dir / split
                split_labels_dir = labels_dir / split
                
                if not split_images_dir.exists() or not split_labels_dir.exists():
                    self.logger.warning(f"âš ï¸ {split} ë¶„í•  ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                    continue
                
                # ì´ë¯¸ì§€ íŒŒì¼ ê²€ì‚¬
                image_files = list(split_images_dir.glob("*.webp"))
                label_files = list(split_labels_dir.glob("*.txt"))
                
                self.logger.info(f"ğŸ“Š {split} ë¶„í• : {len(image_files)}ê°œ ì´ë¯¸ì§€, {len(label_files)}ê°œ ë¼ë²¨")
                
                # íŒŒì¼ ë§¤ì¹­ ê²€ì‚¬
                for img_file in image_files:
                    label_file = split_labels_dir / f"{img_file.stem}.txt"
                    if not label_file.exists():
                        validation_result['missing_files'].append(str(label_file))
                
                validation_result['total_images'] += len(image_files)
                validation_result['total_labels'] += len(label_files)
            
            # YOLO ì„¤ì • íŒŒì¼ ìƒì„±
            self.create_yolo_config()
            
            validation_result['valid'] = True
            self.logger.info(f"âœ… ë°ì´í„°ì…‹ ê²€ì¦ ì™„ë£Œ: {validation_result['total_images']}ê°œ ì´ë¯¸ì§€, {validation_result['total_labels']}ê°œ ë¼ë²¨")
            
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„°ì…‹ ê²€ì¦ ì‹¤íŒ¨: {e}")
            validation_result['error'] = str(e)
        
        return validation_result['valid'], validation_result
    
    def create_yolo_config(self):
        """YOLO ì„¤ì • íŒŒì¼ ìƒì„±"""
        config_path = self.output_dir / "data.yaml"
        
        yolo_config = {
            'path': str(self.output_dir.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'test': 'images/test',
            'nc': self.config['model']['num_classes'],
            'names': self.config['model']['classes']
        }
        
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(yolo_config, f, default_flow_style=False, allow_unicode=True)
        
        self.logger.info(f"ğŸ“ YOLO ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
    
    def train_model(self) -> Dict:
        """YOLO ëª¨ë¸ í•™ìŠµ"""
        if not YOLO_AVAILABLE:
            raise ImportError("ultralyticsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        self.logger.info("ğŸš€ YOLO ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        # í•™ìŠµ ì‹œì‘ ì´ë²¤íŠ¸ ë¡œê¹…
        self.log_training_event('running', 'YOLO ëª¨ë¸ í•™ìŠµ ì‹œì‘', {
            'epochs': self.config['training']['epochs'],
            'batch_size': self.config['training']['batch_size'],
            'device': self.config['training']['device']
        })
        
        try:
            # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
            model = YOLO(self.config['model']['base_model'])
            
            # í•™ìŠµ ì„¤ì •
            train_config = self.config['training']
            data_config = self.config['data']
            
            # í•™ìŠµ ì‹¤í–‰
            results = model.train(
                data=str(self.output_dir / "data.yaml"),
                epochs=train_config['epochs'],
                imgsz=train_config['imgsz'],
                batch=train_config['batch_size'],
                device=train_config['device'],
                patience=train_config['patience'],
                save_period=train_config['save_period'],
                lr0=train_config['lr0'],
                lrf=train_config['lrf'],
                momentum=train_config['momentum'],
                weight_decay=train_config['weight_decay'],
                warmup_epochs=train_config['warmup_epochs'],
                warmup_momentum=train_config['warmup_momentum'],
                warmup_bias_lr=train_config['warmup_bias_lr'],
                # ë°ì´í„° ì¦ê°• ì„¤ì •
                hsv_h=data_config['hsv_h'],
                hsv_s=data_config['hsv_s'],
                hsv_v=data_config['hsv_v'],
                degrees=data_config['degrees'],
                translate=data_config['translate'],
                scale=data_config['scale'],
                shear=data_config['shear'],
                perspective=data_config['perspective'],
                flipud=data_config['flipud'],
                fliplr=data_config['fliplr'],
                mosaic=data_config['mosaic'],
                mixup=data_config['mixup'],
                copy_paste=data_config['copy_paste'],
                # ì¶œë ¥ ë””ë ‰í† ë¦¬
                project=str(self.training_dir / "runs"),
                name="lego_yolo_training"
            )
            
            self.logger.info("âœ… YOLO ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
            
            # í•™ìŠµ ì™„ë£Œ ì´ë²¤íŠ¸ ë¡œê¹…
            self.log_training_event('completed', 'YOLO ëª¨ë¸ í•™ìŠµ ì™„ë£Œ', {
                'model_path': str(results.save_dir / "weights" / "best.pt"),
                'training_time': getattr(results, 'training_time', None)
            })
            
            # í•™ìŠµ ê²°ê³¼ ì €ì¥
            training_results = {
                'model_path': str(results.save_dir / "weights" / "best.pt"),
                'last_model_path': str(results.save_dir / "weights" / "last.pt"),
                'results_path': str(results.save_dir),
                'metrics': results.results_dict if hasattr(results, 'results_dict') else {},
                'training_time': getattr(results, 'training_time', None)
            }
            
            return training_results
            
        except Exception as e:
            # í•™ìŠµ ì‹¤íŒ¨ ì´ë²¤íŠ¸ ë¡œê¹…
            self.log_training_event('failed', f'YOLO ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}', {
                'error': str(e)
            })
            self.logger.error(f"âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            raise
    
    def validate_model(self, model_path: str) -> Dict:
        """í•™ìŠµëœ ëª¨ë¸ ê²€ì¦"""
        self.logger.info("ğŸ” í•™ìŠµëœ ëª¨ë¸ ê²€ì¦ ì‹œì‘...")
        
        try:
            model = YOLO(model_path)
            
            # ê²€ì¦ ì‹¤í–‰
            val_config = self.config['validation']
            results = model.val(
                data=str(self.output_dir / "data.yaml"),
                conf=val_config['conf_threshold'],
                iou=val_config['iou_threshold'],
                max_det=val_config['max_det'],
                save_json=val_config['save_json'],
                save_hybrid=val_config['save_hybrid'],
                verbose=val_config['verbose']
            )
            
            # ì•ˆì „í•œ ë©”íŠ¸ë¦­ ì¶”ì¶œ
            validation_metrics = {
                'mAP50': 0,
                'mAP50_95': 0,
                'precision': 0,
                'recall': 0,
                'f1_score': 0
            }
            
            # results.boxê°€ ìˆëŠ” ê²½ìš° ì•ˆì „í•˜ê²Œ ì ‘ê·¼
            if hasattr(results, 'box') and results.box is not None:
                validation_metrics['mAP50'] = getattr(results.box, 'map50', 0)
                validation_metrics['mAP50_95'] = getattr(results.box, 'map', 0)
                validation_metrics['precision'] = getattr(results.box, 'mp', 0)
                validation_metrics['recall'] = getattr(results.box, 'mr', 0)
                
                # F1 ìŠ¤ì½”ì–´ ê³„ì‚° (ì•ˆì „í•˜ê²Œ)
                if validation_metrics['precision'] > 0 and validation_metrics['recall'] > 0:
                    validation_metrics['f1_score'] = 2 * (validation_metrics['precision'] * validation_metrics['recall']) / (validation_metrics['precision'] + validation_metrics['recall'])
            
            # results.metricsê°€ ìˆëŠ” ê²½ìš° ëŒ€ì•ˆìœ¼ë¡œ ì‚¬ìš©
            elif hasattr(results, 'metrics') and results.metrics is not None:
                metrics = results.metrics
                validation_metrics['mAP50'] = metrics.get('mAP50', 0)
                validation_metrics['mAP50_95'] = metrics.get('mAP50-95', 0)
                validation_metrics['precision'] = metrics.get('precision', 0)
                validation_metrics['recall'] = metrics.get('recall', 0)
                validation_metrics['f1_score'] = metrics.get('f1', 0)
            
            # vars(results)ë¡œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼
            else:
                try:
                    results_dict = vars(results)
                    validation_metrics['mAP50'] = results_dict.get('mAP50', 0)
                    validation_metrics['mAP50_95'] = results_dict.get('mAP50-95', 0)
                    validation_metrics['precision'] = results_dict.get('precision', 0)
                    validation_metrics['recall'] = results_dict.get('recall', 0)
                except:
                    self.logger.warning("âš ï¸ ë©”íŠ¸ë¦­ ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
            
            self.logger.info(f"ğŸ“Š ëª¨ë¸ ê²€ì¦ ê²°ê³¼: mAP50={validation_metrics['mAP50']:.3f}, mAP50-95={validation_metrics['mAP50_95']:.3f}")
            
            return validation_metrics
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            raise
    
    def deploy_model(self, model_path: str) -> str:
        """í•™ìŠµëœ ëª¨ë¸ ë°°í¬"""
        self.logger.info("ğŸš€ í•™ìŠµëœ ëª¨ë¸ ë°°í¬ ì‹œì‘...")
        
        try:
            # ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            model = YOLO(model_path)
            onnx_path = model.export(format='onnx', imgsz=self.config['model']['input_size'])
            
            # ë°°í¬ìš© íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            deployed_model_name = f"lego_yolo_custom_{timestamp}.onnx"
            deployed_model_path = self.models_dir / deployed_model_name
            
            # ëª¨ë¸ íŒŒì¼ ë³µì‚¬
            shutil.copy2(onnx_path, deployed_model_path)
            
            # ê¸°ì¡´ ëª¨ë¸ ë°±ì—… (ìˆëŠ” ê²½ìš°)
            old_model_path = self.models_dir / "lego_yolo_custom.onnx"
            if old_model_path.exists():
                backup_path = self.models_dir / f"lego_yolo_custom_backup_{timestamp}.onnx"
                shutil.copy2(old_model_path, backup_path)
                self.logger.info(f"ğŸ“¦ ê¸°ì¡´ ëª¨ë¸ ë°±ì—…: {backup_path}")
            
            # ìƒˆ ëª¨ë¸ì„ ê¸°ë³¸ ëª¨ë¸ë¡œ ì„¤ì •
            shutil.copy2(deployed_model_path, old_model_path)
            
            self.logger.info(f"âœ… ëª¨ë¸ ë°°í¬ ì™„ë£Œ: {deployed_model_path}")
            self.logger.info(f"âœ… ê¸°ë³¸ ëª¨ë¸ ì—…ë°ì´íŠ¸: {old_model_path}")
            
            return str(deployed_model_path)
            
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë°°í¬ ì‹¤íŒ¨: {e}")
            raise
    
    def run_full_pipeline(self) -> Dict:
        """ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("ğŸ¯ ë ˆê³  YOLO í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
        
        pipeline_results = {
            'start_time': datetime.now(),
            'dataset_validation': None,
            'training': None,
            'validation': None,
            'deployment': None,
            'success': False,
            'error': None
        }
        
        try:
            # 1. ë°ì´í„°ì…‹ ê²€ì¦
            self.logger.info("ğŸ“Š 1ë‹¨ê³„: ë°ì´í„°ì…‹ ê²€ì¦")
            is_valid, validation_info = self.validate_dataset()
            if not is_valid:
                raise ValueError(f"ë°ì´í„°ì…‹ ê²€ì¦ ì‹¤íŒ¨: {validation_info}")
            pipeline_results['dataset_validation'] = validation_info
            
            # 2. ëª¨ë¸ í•™ìŠµ
            self.logger.info("ğŸš€ 2ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ")
            training_results = self.train_model()
            pipeline_results['training'] = training_results
            
            # 3. ëª¨ë¸ ê²€ì¦
            self.logger.info("ğŸ” 3ë‹¨ê³„: ëª¨ë¸ ê²€ì¦")
            validation_metrics = self.validate_model(training_results['model_path'])
            pipeline_results['validation'] = validation_metrics
            
            # 4. ëª¨ë¸ ë°°í¬
            self.logger.info("ğŸš€ 4ë‹¨ê³„: ëª¨ë¸ ë°°í¬")
            deployed_path = self.deploy_model(training_results['model_path'])
            pipeline_results['deployment'] = {'deployed_path': deployed_path}
            
            pipeline_results['success'] = True
            pipeline_results['end_time'] = datetime.now()
            
            self.logger.info("ğŸ‰ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            
        except Exception as e:
            pipeline_results['error'] = str(e)
            pipeline_results['end_time'] = datetime.now()
            self.logger.error(f"âŒ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
        
        # ê²°ê³¼ ì €ì¥
        results_file = self.training_dir / f"pipeline_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(pipeline_results, f, indent=2, ensure_ascii=False, default=str)
        
        return pipeline_results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë ˆê³  ë¶€í’ˆ YOLO ëª¨ë¸ í•™ìŠµ')
    parser.add_argument('--config', type=str, help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--validate-only', action='store_true', help='ë°ì´í„°ì…‹ ê²€ì¦ë§Œ ì‹¤í–‰')
    parser.add_argument('--train-only', action='store_true', help='í•™ìŠµë§Œ ì‹¤í–‰')
    parser.add_argument('--validate-model', type=str, help='íŠ¹ì • ëª¨ë¸ ê²€ì¦')
    parser.add_argument('--deploy-model', type=str, help='íŠ¹ì • ëª¨ë¸ ë°°í¬')
    parser.add_argument('--device', type=str, default='auto', help='í•™ìŠµ ë””ë°”ì´ìŠ¤ (auto, cpu, cuda, cuda:0, cuda:1)')
    parser.add_argument('--epochs', type=int, help='í•™ìŠµ ì—í¬í¬ ìˆ˜')
    parser.add_argument('--batch-size', type=int, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--gpu-memory-fraction', type=float, default=0.8, help='GPU ë©”ëª¨ë¦¬ ì‚¬ìš© ë¹„ìœ¨ (0.0-1.0)')
    
    args = parser.parse_args()
    
    # í•™ìŠµê¸° ì´ˆê¸°í™”
    trainer = LegoYOLOTrainer(args.config)
    
    # CLI ì¸ìë¡œ ì„¤ì • ì—…ë°ì´íŠ¸
    if args.device != 'auto':
        trainer.config['training']['device'] = args.device
    if args.epochs:
        trainer.config['training']['epochs'] = args.epochs
    if args.batch_size:
        trainer.config['training']['batch_size'] = args.batch_size
    
    # GPU ë©”ëª¨ë¦¬ ì„¤ì •
    if args.device.startswith('cuda') and args.gpu_memory_fraction < 1.0:
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.set_per_process_memory_fraction(args.gpu_memory_fraction)
                print(f"ğŸ”§ GPU ë©”ëª¨ë¦¬ ì‚¬ìš© ë¹„ìœ¨ ì„¤ì •: {args.gpu_memory_fraction}")
        except Exception as e:
            print(f"âš ï¸ GPU ë©”ëª¨ë¦¬ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    try:
        if args.validate_only:
            # ë°ì´í„°ì…‹ ê²€ì¦ë§Œ ì‹¤í–‰
            is_valid, info = trainer.validate_dataset()
            print(f"ë°ì´í„°ì…‹ ê²€ì¦ ê²°ê³¼: {'ì„±ê³µ' if is_valid else 'ì‹¤íŒ¨'}")
            print(json.dumps(info, indent=2, ensure_ascii=False))
            
        elif args.validate_model:
            # íŠ¹ì • ëª¨ë¸ ê²€ì¦
            metrics = trainer.validate_model(args.validate_model)
            print("ëª¨ë¸ ê²€ì¦ ê²°ê³¼:")
            print(json.dumps(metrics, indent=2, ensure_ascii=False))
            
        elif args.deploy_model:
            # íŠ¹ì • ëª¨ë¸ ë°°í¬
            deployed_path = trainer.deploy_model(args.deploy_model)
            print(f"ëª¨ë¸ ë°°í¬ ì™„ë£Œ: {deployed_path}")
            
        elif args.train_only:
            # í•™ìŠµë§Œ ì‹¤í–‰
            results = trainer.train_model()
            print("í•™ìŠµ ì™„ë£Œ:")
            print(json.dumps(results, indent=2, ensure_ascii=False))
            
        else:
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            results = trainer.run_full_pipeline()
            print("í•™ìŠµ íŒŒì´í”„ë¼ì¸ ê²°ê³¼:")
            print(json.dumps(results, indent=2, ensure_ascii=False))
            
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
