#!/usr/bin/env python3
"""
ì •ë°€ ì˜¤ë¥˜ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
- ë…¼ë¦¬ì  ì˜¤ë¥˜ ê²€ì¦
- ê²½ê³„ ì¡°ê±´ ë¶„ì„
- ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
- ì‹¤ì œ ì‹¤í–‰ ê°€ëŠ¥ì„± ê²€ì¦
"""

import ast
import re
import sys
from pathlib import Path
from typing import List, Tuple, Dict, Any

class DeepErrorAnalyzer:
    """ì •ë°€ ì˜¤ë¥˜ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.critical_errors = []
        self.warnings = []
        self.info = []
    
    def analyze_pnp_point_matching(self, file_path: str) -> List[Tuple[str, str]]:
        """PnP íŠ¹ì§•ì  ë§¤ì¹­ ë¡œì§ ë¶„ì„"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        except Exception as e:
            issues.append(("ERROR", f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}"))
            return issues
        
        # 3D-2D ì  ë§¤ì¹­ ë¡œì§ ì°¾ê¸°
        in_pnp_section = False
        obj_points_collect = False
        img_points_collect = False
        obj_points_count = 0
        img_points_count = 0
        
        for i, line in enumerate(lines, 1):
            if '_calculate_rms' in line and 'def' in line:
                in_pnp_section = True
                continue
            
            if in_pnp_section:
                if 'obj_points_3d.append' in line:
                    obj_points_collect = True
                    obj_points_count += 1
                
                if 'img_points_2d.append' in line:
                    img_points_collect = True
                    img_points_count += 1
                
                # ë°°ì—´ ìƒì„± ë¶€ë¶„ í™•ì¸
                if 'np.array(obj_points_3d' in line:
                    # ê¸¸ì´ ë¶ˆì¼ì¹˜ í™•ì¸
                    if '[:len(img_points_2d)]' in line:
                        issues.append(("INFO", f"âœ… 3D-2D ì  ê¸¸ì´ ë™ê¸°í™” ë¡œì§ ì¡´ì¬ (line {i})"))
                    elif 'obj_points_3d' in line and 'len' not in line:
                        issues.append(("ERROR", f"3D-2D ì  ê¸¸ì´ ë™ê¸°í™” ì—†ìŒ (line {i}) - ë¶ˆì¼ì¹˜ ì˜¤ë¥˜ ê°€ëŠ¥"))
                
                if 'np.array(img_points_2d' in line:
                    if 'len' not in line or '[:len' in line:
                        issues.append(("INFO", f"âœ… img_points_2d ë°°ì—´ ìƒì„± ë¡œì§ í™•ì¸ (line {i})"))
                
                # í•¨ìˆ˜ ì¢…ë£Œ í™•ì¸
                if 'def ' in line and i > 1:
                    break
        
        # íŠ¹ì§•ì  ìˆ˜ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„± ë¶„ì„
        if obj_points_collect and img_points_collect:
            issues.append(("INFO", "âœ… 3D ë° 2D íŠ¹ì§•ì  ìˆ˜ì§‘ ë¡œì§ ì¡´ì¬"))
            issues.append(("WARNING", f"3D ì : {obj_points_count}ê°œ, 2D ì : {img_points_count}ê°œ - ë™ê¸°í™” ë¡œì§ í•„ìš”"))
        
        return issues
    
    def analyze_depth_map_reading(self, file_path: str) -> List[Tuple[str, str]]:
        """ê¹Šì´ ë§µ ì½ê¸° ë¡œì§ ë¶„ì„"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            issues.append(("ERROR", f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}"))
            return issues
        
        # OpenEXR ì½ê¸° ë¡œì§ í™•ì¸
        if 'OpenEXR.InputFile' in content:
            issues.append(("INFO", "âœ… OpenEXR íŒŒì¼ ì½ê¸° ë¡œì§ ì¡´ì¬"))
        else:
            issues.append(("ERROR", "OpenEXR íŒŒì¼ ì½ê¸° ë¡œì§ ì—†ìŒ"))
        
        # ì±„ë„ ì½ê¸° í™•ì¸
        channel_patterns = [
            (r"channel\('Z'", "Z ì±„ë„"),
            (r"channel\('Depth'", "Depth ì±„ë„"),
            (r"channel\('R'", "R ì±„ë„ (í´ë°±)")
        ]
        
        for pattern, name in channel_patterns:
            if re.search(pattern, content):
                issues.append(("INFO", f"âœ… {name} ì½ê¸° ë¡œì§ ì¡´ì¬"))
        
        # NumPy ë³€í™˜ í™•ì¸
        if 'np.frombuffer' in content:
            issues.append(("INFO", "âœ… NumPy ë³€í™˜ ë¡œì§ ì¡´ì¬ (frombuffer)"))
            # bytes/str ì²˜ë¦¬ í™•ì¸
            if 'isinstance(depth_channel, bytes)' in content:
                issues.append(("INFO", "âœ… bytes/str íƒ€ì… ì²˜ë¦¬ ë¡œì§ ì¡´ì¬"))
            else:
                issues.append(("WARNING", "bytes/str íƒ€ì… ì²˜ë¦¬ ë¡œì§ í™•ì¸ í•„ìš”"))
        elif 'np.fromstring' in content:
            issues.append(("WARNING", "fromstring ì‚¬ìš© (deprecated, frombuffer ê¶Œì¥)"))
        
        # reshape í™•ì¸
        if 'reshape((height, width))' in content:
            issues.append(("INFO", "âœ… reshape ë¡œì§ ì¡´ì¬"))
        else:
            issues.append(("WARNING", "reshape ë¡œì§ í™•ì¸ í•„ìš”"))
        
        return issues
    
    def analyze_camera_parameter_calculation(self, file_path: str) -> List[Tuple[str, str]]:
        """ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ê³„ì‚° ë¡œì§ ë¶„ì„"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            issues.append(("ERROR", f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}"))
            return issues
        
        # K í–‰ë ¬ ê³„ì‚° í™•ì¸
        k_matrix_checks = [
            ('fx =', 'fx ê³„ì‚°'),
            ('fy =', 'fy ê³„ì‚°'),
            ('cx =', 'cx ê³„ì‚° (ì£¼ì  X)'),
            ('cy =', 'cy ê³„ì‚° (ì£¼ì  Y)'),
            ('K = [', 'K í–‰ë ¬ ìƒì„±')
        ]
        
        for check, name in k_matrix_checks:
            if check in content:
                issues.append(("INFO", f"âœ… {name} ë¡œì§ ì¡´ì¬"))
            else:
                issues.append(("WARNING", f"{name} ë¡œì§ í™•ì¸ í•„ìš”"))
        
        # ì„¼ì„œ í¬ê¸° ê³„ì‚° í™•ì¸
        if 'sensor_height_mm' in content and 'sensor_fit' in content:
            issues.append(("INFO", "âœ… ì„¼ì„œ í¬ê¸° ê³„ì‚° ë¡œì§ ì¡´ì¬ (sensor_fit ê³ ë ¤)"))
        else:
            issues.append(("WARNING", "ì„¼ì„œ í¬ê¸° ê³„ì‚° ë¡œì§ í™•ì¸ í•„ìš”"))
        
        # R, t ê³„ì‚° í™•ì¸
        if 'rotation_matrix_3x3' in content and 'translation' in content:
            issues.append(("INFO", "âœ… R, t ê³„ì‚° ë¡œì§ ì¡´ì¬"))
        else:
            issues.append(("WARNING", "R, t ê³„ì‚° ë¡œì§ í™•ì¸ í•„ìš”"))
        
        # ì™œê³¡ ê³„ìˆ˜ í™•ì¸
        if 'distortion_coeffs' in content:
            if 'k1' in content and 'k2' in content:
                issues.append(("INFO", "âœ… ì™œê³¡ ê³„ìˆ˜ ì„¤ì • ì¡´ì¬"))
            else:
                issues.append(("WARNING", "ì™œê³¡ ê³„ìˆ˜ ì„¤ì • ë¶ˆì™„ì „"))
        
        return issues
    
    def analyze_depth_map_file_handling(self, file_path: str) -> List[Tuple[str, str]]:
        """ê¹Šì´ ë§µ íŒŒì¼ ì²˜ë¦¬ ë¡œì§ ë¶„ì„"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            issues.append(("ERROR", f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}"))
            return issues
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì • í™•ì¸
        if '_configure_depth_output_path' in content:
            issues.append(("INFO", "âœ… ê¹Šì´ ë§µ ì¶œë ¥ ê²½ë¡œ ì„¤ì • í•¨ìˆ˜ ì¡´ì¬"))
        else:
            issues.append(("ERROR", "ê¹Šì´ ë§µ ì¶œë ¥ ê²½ë¡œ ì„¤ì • í•¨ìˆ˜ ì—†ìŒ"))
        
        # íŒŒì¼ ì°¾ê¸° ë¡œì§ í™•ì¸
        if '_locate_rendered_depth_map' in content:
            issues.append(("INFO", "âœ… ë Œë”ëœ ê¹Šì´ ë§µ íŒŒì¼ ì°¾ê¸° í•¨ìˆ˜ ì¡´ì¬"))
            # ì—¬ëŸ¬ íŒ¨í„´ ê²€ìƒ‰ í™•ì¸
            if 'possible_names' in content or 'exr' in content.lower():
                issues.append(("INFO", "âœ… íŒŒì¼ëª… íŒ¨í„´ ê²€ìƒ‰ ë¡œì§ ì¡´ì¬"))
        else:
            issues.append(("ERROR", "ë Œë”ëœ ê¹Šì´ ë§µ íŒŒì¼ ì°¾ê¸° í•¨ìˆ˜ ì—†ìŒ"))
        
        # íŒŒì¼ ì´ë™ ë¡œì§ í™•ì¸
        if 'shutil.move' in content and 'depth_path' in content:
            issues.append(("INFO", "âœ… ê¹Šì´ ë§µ íŒŒì¼ ì´ë™ ë¡œì§ ì¡´ì¬"))
        else:
            issues.append(("WARNING", "ê¹Šì´ ë§µ íŒŒì¼ ì´ë™ ë¡œì§ í™•ì¸ í•„ìš”"))
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if 'os.path.exists(depth_path)' in content or 'os.path.exists(actual_depth_path)' in content:
            issues.append(("INFO", "âœ… íŒŒì¼ ì¡´ì¬ í™•ì¸ ë¡œì§ ì¡´ì¬"))
        else:
            issues.append(("WARNING", "íŒŒì¼ ì¡´ì¬ í™•ì¸ ë¡œì§ í™•ì¸ í•„ìš”"))
        
        return issues
    
    def analyze_quality_threshold_consistency(self, file_path: str) -> List[Tuple[str, str]]:
        """í’ˆì§ˆ ê¸°ì¤€ ì¼ê´€ì„± ë¶„ì„"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            issues.append(("ERROR", f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}"))
            return issues
        
        # ëª¨ë“  RMS ê¸°ì¤€ í™•ì¸
        rms_patterns = re.findall(r'rms.*?<=\s*([\d.]+)', content, re.IGNORECASE)
        rms_values = [float(v) for v in rms_patterns if v.replace('.', '').isdigit()]
        
        unique_rms = set(rms_values)
        if len(unique_rms) == 1 and 1.5 in unique_rms:
            issues.append(("INFO", "âœ… RMS ê¸°ì¤€ ì¼ê´€ì„±: ëª¨ë“  ìœ„ì¹˜ì—ì„œ 1.5px"))
        elif 1.5 in unique_rms:
            issues.append(("ERROR", f"RMS ê¸°ì¤€ ë¶ˆì¼ì¹˜: {unique_rms} (ê¸°ìˆ ë¬¸ì„œ: 1.5px)"))
        else:
            issues.append(("ERROR", f"RMS ê¸°ì¤€ ì˜¤ë¥˜: {unique_rms} (ê¸°ìˆ ë¬¸ì„œ: 1.5px)"))
        
        # ëª¨ë“  Depth ê¸°ì¤€ í™•ì¸
        depth_patterns = re.findall(r'depth.*?>=\s*([\d.]+)', content, re.IGNORECASE)
        depth_values = [float(v) for v in depth_patterns if v.replace('.', '').isdigit()]
        
        unique_depth = set(depth_values)
        if len(unique_depth) == 1 and 0.85 in unique_depth:
            issues.append(("INFO", "âœ… Depth ê¸°ì¤€ ì¼ê´€ì„±: ëª¨ë“  ìœ„ì¹˜ì—ì„œ 0.85"))
        elif 0.85 in unique_depth:
            issues.append(("ERROR", f"Depth ê¸°ì¤€ ë¶ˆì¼ì¹˜: {unique_depth} (ê¸°ìˆ ë¬¸ì„œ: 0.85)"))
        else:
            issues.append(("ERROR", f"Depth ê¸°ì¤€ ì˜¤ë¥˜: {unique_depth} (ê¸°ìˆ ë¬¸ì„œ: 0.85)"))
        
        return issues
    
    def analyze_error_handling(self, file_path: str) -> List[Tuple[str, str]]:
        """ì˜¤ë¥˜ ì²˜ë¦¬ ë¡œì§ ë¶„ì„"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                tree = ast.parse(f.read())
        except Exception as e:
            issues.append(("ERROR", f"íŒŒì‹± ì‹¤íŒ¨: {e}"))
            return issues
        
        # ì£¼ìš” í•¨ìˆ˜ì˜ ì˜¤ë¥˜ ì²˜ë¦¬ í™•ì¸
        critical_functions = [
            '_calculate_rms',
            '_calculate_depth_score',
            '_extract_camera_parameters',
            '_validate_depth_map_exr'
        ]
        
        for func_name in critical_functions:
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef) and node.name == func_name:
                    has_try = False
                    has_except = False
                    has_fallback = False
                    
                    for child in ast.walk(node):
                        if isinstance(child, ast.Try):
                            has_try = True
                            for handler in child.handlers:
                                has_except = True
                                # í´ë°± ë¡œì§ í™•ì¸
                                for stmt in handler.body:
                                    if isinstance(stmt, ast.Return):
                                        has_fallback = True
                    
                    if has_try and has_except:
                        issues.append(("INFO", f"âœ… {func_name}: try-except ë¸”ë¡ ì¡´ì¬"))
                        if has_fallback:
                            issues.append(("INFO", f"âœ… {func_name}: í´ë°± ë¡œì§ ì¡´ì¬"))
                        else:
                            issues.append(("WARNING", f"{func_name}: í´ë°± ë¡œì§ í™•ì¸ í•„ìš”"))
                    else:
                        issues.append(("WARNING", f"{func_name}: ì˜¤ë¥˜ ì²˜ë¦¬ í™•ì¸ í•„ìš”"))
                    
                    break
        
        return issues
    
    def analyze_data_type_consistency(self, file_path: str) -> List[Tuple[str, str]]:
        """ë°ì´í„° íƒ€ì… ì¼ê´€ì„± ë¶„ì„"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            issues.append(("ERROR", f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}"))
            return issues
        
        # NumPy ë°°ì—´ íƒ€ì… í™•ì¸
        if 'dtype=np.float32' in content:
            issues.append(("INFO", "âœ… NumPy float32 íƒ€ì… ì¼ê´€ì„±"))
        else:
            issues.append(("WARNING", "NumPy íƒ€ì… í™•ì¸ í•„ìš”"))
        
        # ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° íƒ€ì… í™•ì¸
        if 'np.array(K)' in content or 'np.array' in content and 'K' in content:
            issues.append(("INFO", "âœ… ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° NumPy ë³€í™˜"))
        else:
            issues.append(("WARNING", "ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° íƒ€ì… ë³€í™˜ í™•ì¸ í•„ìš”"))
        
        return issues
    
    def run_deep_analysis(self, file_path: str) -> Dict[str, Any]:
        """ì „ì²´ ì‹¬ì¸µ ë¶„ì„ ì‹¤í–‰"""
        results = {
            'file': file_path,
            'pnp_point_matching': [],
            'depth_map_reading': [],
            'camera_parameter_calculation': [],
            'depth_map_file_handling': [],
            'quality_threshold_consistency': [],
            'error_handling': [],
            'data_type_consistency': []
        }
        
        print(f"\n{'='*60}")
        print("ì •ë°€ ì˜¤ë¥˜ ë¶„ì„")
        print(f"{'='*60}")
        
        print("\n[1/7] PnP íŠ¹ì§•ì  ë§¤ì¹­ ë¡œì§ ë¶„ì„...")
        results['pnp_point_matching'] = self.analyze_pnp_point_matching(file_path)
        
        print("[2/7] ê¹Šì´ ë§µ ì½ê¸° ë¡œì§ ë¶„ì„...")
        results['depth_map_reading'] = self.analyze_depth_map_reading(file_path)
        
        print("[3/7] ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ê³„ì‚° ë¡œì§ ë¶„ì„...")
        results['camera_parameter_calculation'] = self.analyze_camera_parameter_calculation(file_path)
        
        print("[4/7] ê¹Šì´ ë§µ íŒŒì¼ ì²˜ë¦¬ ë¡œì§ ë¶„ì„...")
        results['depth_map_file_handling'] = self.analyze_depth_map_file_handling(file_path)
        
        print("[5/7] í’ˆì§ˆ ê¸°ì¤€ ì¼ê´€ì„± ë¶„ì„...")
        results['quality_threshold_consistency'] = self.analyze_quality_threshold_consistency(file_path)
        
        print("[6/7] ì˜¤ë¥˜ ì²˜ë¦¬ ë¡œì§ ë¶„ì„...")
        results['error_handling'] = self.analyze_error_handling(file_path)
        
        print("[7/7] ë°ì´í„° íƒ€ì… ì¼ê´€ì„± ë¶„ì„...")
        results['data_type_consistency'] = self.analyze_data_type_consistency(file_path)
        
        return results

def print_deep_results(results: Dict[str, Any]):
    """ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
    all_issues = []
    
    for category, issues in results.items():
        if category == 'file':
            continue
        all_issues.extend(issues)
    
    # ì´ìŠˆ ë¶„ë¥˜
    errors = [i for i in all_issues if i[0] == 'ERROR']
    warnings = [i for i in all_issues if i[0] == 'WARNING']
    infos = [i for i in all_issues if i[0] == 'INFO']
    
    print(f"\n{'='*60}")
    print("ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*60}")
    print(f"âœ… ì •ìƒ: {len(infos)}ê°œ")
    print(f"[WARNING] ê²½ê³ : {len(warnings)}ê°œ")
    print(f"[ERROR] ì˜¤ë¥˜: {len(errors)}ê°œ")
    
    if errors:
        print(f"\n[ERROR] ì‹¬ê°í•œ ì˜¤ë¥˜ ({len(errors)}ê°œ):")
        for err_type, msg in errors:
            print(f"  - {msg}")
    
    if warnings:
        print(f"\n[WARNING] ì£¼ì˜ í•„ìš” ({len(warnings)}ê°œ):")
        for warn_type, msg in warnings:
            print(f"  - {msg}")
    
    # ìƒì„¸ ê²°ê³¼
    print(f"\n{'='*60}")
    print("ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    print(f"{'='*60}")
    
    for category, issues in results.items():
        if category == 'file' or not issues:
            continue
        
        category_name = category.replace('_', ' ').title()
        print(f"\n[{category_name}]")
        
        for issue_type, msg in issues:
            prefix = "  âœ…" if issue_type == "INFO" else "  [WARNING]" if issue_type == "WARNING" else "  [ERROR]"
            print(f"{prefix} {msg}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    analyzer = DeepErrorAnalyzer()
    
    file_path = "scripts/render_ldraw_to_supabase.py"
    
    if not Path(file_path).exists():
        print(f"[ERROR] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
        return 1
    
    results = analyzer.run_deep_analysis(file_path)
    print_deep_results(results)
    
    # ê²°ê³¼ ì €ì¥
    import json
    output_path = "output/deep_error_analysis_report.json"
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œ ì €ì¥: {output_path}")
    
    # ì¢…í•© í‰ê°€
    all_issues = []
    for category, issues in results.items():
        if category != 'file':
            all_issues.extend(issues)
    
    errors = [i for i in all_issues if i[0] == 'ERROR']
    
    if errors:
        print(f"\n[ERROR] ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼: {len(errors)}ê°œ ì˜¤ë¥˜ ë°œê²¬")
        return 1
    else:
        print(f"\nâœ… ì‹¬ì¸µ ë¶„ì„ ì™„ë£Œ: ëª¨ë“  í•­ëª© ì •ìƒ")
        return 0

if __name__ == "__main__":
    sys.exit(main())

