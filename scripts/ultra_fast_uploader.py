#!/usr/bin/env python3 """ BrickBox 초고속 업로더 (극한 최적화) - 동시 업로드 32개 - 청크 업로드 16MB - HTTP/2 Keep-Alive - 메모리 맵핑 - 배치 DB 업데이트 """ import os import sys import asyncio import aiohttp import mmap import time import hashlib from pathlib import Path from typing import List, Dict, Set, Tuple from concurrent.futures import ThreadPoolExecutor import logging from supabase import create_client, Client # 로깅 최소화 logging.basicConfig(level=logging.ERROR) logger = logging.getLogger(__name__) class UltraFastUploader: def __init__(self, supabase_url: str, service_key: str): self.supabase = create_client(supabase_url, service_key) self.session = None self.uploaded_files: Set[str] = set() self.failed_files: List[str] = [] # 극한 성능 설정 self.max_concurrent = 32 # 동시 업로드 수 self.chunk_size = 16 * 1024 * 1024 # 16MB 청크 self.retry_count = 2 self.retry_delay = 0.5 # 메모리 맵핑 캐시 self.file_cache: Dict[str, bytes] = {} self.cache_size_limit = 100 # 최대 100개 파일 캐시 async def __aenter__(self): # HTTP/2 Keep-Alive 연결 풀 connector = aiohttp.TCPConnector( limit=100, limit_per_host=50, keepalive_timeout=300, enable_cleanup_closed=True ) self.session = aiohttp.ClientSession( timeout=aiohttp.ClientTimeout(total=120), connector=connector, headers={ 'Connection': 'keep-alive', 'User-Agent': 'BrickBox-UltraFast/1.0' } ) return self async def __aexit__(self, exc_type, exc_val, exc_tb): if self.session: await self.session.close() def scan_files_optimized(self, base_dir: Path) -> List[Dict]: """최적화된 파일 스캔 (크기순 정렬)""" items = [] extensions = {'.webp', '.png', '.jpg', '.jpeg', '.txt', '.json'} # 병렬 파일 스캔 with ThreadPoolExecutor(max_workers=8) as executor: futures = [] for file_path in base_dir.rglob('*'): if file_path.is_file() and file_path.suffix.lower() in extensions: future = executor.submit(self._get_file_info, file_path) futures.append(future) for future in futures: try: item = future.result(timeout=1) if item: items.append(item) except: continue # 크기순 정렬 (큰 파일 우선) items.sort(key=lambda x: x['size'], reverse=True) return items def _get_file_info(self, file_path: Path) -> Dict: """파일 정보 수집""" try: stat = file_path.stat() part_id = file_path.parent.name file_type = self._get_file_type(file_path.suffix) return { 'file_path': str(file_path), 'part_id': part_id, 'file_type': file_type, 'size': stat.st_size, 'mtime': stat.st_mtime } except: return None def _get_file_type(self, suffix: str) -> str: if suffix.lower() in {'.webp', '.png', '.jpg', '.jpeg'}: return 'image' elif suffix.lower() == '.txt': return 'annotation' elif suffix.lower() == '.json': return 'json' return 'other' async def batch_check_existing(self, part_ids: Set[str]) -> Set[str]: """배치 기존 파일 확인 (최적화)""" existing = set() # Part ID별로 배치 확인 batch_size = 10 part_id_list = list(part_ids) for i in range(0, len(part_id_list), batch_size): batch = part_id_list[i:i + batch_size] # 병렬 확인 tasks = [self._check_part_files(part_id) for part_id in batch] results = await asyncio.gather(*tasks, return_exceptions=True) for result in results: if isinstance(result, set): existing.update(result) return existing async def _check_part_files(self, part_id: str) -> Set[str]: """Part ID별 파일 확인""" try: files = self.supabase.storage.from_("lego-synthetic").list(f"synthetic/{part_id}") if files: return {f"synthetic/{part_id}/{f['name']}" for f in files if f.get('name')} except: pass return set() async def upload_file_ultra_fast(self, item: Dict, existing_files: Set[str]) -> bool: """초고속 파일 업로드""" try: file_path = Path(item['file_path']) filename = file_path.name part_id = item['part_id'] supa_path = f"synthetic/{part_id}/{filename}" # 중복 확인 if supa_path in existing_files: return True # 메모리 맵핑으로 파일 읽기 data = await self._read_file_mmap(file_path) if not data: return False # Content-Type 결정 content_type = self._get_content_type(filename) # 업로드 실행 (재시도 최소화) for attempt in range(self.retry_count): try: response = self.supabase.storage.from_("lego-synthetic").upload( supa_path, data, file_options={ "content-type": content_type, "upsert": True, "cache-control": "public, max-age=31536000" } ) if hasattr(response, 'error') and response.error: raise Exception(f"Upload error: {response.error}") self.uploaded_files.add(supa_path) return True except Exception as e: if attempt < self.retry_count - 1: await asyncio.sleep(self.retry_delay) continue else: self.failed_files.append(filename) return False except Exception as e: self.failed_files.append(item['file_path']) return False async def _read_file_mmap(self, file_path: Path) -> bytes: """메모리 맵핑 파일 읽기""" try: # 캐시 확인 cache_key = str(file_path) if cache_key in self.file_cache: return self.file_cache[cache_key] # 메모리 맵핑으로 읽기 with open(file_path, 'rb') as f: with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm: data = mm.read() # 캐시 저장 (크기 제한) if len(self.file_cache) < self.cache_size_limit: self.file_cache[cache_key] = data return data except Exception as e: logger.error(f"파일 읽기 실패 {file_path}: {e}") return b'' def _get_content_type(self, filename: str) -> str: """Content-Type 결정""" lower = filename.lower() if lower.endswith('.webp'): return 'image/webp' elif lower.endswith('.png'): return 'image/png' elif lower.endswith(('.jpg', '.jpeg')): return 'image/jpeg' elif lower.endswith('.json'): return 'application/json' else: return 'text/plain' async def upload_batch_ultra_fast(self, items: List[Dict], existing_files: Set[str]) -> Dict: """초고속 배치 업로드""" semaphore = asyncio.Semaphore(self.max_concurrent) async def upload_with_semaphore(item): async with semaphore: return await self.upload_file_ultra_fast(item, existing_files) # 병렬 업로드 실행 tasks = [upload_with_semaphore(item) for item in items] results = await asyncio.gather(*tasks, return_exceptions=True) # 결과 집계 success_count = sum(1 for r in results if r is True) fail_count = len(results) - success_count return { 'success': success_count, 'failed': fail_count, 'total': len(items) } async def upload_directory_ultra_fast(self, base_dir: Path) -> Dict: """초고속 디렉토리 업로드""" print(f" 파일 스캔 중: {base_dir}") items = self.scan_files_optimized(base_dir) if not items: print(" 업로드할 파일이 없습니다") return {'success': 0, 'failed': 0, 'total': 0} print(f" 업로드 대상: {len(items)}개 파일") print(f" 동시 업로드: {self.max_concurrent}개") print(f" 청크 크기: {self.chunk_size // (1024*1024)}MB") # Part ID 수집 part_ids = {item['part_id'] for item in items} print(f" 기존 파일 확인 중: {len(part_ids)}개 Part ID") # 기존 파일 확인 existing_files = await self.batch_check_existing(part_ids) print(f" 기존 파일: {len(existing_files)}개") # 배치별 업로드 batch_size = 200 # 더 큰 배치 total_success = 0 total_failed = 0 for i in range(0, len(items), batch_size): batch = items[i:i + batch_size] batch_num = (i // batch_size) + 1 total_batches = (len(items) + batch_size - 1) // batch_size print(f" 배치 {batch_num}/{total_batches} 업로드 중 ({len(batch)}개)") start_time = time.time() result = await self.upload_batch_ultra_fast(batch, existing_files) elapsed = time.time() - start_time total_success += result['success'] total_failed += result['failed'] speed = len(batch) / elapsed if elapsed > 0 else 0 print(f" 배치 {batch_num} 완료: {result['success']}개 성공, {result['failed']}개 실패 ({elapsed:.1f}초, {speed:.1f} 파일/초)") return { 'success': total_success, 'failed': total_failed, 'total': len(items) } async def main(): """메인 실행 함수""" if len(sys.argv) < 2: print("사용법: python ultra_fast_uploader.py <디렉토리경로>") sys.exit(1) base_dir = Path(sys.argv[1]) if not base_dir.exists(): print(f" 디렉토리가 존재하지 않습니다: {base_dir}") sys.exit(1) # Supabase 설정 supabase_url = os.getenv("VITE_SUPABASE_URL", "https://npferbxuxocbfnfbpcnz.supabase.co") service_key = os.getenv("VITE_SUPABASE_SERVICE_ROLE", "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5wZmVyYnh1eG9jYmZuZmJwY256Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1OTQ3NDk4NSwiZXhwIjoyMDc1MDUwOTg1fQ.pPWhWrb4QBC-DT4dd6Y1p-LlHNd9UTKef3SHEXUDp00") print(" BrickBox 초고속 업로더 시작") print(f"[DIR] 대상 디렉토리: {base_dir}") print(f" 동시 업로드: 32개") print(f" 청크 크기: 16MB") print(f" HTTP/2 Keep-Alive 활성화") start_time = time.time() async with UltraFastUploader(supabase_url, service_key) as uploader: result = await uploader.upload_directory_ultra_fast(base_dir) elapsed = time.time() - start_time print(f"\n 업로드 완료!") print(f" 성공: {result['success']}개") print(f" 실패: {result['failed']}개") print(f" 총 파일: {result['total']}개") print(f"⏱️ 소요 시간: {elapsed:.1f}초") print(f" 평균 속도: {result['total']/elapsed:.1f} 파일/초") if result['failed'] > 0: print(f"\n 실패한 파일들:") for failed_file in uploader.failed_files[:10]: print(f" - {failed_file}") if len(uploader.failed_files) > 10: print(f" ... 및 {len(uploader.failed_files)-10}개 더") if __name__ == "__main__": asyncio.run(main()) 