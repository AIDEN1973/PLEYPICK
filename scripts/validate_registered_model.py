#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë“±ë¡ëœ ëª¨ë¸ì˜ ì •í™•ë„ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python scripts/validate_registered_model.py [--version VERSION] [--test-set TEST_SET_PATH]
"""

import os
import sys
import argparse
from pathlib import Path
from supabase import create_client
from ultralytics import YOLO
import torch

# ì¸ì½”ë”© ì„¤ì •
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€ (í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ ì‹œìŠ¤í…œ importë¥¼ ìœ„í•´)
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ ì‹œìŠ¤í…œ ì‚¬ìš©
try:
    from scripts.env_integration import get_supabase_config, apply_environment
    ENV_MANAGER_AVAILABLE = True
except ImportError as e:
    ENV_MANAGER_AVAILABLE = False
    print(f"[WARN] í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ìë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}", flush=True)
    print(f"[WARN] ê¸°ë³¸ í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.", flush=True)

def setup_supabase():
    """Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ ì‹œìŠ¤í…œ ì‚¬ìš©)"""
    if ENV_MANAGER_AVAILABLE:
        # í™˜ê²½ë³€ìˆ˜ ì ìš©
        apply_environment()
        # í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ ì‹œìŠ¤í…œì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        supabase_config = get_supabase_config()
        url = supabase_config.get('url')
        key = supabase_config.get('service_role')
        
        if not url or not key:
            print(f"[ERROR] í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ ì‹œìŠ¤í…œì—ì„œ Supabase ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", flush=True)
            raise ValueError("Supabase configuration not found in environment manager")
    else:
        # í´ë°±: ê¸°ë³¸ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
        url = os.getenv('SUPABASE_URL') or os.getenv('VITE_SUPABASE_URL')
        key = (
            os.getenv('SUPABASE_SERVICE_ROLE_KEY')
            or os.getenv('VITE_SUPABASE_SERVICE_ROLE')
            or os.getenv('SUPABASE_KEY')
        )
        
        if not url or not key:
            print(f"[ERROR] í™˜ê²½ë³€ìˆ˜ì—ì„œ Supabase ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", flush=True)
            raise ValueError("Supabase configuration not found in environment variables")
    
    print(f"[OK] Supabase URL: {url}", flush=True)
    print(f"[OK] Key: {key[:20]}...", flush=True)
    
    # API í‚¤ ìœ íš¨ì„± ê²€ì¦
    if not key or len(key) < 50:
        print(f"[ERROR] ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤ (ê¸¸ì´: {len(key) if key else 0})", flush=True)
        raise ValueError("Invalid API key")
    
    try:
        client = create_client(url, key)
        # ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸
        test_response = client.table('model_registry').select('id').limit(1).execute()
        print(f"[OK] Supabase ì—°ê²° ì„±ê³µ", flush=True)
        return client
    except Exception as e:
        print(f"[ERROR] Supabase ì—°ê²° ì‹¤íŒ¨: {e}", flush=True)
        print(f"   URL: {url}", flush=True)
        print(f"   Key prefix: {key[:30]}...", flush=True)
        raise

def get_active_model(supabase, version=None):
    """í™œì„± ëª¨ë¸ ë˜ëŠ” íŠ¹ì • ë²„ì „ ëª¨ë¸ ì¡°íšŒ"""
    try:
        if version:
            # íŠ¹ì • ë²„ì „ ì¡°íšŒ
            response = supabase.table('model_registry').select('*').eq('version', version).execute()
        else:
            # í™œì„± ëª¨ë¸ ì¡°íšŒ
            response = supabase.table('model_registry').select('*').eq('status', 'active').order('created_at', ascending=False).limit(1).execute()
        
        if not response.data or len(response.data) == 0:
            print(f"[ERROR] ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            if version:
                print(f"   ë²„ì „: {version}")
            else:
                print(f"   í™œì„± ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        model_info = response.data[0]
        print(f"âœ… ëª¨ë¸ ë°œê²¬:")
        print(f"   ë²„ì „: {model_info.get('version')}")
        print(f"   ì´ë¦„: {model_info.get('model_name')}")
        print(f"   URL: {model_info.get('model_url')}")
        print(f"   ìƒíƒœ: {model_info.get('status')}")
        
        return model_info
        
    except Exception as e:
        print(f"[ERROR] ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

def download_model(model_url, output_path):
    """ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        print(f"[DOWNLOAD] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        print(f"   URL: {model_url}")
        print(f"   ì €ì¥ ìœ„ì¹˜: {output_path}")
        
        import requests
        
        response = requests.get(model_url, stream=True)
        response.raise_for_status()
        
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded = 0
        
        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    if total_size > 0:
                        percent = (downloaded / total_size) * 100
                        print(f"\r   ì§„í–‰ë¥ : {percent:.1f}%", end='', flush=True)
        
        print(f"\nâœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {output_path}")
        print(f"   í¬ê¸°: {downloaded / 1024 / 1024:.1f} MB")
        
        return True
        
    except Exception as e:
        print(f"\n[ERROR] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def prepare_test_dataset(test_set_path=None):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„ (ì—¬ëŸ¬ ê²½ë¡œ ìë™ íƒìƒ‰)"""
    # ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ê²½ë¡œ ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœ)
    possible_paths = []
    
    if test_set_path:
        possible_paths.append(Path(test_set_path))
    
    # ê¸°ë³¸ ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
    possible_paths.extend([
        Path("output/datasets/current"),  # ìµœì‹  ë°ì´í„°ì…‹
        Path("output/synthetic/dataset_synthetic"),  # í•©ì„± ë°ì´í„°ì…‹ (ê²€ì¦ ì´ë¯¸ì§€ 40ê°œ í™•ì¸ë¨)
        Path("output/dataset_synthetic"),
        Path("output/datasets/v1.1"),
        Path("output/datasets/v1.0"),
    ])
    
    print(f"[DATASET] í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„...", flush=True)
    
    # ìœ íš¨í•œ ë°ì´í„°ì…‹ ê²½ë¡œ ì°¾ê¸°
    dataset_path = None
    for path in possible_paths:
        if not path.exists():
            continue
            
        val_images = path / "images" / "val"
        val_labels = path / "labels" / "val"
        
        # val í´ë”ì™€ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
        if val_images.exists() and val_labels.exists():
            image_files = list(val_images.glob("*.webp")) + list(val_images.glob("*.jpg")) + list(val_images.glob("*.png"))
            if len(image_files) > 0:
                dataset_path = path
                print(f"âœ… ë°ì´í„°ì…‹ ë°œê²¬: {path}", flush=True)
                print(f"   ê²€ì¦ ì´ë¯¸ì§€ ìˆ˜: {len(image_files)}ê°œ", flush=True)
                break
    
    if not dataset_path:
        print(f"[ERROR] ê²€ì¦ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", flush=True)
        print(f"   ì‹œë„í•œ ê²½ë¡œ:", flush=True)
        for path in possible_paths:
            exists = path.exists()
            val_exists = (path / "images" / "val").exists() if exists else False
            print(f"     - {path}: {'ì¡´ì¬' if exists else 'ì—†ìŒ'} (val: {'ìˆìŒ' if val_exists else 'ì—†ìŒ'})", flush=True)
        print(f"\nğŸ’¡ í•´ê²° ë°©ë²•:", flush=True)
        print(f"   1. ë°ì´í„°ì…‹ ìƒì„±: python scripts/prepare_yolo_dataset.py", flush=True)
        print(f"   2. ë˜ëŠ” --test-set ì˜µì…˜ìœ¼ë¡œ ë°ì´í„°ì…‹ ê²½ë¡œ ì§€ì •", flush=True)
        return None
    
    # data.yaml í™•ì¸
    data_yaml = dataset_path / "data.yaml"
    if not data_yaml.exists():
        # ê¸°ë³¸ data.yaml ìƒì„±
        print(f"[WARN] data.yaml ì—†ìŒ, ìƒì„± ì¤‘...", flush=True)
        
        # ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸
        data_yaml.parent.mkdir(parents=True, exist_ok=True)
        
        # ì‹¤ì œ í´ë˜ìŠ¤ ìˆ˜ í™•ì¸ (ë¼ë²¨ íŒŒì¼ì—ì„œ)
        class_ids = set()
        try:
            for label_file in (dataset_path / "labels" / "val").glob("*.txt"):
                with open(label_file, 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if parts:
                            class_ids.add(int(parts[0]))
            num_classes = max(class_ids) + 1 if class_ids else 1
            class_names = [f'class_{i}' for i in range(num_classes)]
        except:
            num_classes = 1
            class_names = ['lego_part']
        
        data_yaml_content = f"""path: {dataset_path.absolute()}
train: images/train
val: images/val

nc: {num_classes}
names: {class_names}
"""
        try:
            data_yaml.write_text(data_yaml_content, encoding='utf-8')
            print(f"âœ… data.yaml ìƒì„± ì™„ë£Œ (í´ë˜ìŠ¤ ìˆ˜: {num_classes})", flush=True)
        except PermissionError as e:
            print(f"[ERROR] data.yaml íŒŒì¼ ì“°ê¸° ê¶Œí•œ ì˜¤ë¥˜: {e}", flush=True)
            print(f"   ê²½ë¡œ: {data_yaml}", flush=True)
            raise
        except Exception as e:
            print(f"[ERROR] data.yaml íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {e}", flush=True)
            print(f"   ê²½ë¡œ: {data_yaml}", flush=True)
            raise
    
    # ìµœì¢… ê²€ì¦
    val_images = dataset_path / "images" / "val"
    val_labels = dataset_path / "labels" / "val"
    
    image_count = len(list(val_images.glob("*.webp"))) + len(list(val_images.glob("*.jpg"))) + len(list(val_images.glob("*.png")))
    label_count = len(list(val_labels.glob("*.txt")))
    
    print(f"âœ… ê²€ì¦ ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ:", flush=True)
    print(f"   ê²½ë¡œ: {dataset_path}", flush=True)
    print(f"   ê²€ì¦ ì´ë¯¸ì§€: {image_count}ê°œ", flush=True)
    print(f"   ê²€ì¦ ë¼ë²¨: {label_count}ê°œ", flush=True)
    
    if image_count == 0:
        print(f"[WARNING] ê²½ê³ : ê²€ì¦ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!", flush=True)
        return None
    
    return str(dataset_path)

def evaluate_model(model_path, dataset_path, device='cuda'):
    """ëª¨ë¸ í‰ê°€ ì‹¤í–‰"""
    try:
        print(f"[EVAL] ëª¨ë¸ í‰ê°€ ì‹œì‘...", flush=True)
        print(f"   ëª¨ë¸: {model_path}", flush=True)
        print(f"   ë°ì´í„°ì…‹: {dataset_path}", flush=True)
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if device == 'cuda':
            try:
                import torch
                if not torch.cuda.is_available():
                    print(f"[WARN] CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.", flush=True)
                    device = 'cpu'
                else:
                    print(f"[INFO] CUDA ì‚¬ìš© ê°€ëŠ¥ (ë””ë°”ì´ìŠ¤: {device})", flush=True)
            except ImportError:
                print(f"[WARN] PyTorchë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.", flush=True)
                device = 'cpu'
        
        print(f"   ë””ë°”ì´ìŠ¤: {device}", flush=True)
        
        # ë°ì´í„°ì…‹ ì„¤ì • ë¨¼ì € í™•ì¸
        dataset_yaml = Path(dataset_path) / "data.yaml"
        dataset_classes = 1
        dataset_names = ['lego_part']
        
        if dataset_yaml.exists():
            try:
                import yaml
                with open(dataset_yaml, 'r', encoding='utf-8') as f:
                    dataset_config = yaml.safe_load(f)
                dataset_classes = dataset_config.get('nc', 1)
                dataset_names = dataset_config.get('names', ['lego_part'])
                print(f"[INFO] ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ìˆ˜: {dataset_classes}", flush=True)
                print(f"[INFO] ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì´ë¦„: {dataset_names}", flush=True)
            except Exception as e:
                print(f"[WARN] ë°ì´í„°ì…‹ ì„¤ì • ì½ê¸° ì‹¤íŒ¨: {e}", flush=True)
        
        # ëª¨ë¸ ë¡œë“œ ë° í´ë˜ìŠ¤ ìˆ˜ í™•ì¸
        print(f"[INFO] ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}", flush=True)
        try:
            model = YOLO(str(model_path))
            print(f"[INFO] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ", flush=True)
            
            # ëª¨ë¸ í´ë˜ìŠ¤ ìˆ˜ í™•ì¸
            model_classes = None
            try:
                # ë°©ë²• 1: model.model.nc í™•ì¸
                if hasattr(model, 'model') and hasattr(model.model, 'nc'):
                    model_classes = model.model.nc
                    print(f"[INFO] ëª¨ë¸ í´ë˜ìŠ¤ ìˆ˜ (model.nc): {model_classes}", flush=True)
                # ë°©ë²• 2: model.yaml í™•ì¸
                elif hasattr(model, 'model') and hasattr(model.model, 'yaml'):
                    yaml_dict = model.model.yaml if isinstance(model.model.yaml, dict) else {}
                    model_classes = yaml_dict.get('nc', None)
                    if model_classes:
                        print(f"[INFO] ëª¨ë¸ í´ë˜ìŠ¤ ìˆ˜ (yaml): {model_classes}", flush=True)
                # ë°©ë²• 3: model.overrides í™•ì¸
                elif hasattr(model, 'overrides') and isinstance(model.overrides, dict):
                    model_classes = model.overrides.get('nc', None)
                    if model_classes:
                        print(f"[INFO] ëª¨ë¸ í´ë˜ìŠ¤ ìˆ˜ (overrides): {model_classes}", flush=True)
            except Exception as e:
                print(f"[WARN] ëª¨ë¸ í´ë˜ìŠ¤ ìˆ˜ í™•ì¸ ì‹¤íŒ¨: {e}", flush=True)
            
            # í´ë˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜ ê²½ê³ 
            if model_classes and model_classes != dataset_classes:
                print(f"[WARNING] ê²½ê³ : ëª¨ë¸ í´ë˜ìŠ¤ ìˆ˜({model_classes})ì™€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ìˆ˜({dataset_classes})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!", flush=True)
                print(f"[INFO] ëª¨ë¸ì´ {model_classes}ê°œ í´ë˜ìŠ¤ë¥¼ ê¸°ëŒ€í•˜ì§€ë§Œ ë°ì´í„°ì…‹ì€ {dataset_classes}ê°œ í´ë˜ìŠ¤ë§Œ ìˆìŠµë‹ˆë‹¤.", flush=True)
                print(f"[INFO] ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤. YOLOê°€ ìë™ìœ¼ë¡œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", flush=True)
        except Exception as e:
            print(f"[ERROR] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}", flush=True)
            import traceback
            traceback.print_exc(file=sys.stderr)
            raise
        
        # í‰ê°€ ì‹¤í–‰ (ë” ì•ˆì „í•œ íŒŒë¼ë¯¸í„°)
        print(f"[INFO] ëª¨ë¸ í‰ê°€ ì‹œì‘...", flush=True)
        try:
            # CPUì—ì„œëŠ” batch í¬ê¸°ì™€ half precision ì¡°ì •
            batch_size = 4 if device == 'cpu' else 16  # CPUì—ì„œëŠ” ë” ì‘ì€ batch
            
            # ëª¨ë¸ íƒ€ì… ê°ì§€
            model_path_str = str(model_path).lower()
            is_segment = 'seg' in model_path_str or 'segment' in model_path_str
            task_type = 'segment' if is_segment else 'detect'
            print(f"[INFO] ëª¨ë¸ íƒ€ì…: {task_type}", flush=True)
            
            # ë°ì´í„°ì…‹ YAML ì—…ë°ì´íŠ¸ (ëª¨ë¸ê³¼ ì¼ì¹˜í•˜ë„ë¡)
            try:
                import yaml
                yaml_data = {
                    'path': str(Path(dataset_path).absolute()),
                    'train': 'images/train',
                    'val': 'images/val',
                    'nc': dataset_classes,
                    'names': dataset_names if isinstance(dataset_names, list) else list(dataset_names) if dataset_names else ['lego_part']
                }
                # YAML íŒŒì¼ ì¬ì‘ì„± (ëª¨ë¸ê³¼ ì¼ì¹˜í•˜ë„ë¡)
                with open(dataset_yaml, 'w', encoding='utf-8') as f:
                    yaml.dump(yaml_data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
                print(f"[INFO] ë°ì´í„°ì…‹ YAML ì—…ë°ì´íŠ¸ ì™„ë£Œ (nc={dataset_classes})", flush=True)
            except Exception as e:
                print(f"[WARN] YAML ì—…ë°ì´íŠ¸ ì‹¤íŒ¨, ê³„ì† ì§„í–‰: {e}", flush=True)
            
            # í‰ê°€ ì‹¤í–‰ (ë‹¨ê³„ë³„ë¡œ ì§„í–‰)
            print(f"[INFO] í‰ê°€ íŒŒë¼ë¯¸í„°: batch={batch_size}, device={device}, task={task_type}", flush=True)
            
            results = model.val(
                data=str(dataset_yaml),
                imgsz=640,
                batch=batch_size,
                device=device,
                conf=0.25,
                iou=0.60,
                verbose=True,
                save=False,  # ê²°ê³¼ ì €ì¥ ë¹„í™œì„±í™”
                plots=False,  # í”Œë¡¯ ìƒì„± ë¹„í™œì„±í™”
                half=False,  # half precision ë¹„í™œì„±í™” (í˜¸í™˜ì„± í–¥ìƒ)
                task=task_type,  # ëª¨ë¸ íƒ€ì… ëª…ì‹œ
                max_det=300,  # ìµœëŒ€ íƒì§€ ìˆ˜ ì œí•œ
                agnostic_nms=False  # í´ë˜ìŠ¤ë³„ NMS ì‚¬ìš©
            )
            print(f"[INFO] ëª¨ë¸ í‰ê°€ ì™„ë£Œ", flush=True)
        except Exception as e:
            print(f"[ERROR] ëª¨ë¸ í‰ê°€ ì‹¤í–‰ ì‹¤íŒ¨: {e}", flush=True)
            print(f"[DEBUG] ì˜¤ë¥˜ ë°œìƒ ìœ„ì¹˜:", flush=True)
            import traceback
            traceback.print_exc(file=sys.stderr)
            traceback.print_exc()  # stdoutì—ë„ ì¶œë ¥
            raise
        
        # ê²°ê³¼ ê°ì²´ êµ¬ì¡° í™•ì¸ (ë””ë²„ê¹…)
        print(f"[DEBUG] ê²°ê³¼ ê°ì²´ íƒ€ì…: {type(results)}", flush=True)
        print(f"[DEBUG] ê²°ê³¼ ê°ì²´ ì†ì„±: {dir(results)}", flush=True)
        if hasattr(results, 'box'):
            print(f"[DEBUG] results.box íƒ€ì…: {type(results.box)}", flush=True)
            if results.box:
                print(f"[DEBUG] results.box ì†ì„±: {[attr for attr in dir(results.box) if not attr.startswith('_')]}", flush=True)
        
        # ë©”íŠ¸ë¦­ ì¶”ì¶œ (ì•ˆì „í•œ ë°©ì‹)
        def safe_get_metric(obj, attr_name, default=0.0):
            """ì•ˆì „í•˜ê²Œ ë©”íŠ¸ë¦­ ê°’ì„ ê°€ì ¸ì˜¤ê¸°"""
            try:
                value = getattr(obj, attr_name, None)
                if value is None:
                    return default
                # numpy arrayë‚˜ tensorì¸ ê²½ìš° ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
                if hasattr(value, '__len__') and not isinstance(value, str):
                    if len(value) > 0:
                        return float(value[0] if hasattr(value, '__getitem__') else value)
                    return default
                return float(value)
            except (IndexError, TypeError, AttributeError) as e:
                print(f"[WARN] ë©”íŠ¸ë¦­ {attr_name} ì¶”ì¶œ ì‹¤íŒ¨: {e}", flush=True)
                return default
        
        # ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ ì‹œë„
        metrics = {}
        
        # ë°©ë²• 1: results.box ì§ì ‘ ì ‘ê·¼
        if hasattr(results, 'box') and results.box:
            try:
                metrics['mAP50'] = safe_get_metric(results.box, 'map50', 0.0)
                metrics['mAP50_95'] = safe_get_metric(results.box, 'map', 0.0)
                metrics['precision'] = safe_get_metric(results.box, 'mp', 0.0)
                metrics['recall'] = safe_get_metric(results.box, 'mr', 0.0)
            except Exception as e:
                print(f"[WARN] results.boxì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ ì‹¤íŒ¨: {e}", flush=True)
        
        # ë°©ë²• 2: results.results_dict ì‚¬ìš© (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
        if not metrics.get('mAP50'):
            try:
                if hasattr(results, 'results_dict'):
                    metrics['mAP50'] = float(results.results_dict.get('metrics/mAP50(B)', results.results_dict.get('metrics/mAP50', 0.0)))
                    metrics['mAP50_95'] = float(results.results_dict.get('metrics/mAP50-95(B)', results.results_dict.get('metrics/mAP50-95', 0.0)))
                    metrics['precision'] = float(results.results_dict.get('metrics/precision(B)', results.results_dict.get('metrics/precision', 0.0)))
                    metrics['recall'] = float(results.results_dict.get('metrics/recall(B)', results.results_dict.get('metrics/recall', 0.0)))
            except Exception as e:
                print(f"[WARN] results_dictì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ ì‹¤íŒ¨: {e}", flush=True)
        
        # ë°©ë²• 3: results.keys_dict ì‚¬ìš©
        if not metrics.get('mAP50'):
            try:
                if hasattr(results, 'keys'):
                    for key in results.keys():
                        if 'map50' in key.lower() and 'box' in key.lower():
                            metrics['mAP50'] = float(results.keys()[key])
                        elif 'map' in key.lower() and 'box' in key.lower() and 'map50' not in key.lower():
                            metrics['mAP50_95'] = float(results.keys()[key])
            except Exception as e:
                print(f"[WARN] keysì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œ ì‹¤íŒ¨: {e}", flush=True)
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        metrics.setdefault('mAP50', 0.0)
        metrics.setdefault('mAP50_95', 0.0)
        metrics.setdefault('precision', 0.0)
        metrics.setdefault('recall', 0.0)
        
        # F1 Score ê³„ì‚°
        if metrics['precision'] > 0 or metrics['recall'] > 0:
            metrics['f1_score'] = 2 * (metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'] + 1e-10)
        else:
            metrics['f1_score'] = 0.0
        
        print(f"\nâœ… í‰ê°€ ì™„ë£Œ:")
        print(f"   mAP50: {metrics['mAP50']:.4f}")
        print(f"   mAP50-95: {metrics['mAP50_95']:.4f}")
        print(f"   Precision: {metrics['precision']:.4f}")
        print(f"   Recall: {metrics['recall']:.4f}")
        print(f"   F1 Score: {metrics['f1_score']:.4f}")
        
        # íŒŒì‹±ì„ ìœ„í•œ í‘œì¤€ í˜•ì‹ ì¶œë ¥
        print(f"\n[METRICS]")
        print(f"mAP50: {metrics['mAP50']:.6f}")
        print(f"mAP50-95: {metrics['mAP50_95']:.6f}")
        print(f"Precision: {metrics['precision']:.6f}")
        print(f"Recall: {metrics['recall']:.6f}")
        
        return metrics
        
    except Exception as e:
        print(f"[ERROR] ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {e}", flush=True)
        import traceback
        print(f"\n[ERROR] Traceback:", flush=True)
        traceback.print_exc(file=sys.stderr)
        traceback.print_exc()  # stdoutì—ë„ ì¶œë ¥
        return None

def update_model_metrics(supabase, model_id, metrics):
    """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
    try:
        print(f"[UPDATE] ëª¨ë¸ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ì¤‘...")
        
        # ê¸°ì¡´ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
        current_model = supabase.table('model_registry').select('metrics').eq('id', model_id).execute()
        existing_metrics = current_model.data[0].get('metrics', {}) if current_model.data else {}
        
        # ìƒˆ ë©”íŠ¸ë¦­ ë³‘í•© (ê²€ì¦ ë©”íŠ¸ë¦­ ìš°ì„ )
        updated_metrics = {
            **existing_metrics,
            'validation_mAP50': metrics['mAP50'],
            'validation_mAP50_95': metrics['mAP50_95'],
            'validation_precision': metrics['precision'],
            'validation_recall': metrics['recall'],
            'validation_f1_score': metrics['f1_score'],
            'last_validated': str(Path().cwd() / 'output' / 'validation')  # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ ê°€ëŠ¥
        }
        
        # ì—…ë°ì´íŠ¸ ì‹¤í–‰
        response = supabase.table('model_registry').update({
            'metrics': updated_metrics
        }).eq('id', model_id).execute()
        
        print(f"âœ… ëª¨ë¸ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        print(f"   ëª¨ë¸ ID: {model_id}")
        print(f"   ê²€ì¦ mAP50: {metrics['mAP50']:.4f}")
        print(f"   ê²€ì¦ mAP50-95: {metrics['mAP50_95']:.4f}")
        
        return True
        
    except Exception as e:
        print(f"[ERROR] ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def validate_model_accuracy(model_info, test_set_path=None, device='cuda'):
    """ëª¨ë¸ ì •í™•ë„ ê²€ì¦ ë©”ì¸ í•¨ìˆ˜"""
    try:
        print(f"\n[STEP 1/5] ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ...", flush=True)
        # 1. ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        model_url = model_info.get('model_url')
        if not model_url:
            print(f"[ERROR] ëª¨ë¸ URLì´ ì—†ìŠµë‹ˆë‹¤.", flush=True)
            return False
        
        # ë¡œì»¬ ì €ì¥ ê²½ë¡œ
        model_dir = Path("output/validation/models")
        model_dir.mkdir(parents=True, exist_ok=True)
        
        model_filename = model_url.split('/')[-1]
        model_path = model_dir / model_filename
        
        # .onnxì¸ ê²½ìš° ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥ (YOLO v8+ ì§€ì›)
        if model_url.endswith('.onnx'):
            onnx_path = model_dir / model_filename
            if download_model(model_url, onnx_path):
                # ONNX íŒŒì¼ì„ ì§ì ‘ ì‚¬ìš©
                model_path = onnx_path
                print(f"[INFO] ONNX ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {model_path}", flush=True)
            else:
                print(f"[ERROR] ONNX ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨", flush=True)
                return False
        else:
            # .pt íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            if not download_model(model_url, model_path):
                print(f"[ERROR] ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨", flush=True)
                return False
        
        print(f"âœ… ëª¨ë¸ íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ: {model_path}", flush=True)
        
        print(f"\n[STEP 2/5] í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„...", flush=True)
        # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„
        dataset_path = prepare_test_dataset(test_set_path)
        if not dataset_path:
            print(f"[ERROR] í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹¤íŒ¨", flush=True)
            return False
        
        print(f"\n[STEP 3/5] ëª¨ë¸ í‰ê°€ ì‹¤í–‰...", flush=True)
        # 3. ëª¨ë¸ í‰ê°€
        metrics = evaluate_model(str(model_path), dataset_path, device)
        if not metrics:
            return False
        
        print(f"\n[STEP 4/5] ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸...", flush=True)
        # 4. ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        model_id = model_info.get('id')
        if model_id:
            # Supabase í´ë¼ì´ì–¸íŠ¸ ì¬ìƒì„± (ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ìš©)
            supabase_client = setup_supabase()
            update_model_metrics(supabase_client, model_id, metrics)
        
        print(f"\n[STEP 5/5] SLO ê¸°ì¤€ í™•ì¸ ë° í”¼ë“œë°±...", flush=True)
        # 5. SLO ê¸°ì¤€ í™•ì¸ ë° ìƒì„¸ í”¼ë“œë°±
        print(f"\nğŸ“Š SLO ê¸°ì¤€ í™•ì¸:")
        
        # SLO ê¸°ì¤€ ì •ì˜
        slo_recall = 0.95
        slo_map50 = 0.90
        slo_map50_95 = 0.60
        
        checks = {
            'Recall â‰¥ 0.95': {
                'passed': metrics['recall'] >= slo_recall,
                'current': metrics['recall'],
                'target': slo_recall,
                'gap': slo_recall - metrics['recall'],
                'percentage': (metrics['recall'] / slo_recall * 100) if slo_recall > 0 else 0
            },
            'mAP50 â‰¥ 0.90': {
                'passed': metrics['mAP50'] >= slo_map50,
                'current': metrics['mAP50'],
                'target': slo_map50,
                'gap': slo_map50 - metrics['mAP50'],
                'percentage': (metrics['mAP50'] / slo_map50 * 100) if slo_map50 > 0 else 0
            },
            'mAP50-95 â‰¥ 0.60': {
                'passed': metrics['mAP50_95'] >= slo_map50_95,
                'current': metrics['mAP50_95'],
                'target': slo_map50_95,
                'gap': slo_map50_95 - metrics['mAP50_95'],
                'percentage': (metrics['mAP50_95'] / slo_map50_95 * 100) if slo_map50_95 > 0 else 0
            }
        }
        
        all_passed = True
        for check_name, check_data in checks.items():
            status = "âœ…" if check_data['passed'] else "[ERROR]"
            print(f"   {status} {check_name}: {check_data['current']:.4f} (ëª©í‘œ: {check_data['target']:.2f}, ë‹¬ì„±ë¥ : {check_data['percentage']:.1f}%)", flush=True)
            if not check_data['passed']:
                all_passed = False
        
        # ìƒì„¸ í”¼ë“œë°± ì œê³µ
        print(f"\nğŸ“‹ ê²€ì¦ ê²°ê³¼ ë¶„ì„:", flush=True)
        
        if all_passed:
            print(f"âœ… ëª¨ë“  SLO ê¸°ì¤€ í†µê³¼! ëª¨ë¸ì´ í”„ë¡œë•ì…˜ í™˜ê²½ì— ë°°í¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.", flush=True)
        else:
            print(f"[ERROR] SLO ê¸°ì¤€ ë¯¸ë‹¬ - ëª¨ë¸ ê°œì„  í•„ìš”", flush=True)
            
            # Recall ë¶„ì„
            if metrics['recall'] < slo_recall:
                recall_gap = slo_recall - metrics['recall']
                print(f"\nğŸ” Recall ë¶„ì„ (í˜„ì¬: {metrics['recall']:.1%}, ëª©í‘œ: {slo_recall:.0%}):", flush=True)
                print(f"   - ë¬¸ì œ: ëª¨ë¸ì´ {recall_gap:.1%}ë§Œí¼ ê°ì²´ë¥¼ ë†“ì¹˜ê³  ìˆìŠµë‹ˆë‹¤.", flush=True)
                print(f"   - ì˜í–¥: ì•½ {100 - metrics['recall']*100:.1f}%ì˜ ê°ì²´ë¥¼ íƒì§€í•˜ì§€ ëª»í•©ë‹ˆë‹¤.", flush=True)
                print(f"   - í•´ê²° ë°©ì•ˆ:", flush=True)
                print(f"     1. Confidence threshold ë‚®ì¶”ê¸° (í˜„ì¬: 0.25 â†’ 0.15 ê¶Œì¥)", flush=True)
                print(f"     2. ì¶”ê°€ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ (íŠ¹íˆ ë†“ì¹œ ì¼€ì´ìŠ¤)", flush=True)
                print(f"     3. ë°ì´í„° ì¦ê°• ê°•í™” (rotation, scaling ë“±)", flush=True)
                print(f"     4. í•™ìŠµ ì—í­ ìˆ˜ ì¦ê°€", flush=True)
            
            # mAP50 ë¶„ì„
            if metrics['mAP50'] < slo_map50:
                map50_gap = slo_map50 - metrics['mAP50']
                print(f"\nğŸ” mAP50 ë¶„ì„ (í˜„ì¬: {metrics['mAP50']:.1%}, ëª©í‘œ: {slo_map50:.0%}):", flush=True)
                print(f"   - ë¬¸ì œ: í‰ê·  ì •ë°€ë„ê°€ {map50_gap:.1%}ë§Œí¼ ë¶€ì¡±í•©ë‹ˆë‹¤.", flush=True)
                print(f"   - ì˜í–¥: íƒì§€ ì •í™•ë„ê°€ ëª©í‘œë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤.", flush=True)
                print(f"   - í•´ê²° ë°©ì•ˆ:", flush=True)
                print(f"     1. ë°”ìš´ë”© ë°•ìŠ¤ ë¼ë²¨ë§ í’ˆì§ˆ ì¬ê²€í† ", flush=True)
                print(f"     2. í•™ìŠµ ë°ì´í„° ë‹¤ì–‘ì„± í™•ë³´", flush=True)
                print(f"     3. ëª¨ë¸ ì•„í‚¤í…ì²˜ ë³€ê²½ (ë” í° ëª¨ë¸ ê³ ë ¤)", flush=True)
                print(f"     4. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ìµœì í™”", flush=True)
            
            # mAP50-95 ë¶„ì„
            if metrics['mAP50_95'] < slo_map50_95:
                map50_95_gap = slo_map50_95 - metrics['mAP50_95']
                print(f"\nğŸ” mAP50-95 ë¶„ì„ (í˜„ì¬: {metrics['mAP50_95']:.1%}, ëª©í‘œ: {slo_map50_95:.0%}):", flush=True)
                print(f"   - ë¬¸ì œ: IoU ì„ê³„ê°’ ë²”ìœ„ì—ì„œ ì •ë°€ë„ê°€ {map50_95_gap:.1%}ë§Œí¼ ë¶€ì¡±í•©ë‹ˆë‹¤.", flush=True)
                print(f"   - ì˜í–¥: ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ì¹˜ ì •í™•ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.", flush=True)
                print(f"   - í•´ê²° ë°©ì•ˆ:", flush=True)
                print(f"     1. ë°”ìš´ë”© ë°•ìŠ¤ ë¼ë²¨ë§ ì •í™•ë„ ê°œì„ ", flush=True)
                print(f"     2. IoU loss ê°€ì¤‘ì¹˜ ì¡°ì •", flush=True)
                print(f"     3. ë°ì´í„° ì¦ê°• ì‹œ ìœ„ì¹˜ ë³´ì¡´ ê°•í™”", flush=True)
            
            # ì¢…í•© ê¶Œì¥ì‚¬í•­
            print(f"\nğŸ’¡ ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ê¶Œì¥ì‚¬í•­:", flush=True)
            print(f"   1ìˆœìœ„: Recall ê°œì„  (confidence threshold ì¡°ì •)", flush=True)
            print(f"   2ìˆœìœ„: í•™ìŠµ ë°ì´í„° í’ˆì§ˆ ë° ì–‘ í™•ë³´", flush=True)
            print(f"   3ìˆœìœ„: í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¬ì¡°ì • (learning rate, batch size ë“±)", flush=True)
            print(f"   4ìˆœìœ„: ëª¨ë¸ ì•„í‚¤í…ì²˜ ê²€í†  (ë” í° ëª¨ë¸ ë˜ëŠ” ë‹¤ë¥¸ ë°±ë³¸ ê³ ë ¤)", flush=True)
            
            # Precisionê³¼ Recallì˜ ê· í˜• ë¶„ì„
            if metrics['precision'] > 0.8 and metrics['recall'] < 0.5:
                print(f"\nâš–ï¸ Precision-Recall ë¶ˆê· í˜• ê°ì§€:", flush=True)
                print(f"   - Precisionì´ ë†’ì§€ë§Œ Recallì´ ë‚®ìŠµë‹ˆë‹¤.", flush=True)
                print(f"   - ëª¨ë¸ì´ íƒì§€í•˜ëŠ” ê°ì²´ëŠ” ì •í™•í•˜ë‚˜, ë§ì€ ê°ì²´ë¥¼ ë†“ì¹˜ê³  ìˆìŠµë‹ˆë‹¤.", flush=True)
                print(f"   - í•´ê²°: Confidence thresholdë¥¼ ë‚®ì¶° ë” ë§ì€ ê°ì²´ë¥¼ íƒì§€í•˜ë„ë¡ ì„¤ì •", flush=True)
        
        return True
        
    except Exception as e:
        print(f"\n[ERROR] ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}", flush=True)
        import traceback
        print(f"\n[ERROR] Traceback:", flush=True)
        traceback.print_exc(file=sys.stderr)
        traceback.print_exc()  # stdoutì—ë„ ì¶œë ¥
        return False

def main():
    parser = argparse.ArgumentParser(description='ë“±ë¡ëœ ëª¨ë¸ì˜ ì •í™•ë„ ê²€ì¦')
    parser.add_argument('--version', type=str, help='ê²€ì¦í•  ëª¨ë¸ ë²„ì „ (ì—†ìœ¼ë©´ í™œì„± ëª¨ë¸)')
    parser.add_argument('--test-set', type=str, help='í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê²½ë¡œ (ê¸°ë³¸: output/dataset_synthetic)')
    parser.add_argument('--device', type=str, default='auto', help='ë””ë°”ì´ìŠ¤ (auto/cuda/cpu, ê¸°ë³¸: auto)')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ§± BrickBox ëª¨ë¸ ì •í™•ë„ ê²€ì¦")
    print("=" * 60)
    
    # Supabase ì—°ê²°
    supabase = setup_supabase()
    
    # ëª¨ë¸ ì¡°íšŒ
    model_info = get_active_model(supabase, args.version)
    if not model_info:
        sys.exit(1)
    
    # ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ
    if args.device == 'auto':
        try:
            import torch
            if torch.cuda.is_available():
                device = 'cuda'
                print(f"[INFO] CUDA ìë™ ê°ì§€: {device} ì‚¬ìš©", flush=True)
            else:
                device = 'cpu'
                print(f"[INFO] CUDA ì—†ìŒ: {device} ì‚¬ìš©", flush=True)
        except ImportError:
            device = 'cpu'
            print(f"[INFO] PyTorch ì—†ìŒ: {device} ì‚¬ìš©", flush=True)
    else:
        device = args.device
    
    # ëª¨ë¸ ê²€ì¦
    success = validate_model_accuracy(model_info, args.test_set, device)
    
    if success:
        print("\n" + "=" * 60)
        print("âœ… ëª¨ë¸ ê²€ì¦ ì™„ë£Œ")
        print("=" * 60)
        sys.exit(0)
    else:
        print("\n" + "=" * 60)
        print("[ERROR] ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨")
        print("=" * 60)
        sys.exit(1)

if __name__ == '__main__':
    main()

