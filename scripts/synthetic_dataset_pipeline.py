#!/usr/bin/env python3
"""
ğŸ§± BrickBox í•©ì„± ë°ì´í„°ì…‹ ìƒì„± í†µí•© íŒŒì´í”„ë¼ì¸

LDraw â†’ Blender â†’ Supabase ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í†µí•© ê´€ë¦¬í•˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
- ë°°ì¹˜ ì²˜ë¦¬
- ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
- ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬
- ê²°ê³¼ ê²€ì¦ ë° ë³´ê³ ì„œ ìƒì„±
"""

import os
import sys
import json
import time
import logging
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import asyncio
import concurrent.futures
from dataclasses import dataclass, asdict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

try:
    from supabase import create_client, Client
    from dotenv import load_dotenv
    SUPABASE_AVAILABLE = True
except ImportError:
    print("âš ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install supabase python-dotenv")
    SUPABASE_AVAILABLE = False

@dataclass
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    # ê¸°ë³¸ ì„¤ì •
    project_root: str = str(project_root)
    output_dir: str = "./output/synthetic"
    log_level: str = "INFO"
    
    # LDraw ì„¤ì •
    ldraw_path: str = "C:/ldraw/parts"
    part_list: List[str] = None
    
    # ë Œë”ë§ ì„¤ì •
    image_width: int = 640
    image_height: int = 640
    samples: int = 64
    max_images_per_part: int = 100
    
    # ë°°ì¹˜ ì„¤ì •
    batch_size: int = 10
    max_workers: int = 4
    
    # Supabase ì„¤ì •
    supabase_url: Optional[str] = None
    supabase_key: Optional[str] = None
    bucket_name: str = "lego_parts_images"
    
    def __post_init__(self):
        if self.part_list is None:
            self.part_list = ["3001", "3002", "3003", "3004", "3005"]  # ê¸°ë³¸ ë¶€í’ˆ ëª©ë¡

@dataclass
class PipelineStats:
    """íŒŒì´í”„ë¼ì¸ í†µê³„"""
    total_parts: int = 0
    completed_parts: int = 0
    total_images: int = 0
    successful_images: int = 0
    failed_images: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    
    @property
    def success_rate(self) -> float:
        if self.total_images == 0:
            return 0.0
        return self.successful_images / self.total_images
    
    @property
    def elapsed_time(self) -> Optional[float]:
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return None

class SyntheticDatasetPipeline:
    """í•©ì„± ë°ì´í„°ì…‹ ìƒì„± í†µí•© íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: PipelineConfig):
        self.config = config
        self.stats = PipelineStats()
        self.logger = self._setup_logger()
        self.supabase = None
        
        # í™˜ê²½ ì„¤ì • ë¡œë“œ
        self._load_environment()
        
        # Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if SUPABASE_AVAILABLE and config.supabase_url and config.supabase_key:
            try:
                self.supabase = create_client(config.supabase_url, config.supabase_key)
                self.logger.info("âœ… Supabase í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ")
            except Exception as e:
                self.logger.error(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
    
    def _setup_logger(self) -> logging.Logger:
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger('SyntheticDatasetPipeline')
        logger.setLevel(getattr(logging, self.config.log_level))
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        log_dir = Path(self.config.project_root) / "logs"
        log_dir.mkdir(exist_ok=True)
        
        file_handler = logging.FileHandler(
            log_dir / f"synthetic_pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        )
        file_handler.setLevel(logging.INFO)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def _load_environment(self):
        """í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"""
        try:
            load_dotenv(Path(self.config.project_root) / "config" / "synthetic_dataset.env")
            
            # Supabase ì„¤ì •
            if not self.config.supabase_url:
                self.config.supabase_url = os.getenv('VITE_SUPABASE_URL')
            if not self.config.supabase_key:
                self.config.supabase_key = os.getenv('VITE_SUPABASE_ANON_KEY')
            
            # LDraw ê²½ë¡œ
            if os.getenv('LDRAW_PARTS_PATH'):
                self.config.ldraw_path = os.getenv('LDRAW_PARTS_PATH')
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬
            if os.getenv('SYNTHETIC_OUTPUT_DIR'):
                self.config.output_dir = os.getenv('SYNTHETIC_OUTPUT_DIR')
            
            self.logger.info("âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _validate_ldraw_files(self) -> List[str]:
        """LDraw íŒŒì¼ ê²€ì¦"""
        valid_parts = []
        ldraw_path = Path(self.config.ldraw_path)
        
        if not ldraw_path.exists():
            self.logger.error(f"âŒ LDraw ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {ldraw_path}")
            return valid_parts
        
        for part_id in self.config.part_list:
            part_file = ldraw_path / f"{part_id}.dat"
            if part_file.exists():
                valid_parts.append(part_id)
                self.logger.info(f"âœ… LDraw íŒŒì¼ í™•ì¸: {part_id}")
            else:
                self.logger.warning(f"âš ï¸ LDraw íŒŒì¼ ì—†ìŒ: {part_id}")
        
        return valid_parts
    
    def _create_output_directories(self):
        """ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
        output_path = Path(self.config.output_dir)
        directories = [
            output_path,
            output_path / "images",
            output_path / "annotations", 
            output_path / "metadata",
            output_path / "logs"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            self.logger.info(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {directory}")
    
    def _render_single_part(self, part_id: str, image_count: int) -> Dict:
        """ë‹¨ì¼ ë¶€í’ˆ ë Œë”ë§ (Blender ìŠ¤í¬ë¦½íŠ¸ í˜¸ì¶œ)"""
        try:
            # Blender ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            blender_script = Path(self.config.project_root) / "scripts" / "render_ldraw_to_supabase.py"
            
            cmd = [
                "blender",
                "--background",
                "--python", str(blender_script),
                "--",
                "--part-id", part_id,
                "--count", str(image_count),
                "--ldraw-path", self.config.ldraw_path,
                "--output-dir", str(Path(self.config.output_dir) / part_id)
            ]
            
            if self.config.supabase_url and self.config.supabase_key:
                cmd.extend(["--supabase-url", self.config.supabase_url])
                cmd.extend(["--supabase-key", self.config.supabase_key])
            
            self.logger.info(f"ğŸ¯ {part_id} ë Œë”ë§ ì‹œì‘ ({image_count}ê°œ ì´ë¯¸ì§€)")
            
            # Blender ì‹¤í–‰
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)
            
            if result.returncode == 0:
                self.logger.info(f"âœ… {part_id} ë Œë”ë§ ì™„ë£Œ")
                return {
                    'success': True,
                    'part_id': part_id,
                    'image_count': image_count,
                    'output': result.stdout
                }
            else:
                self.logger.error(f"âŒ {part_id} ë Œë”ë§ ì‹¤íŒ¨: {result.stderr}")
                return {
                    'success': False,
                    'part_id': part_id,
                    'error': result.stderr
                }
                
        except subprocess.TimeoutExpired:
            self.logger.error(f"âŒ {part_id} ë Œë”ë§ íƒ€ì„ì•„ì›ƒ")
            return {
                'success': False,
                'part_id': part_id,
                'error': 'Timeout'
            }
        except Exception as e:
            self.logger.error(f"âŒ {part_id} ë Œë”ë§ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'part_id': part_id,
                'error': str(e)
            }
    
    def _process_part_batch(self, part_ids: List[str]) -> List[Dict]:
        """ë¶€í’ˆ ë°°ì¹˜ ì²˜ë¦¬"""
        results = []
        
        for part_id in part_ids:
            result = self._render_single_part(part_id, self.config.max_images_per_part)
            results.append(result)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if result['success']:
                self.stats.completed_parts += 1
                self.stats.successful_images += result.get('image_count', 0)
            else:
                self.stats.failed_images += 1
            
            self.stats.total_images += self.config.max_images_per_part
        
        return results
    
    def _upload_to_supabase(self, part_id: str, image_files: List[str], annotation_files: List[str]):
        """Supabaseì— ì—…ë¡œë“œ"""
        if not self.supabase:
            self.logger.warning("âš ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤.")
            return
        
        try:
            uploaded_count = 0
            
            for image_file, annotation_file in zip(image_files, annotation_files):
                if not Path(image_file).exists() or not Path(annotation_file).exists():
                    continue
                
                # ì´ë¯¸ì§€ ì—…ë¡œë“œ
                with open(image_file, 'rb') as f:
                    image_data = f.read()
                
                image_path = f"synthetic/{part_id}/{Path(image_file).name}"
                result = self.supabase.storage.from_(self.config.bucket_name).upload(
                    image_path, image_data, file_options={"content-type": "image/png"}
                )
                
                if result.get('error'):
                    self.logger.error(f"âŒ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {result['error']}")
                    continue
                
                # ì–´ë…¸í…Œì´ì…˜ ì—…ë¡œë“œ
                with open(annotation_file, 'rb') as f:
                    annotation_data = f.read()
                
                annotation_path = f"synthetic/{part_id}/{Path(annotation_file).name}"
                result = self.supabase.storage.from_(self.config.bucket_name).upload(
                    annotation_path, annotation_data, file_options={"content-type": "text/plain"}
                )
                
                if result.get('error'):
                    self.logger.error(f"âŒ ì–´ë…¸í…Œì´ì…˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {result['error']}")
                    continue
                
                uploaded_count += 1
            
            self.logger.info(f"âœ… {part_id} Supabase ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_count}ê°œ íŒŒì¼")
            
        except Exception as e:
            self.logger.error(f"âŒ Supabase ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _generate_report(self) -> Dict:
        """ì‹¤í–‰ ë³´ê³ ì„œ ìƒì„±"""
        report = {
            'pipeline_config': asdict(self.config),
            'pipeline_stats': asdict(self.stats),
            'timestamp': datetime.now().isoformat(),
            'success_rate': self.stats.success_rate,
            'elapsed_time': self.stats.elapsed_time
        }
        
        # ë³´ê³ ì„œ ì €ì¥
        report_path = Path(self.config.output_dir) / "logs" / f"pipeline_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ğŸ“Š ë³´ê³ ì„œ ìƒì„±: {report_path}")
        return report
    
    def run_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("ğŸ§± BrickBox í•©ì„± ë°ì´í„°ì…‹ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        self.stats.start_time = datetime.now()
        
        try:
            # 1. LDraw íŒŒì¼ ê²€ì¦
            self.logger.info("1ï¸âƒ£ LDraw íŒŒì¼ ê²€ì¦...")
            valid_parts = self._validate_ldraw_files()
            self.stats.total_parts = len(valid_parts)
            
            if not valid_parts:
                self.logger.error("âŒ ìœ íš¨í•œ LDraw íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            # 2. ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            self.logger.info("2ï¸âƒ£ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±...")
            self._create_output_directories()
            
            # 3. ë°°ì¹˜ ì²˜ë¦¬
            self.logger.info("3ï¸âƒ£ ë°°ì¹˜ ë Œë”ë§ ì‹œì‘...")
            batch_results = []
            
            for i in range(0, len(valid_parts), self.config.batch_size):
                batch = valid_parts[i:i + self.config.batch_size]
                self.logger.info(f"ğŸ“¦ ë°°ì¹˜ {i//self.config.batch_size + 1}: {batch}")
                
                batch_result = self._process_part_batch(batch)
                batch_results.extend(batch_result)
                
                # ë°°ì¹˜ ê°„ ëŒ€ê¸°
                if i + self.config.batch_size < len(valid_parts):
                    time.sleep(2)
            
            # 4. ê²°ê³¼ ê²€ì¦
            self.logger.info("4ï¸âƒ£ ê²°ê³¼ ê²€ì¦...")
            successful_parts = [r for r in batch_results if r['success']]
            failed_parts = [r for r in batch_results if not r['success']]
            
            self.logger.info(f"âœ… ì„±ê³µ: {len(successful_parts)}ê°œ ë¶€í’ˆ")
            if failed_parts:
                self.logger.warning(f"âš ï¸ ì‹¤íŒ¨: {len(failed_parts)}ê°œ ë¶€í’ˆ")
                for failed in failed_parts:
                    self.logger.warning(f"  - {failed['part_id']}: {failed.get('error', 'Unknown error')}")
            
            # 5. ë³´ê³ ì„œ ìƒì„±
            self.logger.info("5ï¸âƒ£ ë³´ê³ ì„œ ìƒì„±...")
            report = self._generate_report()
            
            # 6. ì™„ë£Œ ë©”ì‹œì§€
            self.stats.end_time = datetime.now()
            self.logger.info("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            self.logger.info(f"ğŸ“Š í†µê³„:")
            self.logger.info(f"  - ì´ ë¶€í’ˆ: {self.stats.total_parts}ê°œ")
            self.logger.info(f"  - ì™„ë£Œëœ ë¶€í’ˆ: {self.stats.completed_parts}ê°œ")
            self.logger.info(f"  - ì´ ì´ë¯¸ì§€: {self.stats.total_images}ê°œ")
            self.logger.info(f"  - ì„±ê³µí•œ ì´ë¯¸ì§€: {self.stats.successful_images}ê°œ")
            self.logger.info(f"  - ì„±ê³µë¥ : {self.stats.success_rate:.2%}")
            self.logger.info(f"  - ì†Œìš” ì‹œê°„: {self.stats.elapsed_time:.2f}ì´ˆ")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='BrickBox í•©ì„± ë°ì´í„°ì…‹ ìƒì„± íŒŒì´í”„ë¼ì¸')
    parser.add_argument('--part-list', nargs='+', default=['3001', '3002', '3003'],
                       help='ë Œë”ë§í•  ë¶€í’ˆ ID ëª©ë¡')
    parser.add_argument('--max-images', type=int, default=100,
                       help='ë¶€í’ˆë‹¹ ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜')
    parser.add_argument('--batch-size', type=int, default=5,
                       help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--output-dir', default='./output/synthetic',
                       help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--ldraw-path', default='C:/LDraw/parts',
                       help='LDraw ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ')
    parser.add_argument('--log-level', default='INFO',
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       help='ë¡œê·¸ ë ˆë²¨')
    
    args = parser.parse_args()
    
    # ì„¤ì • ìƒì„±
    config = PipelineConfig(
        part_list=args.part_list,
        max_images_per_part=args.max_images,
        batch_size=args.batch_size,
        output_dir=args.output_dir,
        ldraw_path=args.ldraw_path,
        log_level=args.log_level
    )
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = SyntheticDatasetPipeline(config)
    success = pipeline.run_pipeline()
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
