#!/usr/bin/env python3
"""
ğŸš€ BrickBox 2ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ YOLO11s-seg í•™ìŠµ íŒŒì´í”„ë¼ì¸

1ì°¨: YOLO11n-seg í•™ìŠµ (ë¹ ë¥¸ ìŠ¤ìº”ìš©)
2ì°¨: YOLO11s-seg í•™ìŠµ (ì •ë°€ ê²€ì¦ìš©)

íŠ¹ì§•:
- í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ë™ì‹œ í•™ìŠµ
- ì„±ëŠ¥ ê¸°ë°˜ ëª¨ë¸ ì„ íƒ
- ìë™ ONNX ë³€í™˜
- Supabase ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
"""

import os
import sys
import json
import time
import shutil
import requests
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HybridYOLOTrainingPipeline:
    """2ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ YOLO í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.models_dir = self.project_root / 'public' / 'models'
        self.output_dir = self.project_root / 'output' / 'hybrid_training'
        self.training_results = {}
        
        # Supabase ì„¤ì •
        self.supabase_url = os.getenv('VITE_SUPABASE_URL')
        self.supabase_key = os.getenv('VITE_SUPABASE_SERVICE_ROLE')
        
        if not self.supabase_url or not self.supabase_key:
            raise ValueError("Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def initialize_training_environment(self):
        """í•™ìŠµ í™˜ê²½ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ YOLO í•™ìŠµ í™˜ê²½ ì´ˆê¸°í™”...")
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            self.output_dir.mkdir(parents=True, exist_ok=True)
            
            # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
            self.models_dir.mkdir(parents=True, exist_ok=True)
            
            # Ultralytics ì„¤ì¹˜ í™•ì¸
            try:
                from ultralytics import YOLO
                logger.info("âœ… Ultralytics ì„¤ì¹˜ í™•ì¸ ì™„ë£Œ")
            except ImportError:
                logger.error("âŒ Ultralyticsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                raise
            
            logger.info("âœ… í•™ìŠµ í™˜ê²½ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ í™˜ê²½ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def prepare_hybrid_dataset(self, dataset_path: str) -> Dict[str, str]:
        """í•˜ì´ë¸Œë¦¬ë“œ í•™ìŠµìš© ë°ì´í„°ì…‹ ì¤€ë¹„"""
        try:
            logger.info("ğŸ“Š í•˜ì´ë¸Œë¦¬ë“œ ë°ì´í„°ì…‹ ì¤€ë¹„...")
            
            dataset_path = Path(dataset_path)
            
            # Train/Val ë¶„í•  í™•ì¸
            train_images = dataset_path / 'train' / 'images'
            train_labels = dataset_path / 'train' / 'labels'
            val_images = dataset_path / 'val' / 'images'
            val_labels = dataset_path / 'val' / 'labels'
            
            if not all([train_images.exists(), train_labels.exists(), 
                       val_images.exists(), val_labels.exists()]):
                raise ValueError("Train/Val ë¶„í• ëœ ë°ì´í„°ì…‹ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
            # ë°ì´í„°ì…‹ í†µê³„
            train_count = len(list(train_images.glob('*.jpg')))
            val_count = len(list(val_images.glob('*.jpg')))
            
            logger.info(f"ğŸ“Š ë°ì´í„°ì…‹ í†µê³„:")
            logger.info(f"   - í•™ìŠµ ë°ì´í„°: {train_count}ê°œ")
            logger.info(f"   - ê²€ì¦ ë°ì´í„°: {val_count}ê°œ")
            logger.info(f"   - ì´ ë°ì´í„°: {train_count + val_count}ê°œ")
            
            # dataset.yaml ìƒì„±
            dataset_config = {
                'path': str(dataset_path),
                'train': 'train/images',
                'val': 'val/images',
                'nc': 1,
                'names': ['lego_part']
            }
            
            yaml_path = dataset_path / 'dataset.yaml'
            with open(yaml_path, 'w') as f:
                import yaml
                yaml.dump(dataset_config, f, default_flow_style=False)
            
            logger.info(f"âœ… dataset.yaml ìƒì„±: {yaml_path}")
            
            return {
                'dataset_path': str(dataset_path),
                'yaml_path': str(yaml_path),
                'train_count': train_count,
                'val_count': val_count
            }
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            raise
    
    def train_stage1_model(self, dataset_info: Dict) -> Dict:
        """1ì°¨ ëª¨ë¸ í•™ìŠµ (YOLO11n-seg)"""
        try:
            logger.info("ğŸ”§ 1ì°¨ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (YOLO11n-seg)...")
            
            from ultralytics import YOLO
            import torch
            
            # YOLO11n-seg ëª¨ë¸ ì´ˆê¸°í™”
            model = YOLO('yolo11n-seg.pt')
            
            # í•™ìŠµ ì„¤ì •
            training_name = f'brickbox_hybrid_stage1_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
            
            # í•™ìŠµ ì‹¤í–‰
            results = model.train(
                data=dataset_info['yaml_path'],
                epochs=100,
                batch=16,
                imgsz=640,
                device='cuda' if torch.cuda.is_available() else 'cpu',
                project=str(self.output_dir),
                name=training_name,
                save=True,
                plots=True,
                val=True,
                patience=10,
                save_period=10
            )
            
            # í•™ìŠµ ê²°ê³¼ ì €ì¥
            stage1_results = {
                'model_name': 'yolo11n-seg',
                'model_stage': 'stage1',
                'training_name': training_name,
                'best_model_path': str(self.output_dir / training_name / 'weights' / 'best.pt'),
                'last_model_path': str(self.output_dir / training_name / 'weights' / 'last.pt'),
                'metrics': {
                    'mAP50': float(results.results_dict.get('metrics/mAP50(B)', 0.0)),
                    'mAP50_95': float(results.results_dict.get('metrics/mAP50-95(B)', 0.0)),
                    'precision': float(results.results_dict.get('metrics/precision(B)', 0.0)),
                    'recall': float(results.results_dict.get('metrics/recall(B)', 0.0))
                },
                'training_time': results.results_dict.get('training_time', 0),
                'epochs_completed': results.results_dict.get('epochs', 0)
            }
            
            logger.info(f"âœ… 1ì°¨ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {training_name}")
            logger.info(f"   - mAP50: {stage1_results['metrics']['mAP50']:.4f}")
            logger.info(f"   - mAP50-95: {stage1_results['metrics']['mAP50_95']:.4f}")
            
            return stage1_results
            
        except Exception as e:
            logger.error(f"âŒ 1ì°¨ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            raise
    
    def train_stage2_model(self, dataset_info: Dict) -> Dict:
        """2ì°¨ ëª¨ë¸ í•™ìŠµ (YOLO11s-seg)"""
        try:
            logger.info("ğŸ”§ 2ì°¨ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (YOLO11s-seg)...")
            
            from ultralytics import YOLO
            import torch
            
            # YOLO11s-seg ëª¨ë¸ ì´ˆê¸°í™”
            model = YOLO('yolo11s-seg.pt')
            
            # í•™ìŠµ ì„¤ì •
            training_name = f'brickbox_hybrid_stage2_{datetime.now().strftime("%Y%m%d_%H%M%S")}'
            
            # í•™ìŠµ ì‹¤í–‰
            results = model.train(
                data=dataset_info['yaml_path'],
                epochs=100,
                batch=16,
                imgsz=640,
                device='cuda' if torch.cuda.is_available() else 'cpu',
                project=str(self.output_dir),
                name=training_name,
                save=True,
                plots=True,
                val=True,
                patience=10,
                save_period=10
            )
            
            # í•™ìŠµ ê²°ê³¼ ì €ì¥
            stage2_results = {
                'model_name': 'yolo11s-seg',
                'model_stage': 'stage2',
                'training_name': training_name,
                'best_model_path': str(self.output_dir / training_name / 'weights' / 'best.pt'),
                'last_model_path': str(self.output_dir / training_name / 'weights' / 'last.pt'),
                'metrics': {
                    'mAP50': float(results.results_dict.get('metrics/mAP50(B)', 0.0)),
                    'mAP50_95': float(results.results_dict.get('metrics/mAP50-95(B)', 0.0)),
                    'precision': float(results.results_dict.get('metrics/precision(B)', 0.0)),
                    'recall': float(results.results_dict.get('metrics/recall(B)', 0.0))
                },
                'training_time': results.results_dict.get('training_time', 0),
                'epochs_completed': results.results_dict.get('epochs', 0)
            }
            
            logger.info(f"âœ… 2ì°¨ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {training_name}")
            logger.info(f"   - mAP50: {stage2_results['metrics']['mAP50']:.4f}")
            logger.info(f"   - mAP50-95: {stage2_results['metrics']['mAP50_95']:.4f}")
            
            return stage2_results
            
        except Exception as e:
            logger.error(f"âŒ 2ì°¨ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            raise
    
    def convert_to_onnx(self, model_results: Dict) -> str:
        """PyTorch ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜"""
        try:
            logger.info(f"ğŸ”„ ONNX ë³€í™˜ ì‹œì‘: {model_results['model_name']}")
            
            from ultralytics import YOLO
            
            # ëª¨ë¸ ë¡œë“œ
            model = YOLO(model_results['best_model_path'])
            
            # ONNX ë³€í™˜
            onnx_path = model.export(
                format='onnx',
                imgsz=640,
                optimize=True,
                half=True,  # FP16 ìµœì í™”
                dynamic=False,
                simplify=True
            )
            
            logger.info(f"âœ… ONNX ë³€í™˜ ì™„ë£Œ: {onnx_path}")
            return onnx_path
            
        except Exception as e:
            logger.error(f"âŒ ONNX ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    def deploy_models(self, stage1_results: Dict, stage2_results: Dict):
        """í•™ìŠµëœ ëª¨ë¸ ë°°í¬"""
        try:
            logger.info("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ë°°í¬ ì‹œì‘...")
            
            # ONNX ë³€í™˜
            stage1_onnx = self.convert_to_onnx(stage1_results)
            stage2_onnx = self.convert_to_onnx(stage2_results)
            
            # ëª¨ë¸ íŒŒì¼ ë³µì‚¬
            stage1_dest = self.models_dir / 'yolo11n-seg.onnx'
            stage2_dest = self.models_dir / 'yolo11s-seg.onnx'
            
            shutil.copy2(stage1_onnx, stage1_dest)
            shutil.copy2(stage2_onnx, stage2_dest)
            
            logger.info(f"âœ… ëª¨ë¸ ë°°í¬ ì™„ë£Œ:")
            logger.info(f"   - 1ì°¨ ëª¨ë¸: {stage1_dest}")
            logger.info(f"   - 2ì°¨ ëª¨ë¸: {stage2_dest}")
            
            return {
                'stage1_onnx': str(stage1_dest),
                'stage2_onnx': str(stage2_dest)
            }
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë°°í¬ ì‹¤íŒ¨: {e}")
            raise
    
    def update_model_registry(self, stage1_results: Dict, stage2_results: Dict, deployment_info: Dict):
        """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸"""
        try:
            logger.info("ğŸ“Š ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸...")
            
            import requests
            
            headers = {
                'apikey': self.supabase_key,
                'Authorization': f'Bearer {self.supabase_key}',
                'Content-Type': 'application/json'
            }
            
            # 1ì°¨ ëª¨ë¸ ë“±ë¡
            stage1_data = {
                'model_name': 'yolo11n-seg',
                'model_version': '1.0.0',
                'model_type': 'segmentation',
                'model_stage': 'stage1',
                'model_path': deployment_info['stage1_onnx'],
                'pt_model_path': stage1_results['best_model_path'],
                'performance_metrics': stage1_results['metrics'],
                'segmentation_support': True,
                'memory_usage': 2000,  # 2GB
                'fps_performance': 50.0,
                'model_size_mb': 5.2,
                'hybrid_config': {
                    'conf_threshold': 0.3,
                    'max_detections': 50,
                    'input_size': 640
                },
                'is_active': True,
                'training_metadata': {
                    'training_name': stage1_results['training_name'],
                    'epochs_completed': stage1_results['epochs_completed'],
                    'training_time': stage1_results['training_time']
                }
            }
            
            # 2ì°¨ ëª¨ë¸ ë“±ë¡
            stage2_data = {
                'model_name': 'yolo11s-seg',
                'model_version': '1.0.0',
                'model_type': 'segmentation',
                'model_stage': 'stage2',
                'model_path': deployment_info['stage2_onnx'],
                'pt_model_path': stage2_results['best_model_path'],
                'performance_metrics': stage2_results['metrics'],
                'segmentation_support': True,
                'memory_usage': 4000,  # 4GB
                'fps_performance': 27.5,
                'model_size_mb': 21.5,
                'hybrid_config': {
                    'conf_threshold': 0.5,
                    'max_detections': 20,
                    'input_size': 640
                },
                'is_active': True,
                'training_metadata': {
                    'training_name': stage2_results['training_name'],
                    'epochs_completed': stage2_results['epochs_completed'],
                    'training_time': stage2_results['training_time']
                }
            }
            
            # Supabaseì— ëª¨ë¸ ë“±ë¡
            for model_data in [stage1_data, stage2_data]:
                response = requests.post(
                    f'{self.supabase_url}/rest/v1/model_registry',
                    headers=headers,
                    json=model_data
                )
                
                if response.status_code not in [200, 201]:
                    logger.warning(f"âš ï¸ ëª¨ë¸ ë“±ë¡ ì‹¤íŒ¨: {model_data['model_name']}")
                else:
                    logger.info(f"âœ… ëª¨ë¸ ë“±ë¡ ì™„ë£Œ: {model_data['model_name']}")
            
            # í™œì„± í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì„¤ì •
            self.set_active_hybrid_models()
            
            logger.info("âœ… ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            raise
    
    def set_active_hybrid_models(self):
        """í™œì„± í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì„¤ì •"""
        try:
            import requests
            
            headers = {
                'apikey': self.supabase_key,
                'Authorization': f'Bearer {self.supabase_key}',
                'Content-Type': 'application/json'
            }
            
            # í™œì„± ëª¨ë¸ ì„¤ì •
            active_data = {
                'hybrid_mode': True,
                'stage1_config': {
                    'enabled': True,
                    'auto_load': True,
                    'conf_threshold': 0.3,
                    'max_detections': 50
                },
                'stage2_config': {
                    'enabled': True,
                    'auto_load': False,
                    'trigger_threshold': 0.3,
                    'conf_threshold': 0.5,
                    'max_detections': 20
                }
            }
            
            response = requests.patch(
                f'{self.supabase_url}/rest/v1/active_models',
                headers=headers,
                json=active_data
            )
            
            if response.status_code in [200, 201]:
                logger.info("âœ… í™œì„± í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ í™œì„± ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨")
                
        except Exception as e:
            logger.error(f"âŒ í™œì„± ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def run_hybrid_training(self, dataset_path: str):
        """í•˜ì´ë¸Œë¦¬ë“œ í•™ìŠµ ì „ì²´ ì‹¤í–‰"""
        try:
            logger.info("ğŸš€ BrickBox í•˜ì´ë¸Œë¦¬ë“œ YOLO í•™ìŠµ ì‹œì‘")
            
            # 1. í™˜ê²½ ì´ˆê¸°í™”
            self.initialize_training_environment()
            
            # 2. ë°ì´í„°ì…‹ ì¤€ë¹„
            dataset_info = self.prepare_hybrid_dataset(dataset_path)
            
            # 3. 1ì°¨ ëª¨ë¸ í•™ìŠµ
            stage1_results = self.train_stage1_model(dataset_info)
            
            # 4. 2ì°¨ ëª¨ë¸ í•™ìŠµ
            stage2_results = self.train_stage2_model(dataset_info)
            
            # 5. ëª¨ë¸ ë°°í¬
            deployment_info = self.deploy_models(stage1_results, stage2_results)
            
            # 6. ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
            self.update_model_registry(stage1_results, stage2_results, deployment_info)
            
            # 7. ê²°ê³¼ ì €ì¥
            self.training_results = {
                'stage1': stage1_results,
                'stage2': stage2_results,
                'deployment': deployment_info,
                'timestamp': datetime.now().isoformat()
            }
            
            logger.info("ğŸ‰ í•˜ì´ë¸Œë¦¬ë“œ YOLO í•™ìŠµ ì™„ë£Œ!")
            logger.info(f"   - 1ì°¨ ëª¨ë¸ mAP50: {stage1_results['metrics']['mAP50']:.4f}")
            logger.info(f"   - 2ì°¨ ëª¨ë¸ mAP50: {stage2_results['metrics']['mAP50']:.4f}")
            
            return self.training_results
            
        except Exception as e:
            logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ í•™ìŠµ ì‹¤íŒ¨: {e}")
            raise

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python hybrid_yolo_training_pipeline.py <dataset_path>")
        sys.exit(1)
    
    dataset_path = sys.argv[1]
    
    try:
        pipeline = HybridYOLOTrainingPipeline()
        results = pipeline.run_hybrid_training(dataset_path)
        
        print("âœ… í•˜ì´ë¸Œë¦¬ë“œ í•™ìŠµ ì™„ë£Œ!")
        print(f"ê²°ê³¼: {json.dumps(results, indent=2, ensure_ascii=False)}")
        
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
