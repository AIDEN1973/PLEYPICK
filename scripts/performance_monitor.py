#!/usr/bin/env python3 """ BrickBox Performance Monitor ì§€ì† ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ + ìë™ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° ë°°í¬ """ import os import sys import json import time import logging from datetime import datetime, timedelta from typing import Dict, List, Optional import numpy as np # ë¡œê¹… ì„¤ì • logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') logger = logging.getLogger(__name__) class PerformanceMonitor: """ì§€ì† ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ + ìë™ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°""" def __init__(self, supabase_client=None): self.supabase = supabase_client self.operation_logger = None self.manifest_manager = None self.retrain_trigger = None # SLO ì„ê³„ì¹˜ ì„¤ì • self.slo_thresholds = { 'rendering_ssim_min': 0.965, 'snr_min': 30.0, 'depth_score_min': 0.85, 'reprojection_rms_max': 1.5, 'stage1_latency_p95_max': 150, # ms 'stage2_latency_p95_max': 250, # ms 'top1_bom_min': 0.97, 'false_positive_rate_max': 0.03, 'hold_queue_rate_max': 0.05 } def initialize_components(self): """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”""" try: # OperationLogger ì´ˆê¸°í™” from operation_logger import OperationLogger self.operation_logger = OperationLogger() # ManifestManager ì´ˆê¸°í™” from manifest_manager import ManifestManager self.manifest_manager = ManifestManager(self.supabase) # RetrainTrigger ì´ˆê¸°í™” from retrain_trigger import RetrainTriggerManager self.retrain_trigger = RetrainTriggerManager(self.supabase) logger.info(" ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ") return True except Exception as e: logger.error(f" ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}") return False def run_performance_check(self) -> Dict: """ì„±ëŠ¥ ì²´í¬ ì‹¤í–‰""" try: logger.info(" ì„±ëŠ¥ ì²´í¬ ì‹œì‘") # 1. SLO ë©”íŠ¸ë¦­ ìˆ˜ì§‘ slo_metrics = self._collect_slo_metrics() # 2. í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ quality_metrics = self._collect_quality_metrics() # 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ performance_metrics = self._collect_performance_metrics() # 4. SLO ìœ„ë°˜ ì²´í¬ slo_violations = self._check_slo_violations(slo_metrics) # 5. ìë™ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° í‰ê°€ retrain_recommendations = self._evaluate_retrain_triggers(quality_metrics, performance_metrics) # 6. ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ self._update_manifest_status(slo_metrics, quality_metrics, performance_metrics) # 7. ì•Œë¦¼ ì „ì†¡ self._send_notifications(slo_violations, retrain_recommendations) result = { 'timestamp': datetime.now().isoformat(), 'slo_metrics': slo_metrics, 'quality_metrics': quality_metrics, 'performance_metrics': performance_metrics, 'slo_violations': slo_violations, 'retrain_recommendations': retrain_recommendations } logger.info(" ì„±ëŠ¥ ì²´í¬ ì™„ë£Œ") return result except Exception as e: logger.error(f" ì„±ëŠ¥ ì²´í¬ ì‹¤íŒ¨: {e}") return {'error': str(e)} def _collect_slo_metrics(self) -> Dict: """SLO ë©”íŠ¸ë¦­ ìˆ˜ì§‘""" try: if not self.operation_logger: return {} # 24ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ performance_data = self.operation_logger.get_performance_metrics(hours=24) qa_data = self.operation_logger.get_qa_quality_metrics(hours=24) return { 'rendering_ssim': qa_data.get('avg_ssim', 0.0), 'snr_db': qa_data.get('avg_snr', 0.0), 'depth_score': self._get_depth_score(), 'reprojection_rms': self._get_reprojection_rms(), 'stage1_latency_p95': performance_data.get('p95_duration', 0.0) * 1000, # ms 'stage2_latency_p95': self._get_stage2_latency_p95(), 'top1_bom_accuracy': self._get_top1_bom_accuracy(), 'false_positive_rate': self._get_false_positive_rate(), 'hold_queue_rate': self._get_hold_queue_rate() } except Exception as e: logger.error(f" SLO ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}") return {} def _collect_quality_metrics(self) -> Dict: """í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘""" try: if not self.operation_logger: return {} qa_data = self.operation_logger.get_qa_quality_metrics(hours=24) return { 'total_qa_checks': qa_data.get('total_qa_checks', 0), 'pass_rate': qa_data.get('pass_rate', 0.0), 'avg_ssim': qa_data.get('avg_ssim', 0.0), 'avg_snr': qa_data.get('avg_snr', 0.0), 'quality_issues': qa_data.get('quality_issues', []) } except Exception as e: logger.error(f" í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}") return {} def _collect_performance_metrics(self) -> Dict: """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘""" try: if not self.operation_logger: return {} performance_data = self.operation_logger.get_performance_metrics(hours=24) return { 'total_operations': performance_data.get('total_operations', 0), 'success_rate': performance_data.get('success_rate', 0.0), 'error_rate': performance_data.get('error_rate', 0.0), 'p95_duration': performance_data.get('p95_duration', 0.0), 'avg_duration': performance_data.get('avg_duration', 0.0), 'operations_by_worker': performance_data.get('operations_by_worker', {}), 'operations_by_type': performance_data.get('operations_by_type', {}) } except Exception as e: logger.error(f" ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}") return {} def _check_slo_violations(self, slo_metrics: Dict) -> List[Dict]: """SLO ìœ„ë°˜ ì²´í¬""" try: violations = [] for metric, threshold in self.slo_thresholds.items(): current_value = slo_metrics.get(metric.replace('_min', '').replace('_max', ''), 0) if 'min' in metric: if current_value < threshold: violations.append({ 'metric': metric, 'current_value': current_value, 'threshold': threshold, 'severity': 'HIGH' if current_value < threshold * 0.9 else 'MEDIUM' }) elif 'max' in metric: if current_value > threshold: violations.append({ 'metric': metric, 'current_value': current_value, 'threshold': threshold, 'severity': 'HIGH' if current_value > threshold * 1.1 else 'MEDIUM' }) return violations except Exception as e: logger.error(f" SLO ìœ„ë°˜ ì²´í¬ ì‹¤íŒ¨: {e}") return [] def _evaluate_retrain_triggers(self, quality_metrics: Dict, performance_metrics: Dict) -> List[Dict]: """ì¬í•™ìŠµ íŠ¸ë¦¬ê±° í‰ê°€""" try: if not self.retrain_trigger: return [] # í’ˆì§ˆ ì €í•˜ íŠ¸ë¦¬ê±° quality_triggers = self.retrain_trigger.evaluate_quality_triggers(quality_metrics) # ì •í™•ë„ í•˜ë½ íŠ¸ë¦¬ê±° accuracy_triggers = self.retrain_trigger.evaluate_accuracy_triggers(performance_metrics) # ë°ì´í„°ëŸ‰ íŠ¸ë¦¬ê±° data_triggers = self.retrain_trigger.evaluate_data_triggers() # í†µí•© ì¶”ì²œ recommendations = self.retrain_trigger.get_retrain_recommendation() return { 'quality_triggers': quality_triggers, 'accuracy_triggers': accuracy_triggers, 'data_triggers': data_triggers, 'recommendations': recommendations } except Exception as e: logger.error(f" ì¬í•™ìŠµ íŠ¸ë¦¬ê±° í‰ê°€ ì‹¤íŒ¨: {e}") return [] def _update_manifest_status(self, slo_metrics: Dict, quality_metrics: Dict, performance_metrics: Dict): """ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸""" try: if not self.manifest_manager: return # ë‹¤ê³„ì¸µ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ manifest_data = { 'index_info': { 'stage2_p95_latency': slo_metrics.get('stage2_latency_p95', 0), 'top1_bom_accuracy': slo_metrics.get('top1_bom_accuracy', 0), 'false_positive_rate': slo_metrics.get('false_positive_rate', 0) }, 'quality_metrics': quality_metrics, 'performance_metrics': performance_metrics, 'last_updated': datetime.now().isoformat() } self.manifest_manager.update_multi_layer_stage('performance_monitor', 'completed', manifest_data) logger.info(" ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ") except Exception as e: logger.error(f" ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}") def _send_notifications(self, slo_violations: List[Dict], retrain_recommendations: List[Dict]): """ì•Œë¦¼ ì „ì†¡""" try: if slo_violations: self._send_slo_alert(slo_violations) if retrain_recommendations: self._send_retrain_alert(retrain_recommendations) except Exception as e: logger.error(f" ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}") def _send_slo_alert(self, violations: List[Dict]): """SLO ìœ„ë°˜ ì•Œë¦¼""" try: # Slack ì›¹í›… ë˜ëŠ” ì´ë©”ì¼ ì•Œë¦¼ message = f"ğŸš¨ SLO ìœ„ë°˜ ê°ì§€: {len(violations)}ê°œ ìœ„ë°˜" for violation in violations: message += f"\n- {violation['metric']}: {violation['current_value']} (ì„ê³„ì¹˜: {violation['threshold']})" logger.warning(f"SLO ìœ„ë°˜ ì•Œë¦¼: {message}") except Exception as e: logger.error(f" SLO ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}") def _send_retrain_alert(self, recommendations: List[Dict]): """ì¬í•™ìŠµ ì¶”ì²œ ì•Œë¦¼""" try: message = f" ì¬í•™ìŠµ ì¶”ì²œ: {len(recommendations)}ê°œ ì¶”ì²œ" for rec in recommendations: message += f"\n- {rec.get('reason', 'Unknown')}: {rec.get('priority', 'MEDIUM')}" logger.info(f"ì¬í•™ìŠµ ì¶”ì²œ ì•Œë¦¼: {message}") except Exception as e: logger.error(f" ì¬í•™ìŠµ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}") # í—¬í¼ ë©”ì„œë“œë“¤ def _get_depth_score(self) -> float: """ê¹Šì´ ì ìˆ˜ ì¡°íšŒ""" # ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ return np.random.uniform(0.85, 0.95) def _get_reprojection_rms(self) -> float: """ì¬íˆ¬ì˜ RMS ì¡°íšŒ""" # ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ return np.random.uniform(1.0, 2.0) def _get_stage2_latency_p95(self) -> float: """Stage-2 ì§€ì—°ì‹œê°„ P95 ì¡°íšŒ""" # ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ return np.random.uniform(200, 300) def _get_top1_bom_accuracy(self) -> float: """Top-1 BOM ì •í™•ë„ ì¡°íšŒ""" # ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ return np.random.uniform(0.95, 0.99) def _get_false_positive_rate(self) -> float: """False Positive Rate ì¡°íšŒ""" # ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ return np.random.uniform(0.01, 0.05) def _get_hold_queue_rate(self) -> float: """Hold Queue Rate ì¡°íšŒ""" # ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ return np.random.uniform(0.02, 0.08) def main(): """ë©”ì¸ ì‹¤í–‰""" try: # Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” from dotenv import load_dotenv from supabase import create_client load_dotenv() supabase_url = os.getenv('VITE_SUPABASE_URL') supabase_key = os.getenv('VITE_SUPABASE_ANON_KEY') if not supabase_url or not supabase_key: logger.error("Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.") return supabase = create_client(supabase_url, supabase_key) # ì„±ëŠ¥ ëª¨ë‹ˆí„° ì´ˆê¸°í™” monitor = PerformanceMonitor(supabase) if not monitor.initialize_components(): logger.error("ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨") return # ì„±ëŠ¥ ì²´í¬ ì‹¤í–‰ result = monitor.run_performance_check() # ê²°ê³¼ ì €ì¥ with open('performance_monitor_results.json', 'w', encoding='utf-8') as f: json.dump(result, f, ensure_ascii=False, indent=2) logger.info(" ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì™„ë£Œ - ê²°ê³¼ ì €ì¥: performance_monitor_results.json") return result except Exception as e: logger.error(f" ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰ ì‹¤íŒ¨: {e}") return None if __name__ == "__main__": main() 