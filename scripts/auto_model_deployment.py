#!/usr/bin/env python3
"""
ğŸ¤– BrickBox ìë™ ëª¨ë¸ ë°°í¬ ì‹œìŠ¤í…œ

- í›ˆë ¨ ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ëª¨ë¸ ë°°í¬
- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë°˜ ìë™ ìŠ¹ì¸/ê±°ë¶€
- ë¡¤ë§ ë°°í¬ ì§€ì›
- ëª¨ë¸ ë²„ì „ ê´€ë¦¬
"""

import os
import sys
import json
import logging
import requests
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import hashlib

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/auto_deployment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AutoModelDeployment:
    def __init__(self):
        self.supabase_url = os.getenv('VITE_SUPABASE_URL', 'https://npferbxuxocbfnfbpcnz.supabase.co')
        self.supabase_key = os.getenv('VITE_SUPABASE_SERVICE_ROLE')
        self.models_bucket = 'models'
        
        # ë°°í¬ ì„¤ì •
        self.deployment_config = {
            'auto_approve_threshold': 0.05,  # 5% ì„±ëŠ¥ í–¥ìƒ ì‹œ ìë™ ìŠ¹ì¸
            'min_performance_metrics': {
                'mAP50': 0.7,
                'mAP50_95': 0.5,
                'precision': 0.8,
                'recall': 0.7
            },
            'rolling_deployment': True,
            'rollback_threshold': 0.1  # 10% ì„±ëŠ¥ ì €í•˜ ì‹œ ë¡¤ë°±
        }
    
    def check_training_completion(self) -> Optional[Dict]:
        """í›ˆë ¨ ì™„ë£Œ ëª¨ë¸ í™•ì¸"""
        try:
            logger.info("ğŸ” í›ˆë ¨ ì™„ë£Œ ëª¨ë¸ í™•ì¸ ì¤‘...")
            
            # ìµœê·¼ í›ˆë ¨ ì‘ì—… í™•ì¸
            response = requests.get(
                f"{self.supabase_url}/rest/v1/training_jobs",
                headers={
                    'apikey': self.supabase_key,
                    'Authorization': f'Bearer {self.supabase_key}',
                    'Content-Type': 'application/json'
                },
                params={
                    'status': 'eq.completed',
                    'order': 'created_at.desc',
                    'limit': '1'
                }
            )
            
            if response.status_code != 200:
                logger.error(f"âŒ í›ˆë ¨ ì‘ì—… ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}")
                return None
            
            jobs = response.json()
            if not jobs:
                logger.info("ğŸ“­ ì™„ë£Œëœ í›ˆë ¨ ì‘ì—… ì—†ìŒ")
                return None
            
            latest_job = jobs[0]
            logger.info(f"âœ… ìµœì‹  ì™„ë£Œëœ í›ˆë ¨ ì‘ì—…: {latest_job.get('job_id')}")
            
            return latest_job
            
        except Exception as e:
            logger.error(f"âŒ í›ˆë ¨ ì™„ë£Œ í™•ì¸ ì‹¤íŒ¨: {e}")
            return None
    
    def evaluate_model_performance(self, model_path: str, metrics: Dict) -> Dict:
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        try:
            logger.info("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
            
            # ìµœì†Œ ì„±ëŠ¥ ê¸°ì¤€ í™•ì¸
            min_metrics = self.deployment_config['min_performance_metrics']
            performance_check = {
                'mAP50': metrics.get('mAP50', 0) >= min_metrics['mAP50'],
                'mAP50_95': metrics.get('mAP50_95', 0) >= min_metrics['mAP50_95'],
                'precision': metrics.get('precision', 0) >= min_metrics['precision'],
                'recall': metrics.get('recall', 0) >= min_metrics['recall']
            }
            
            all_metrics_pass = all(performance_check.values())
            
            # í˜„ì¬ í™œì„± ëª¨ë¸ê³¼ ì„±ëŠ¥ ë¹„êµ
            current_model = self.get_current_active_model()
            performance_improvement = 0
            
            if current_model and current_model.get('performance_metrics'):
                current_metrics = current_model['performance_metrics']
                improvement = {
                    'mAP50': metrics.get('mAP50', 0) - current_metrics.get('mAP50', 0),
                    'mAP50_95': metrics.get('mAP50_95', 0) - current_metrics.get('mAP50_95', 0),
                    'precision': metrics.get('precision', 0) - current_metrics.get('precision', 0),
                    'recall': metrics.get('recall', 0) - current_metrics.get('recall', 0)
                }
                performance_improvement = sum(improvement.values()) / len(improvement)
            
            evaluation = {
                'all_metrics_pass': all_metrics_pass,
                'performance_improvement': performance_improvement,
                'auto_approve': all_metrics_pass and performance_improvement >= self.deployment_config['auto_approve_threshold'],
                'performance_check': performance_check,
                'current_model': current_model,
                'improvement_details': performance_improvement
            }
            
            logger.info(f"ğŸ“ˆ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼: {evaluation}")
            return evaluation
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {'all_metrics_pass': False, 'auto_approve': False}
    
    def get_current_active_model(self) -> Optional[Dict]:
        """í˜„ì¬ í™œì„± ëª¨ë¸ ì¡°íšŒ"""
        try:
            response = requests.get(
                f"{self.supabase_url}/rest/v1/model_registry",
                headers={
                    'apikey': self.supabase_key,
                    'Authorization': f'Bearer {self.supabase_key}',
                    'Content-Type': 'application/json'
                },
                params={
                    'is_active': 'eq.true',
                    'order': 'created_at.desc',
                    'limit': '1'
                }
            )
            
            if response.status_code == 200:
                models = response.json()
                return models[0] if models else None
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ í˜„ì¬ í™œì„± ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def upload_model_to_storage(self, local_model_path: str, model_name: str) -> Optional[str]:
        """ëª¨ë¸ì„ Supabase Storageì— ì—…ë¡œë“œ"""
        try:
            logger.info(f"ğŸ“¤ ëª¨ë¸ ì—…ë¡œë“œ ì¤‘: {model_name}")
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(local_model_path):
                logger.error(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {local_model_path}")
                return None
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(local_model_path)
            logger.info(f"ğŸ“ ëª¨ë¸ íŒŒì¼ í¬ê¸°: {file_size / 1024 / 1024:.1f} MB")
            
            # íŒŒì¼ í•´ì‹œ ìƒì„± (ì¤‘ë³µ í™•ì¸ìš©)
            with open(local_model_path, 'rb') as f:
                file_hash = hashlib.md5(f.read()).hexdigest()
            
            # ì—…ë¡œë“œ ê²½ë¡œ ìƒì„±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            upload_path = f"brickbox_s_seg_{timestamp}/{model_name}"
            
            # Supabase Storageì— ì—…ë¡œë“œ
            with open(local_model_path, 'rb') as f:
                files = {'file': (model_name, f, 'application/octet-stream')}
                
                response = requests.post(
                    f"{self.supabase_url}/storage/v1/object/{self.models_bucket}/{upload_path}",
                    headers={
                        'Authorization': f'Bearer {self.supabase_key}',
                        'Content-Type': 'multipart/form-data'
                    },
                    files=files
                )
            
            if response.status_code in [200, 201]:
                public_url = f"{self.supabase_url}/storage/v1/object/public/{self.models_bucket}/{upload_path}"
                logger.info(f"âœ… ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ: {public_url}")
                return public_url
            else:
                logger.error(f"âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def update_model_registry(self, model_data: Dict) -> bool:
        """ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸"""
        try:
            logger.info("ğŸ“‹ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì¤‘...")
            
            # ê¸°ì¡´ í™œì„± ëª¨ë¸ ë¹„í™œì„±í™”
            if model_data.get('current_model_id'):
                requests.patch(
                    f"{self.supabase_url}/rest/v1/model_registry",
                    headers={
                        'apikey': self.supabase_key,
                        'Authorization': f'Bearer {self.supabase_key}',
                        'Content-Type': 'application/json'
                    },
                    json={'is_active': False},
                    params={'id': 'eq.' + str(model_data['current_model_id'])}
                )
            
            # ìƒˆ ëª¨ë¸ ë“±ë¡
            response = requests.post(
                f"{self.supabase_url}/rest/v1/model_registry",
                headers={
                    'apikey': self.supabase_key,
                    'Authorization': f'Bearer {self.supabase_key}',
                    'Content-Type': 'application/json'
                },
                json=model_data
            )
            
            if response.status_code in [200, 201]:
                logger.info("âœ… ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                return True
            else:
                logger.error(f"âŒ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def deploy_model(self, training_job: Dict) -> bool:
        """ëª¨ë¸ ë°°í¬ ì‹¤í–‰"""
        try:
            logger.info("ğŸš€ ëª¨ë¸ ë°°í¬ ì‹œì‘...")
            
            # 1. ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸
            model_path = training_job.get('model_path')
            if not model_path or not os.path.exists(model_path):
                logger.error(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
                return False
            
            # 2. ì„±ëŠ¥ ë©”íŠ¸ë¦­ í™•ì¸
            metrics = training_job.get('performance_metrics', {})
            evaluation = self.evaluate_model_performance(model_path, metrics)
            
            if not evaluation['all_metrics_pass']:
                logger.warning("âš ï¸ ìµœì†Œ ì„±ëŠ¥ ê¸°ì¤€ ë¯¸ë‹¬ë¡œ ë°°í¬ ì¤‘ë‹¨")
                return False
            
            # 3. ëª¨ë¸ ì—…ë¡œë“œ
            model_name = f"set_{training_job.get('set_num', 'unknown')}_best.onnx"
            public_url = self.upload_model_to_storage(model_path, model_name)
            
            if not public_url:
                logger.error("âŒ ëª¨ë¸ ì—…ë¡œë“œ ì‹¤íŒ¨")
                return False
            
            # 4. ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
            model_data = {
                'model_name': f"brickbox_yolo_{training_job.get('set_num', 'unknown')}",
                'model_version': datetime.now().strftime('%Y%m%d_%H%M%S'),
                'model_type': 'yolo11n-seg',
                'model_path': public_url,
                'performance_metrics': metrics,
                'is_active': True,
                'training_job_id': training_job.get('job_id'),
                'auto_deployed': True,
                'deployment_timestamp': datetime.now().isoformat()
            }
            
            success = self.update_model_registry(model_data)
            
            if success:
                logger.info("ğŸ‰ ëª¨ë¸ ë°°í¬ ì™„ë£Œ!")
                
                # 5. ë°°í¬ ì•Œë¦¼ (ì„ íƒì‚¬í•­)
                self.send_deployment_notification(model_data)
                
                return True
            else:
                logger.error("âŒ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë°°í¬ ì‹¤íŒ¨: {e}")
            return False
    
    def send_deployment_notification(self, model_data: Dict):
        """ë°°í¬ ì™„ë£Œ ì•Œë¦¼"""
        try:
            logger.info("ğŸ“¢ ë°°í¬ ì•Œë¦¼ ì „ì†¡ ì¤‘...")
            
            # ì—¬ê¸°ì— ì•Œë¦¼ ë¡œì§ êµ¬í˜„ (Slack, Discord, Email ë“±)
            notification = {
                'message': f"ğŸ¤– ìƒˆ ëª¨ë¸ ë°°í¬ ì™„ë£Œ: {model_data['model_name']}",
                'version': model_data['model_version'],
                'performance': model_data['performance_metrics'],
                'timestamp': model_data['deployment_timestamp']
            }
            
            logger.info(f"ğŸ“¢ ë°°í¬ ì•Œë¦¼: {notification}")
            
        except Exception as e:
            logger.error(f"âŒ ë°°í¬ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    def run_auto_deployment(self):
        """ìë™ ë°°í¬ ì‹¤í–‰"""
        try:
            logger.info("ğŸ¤– ìë™ ëª¨ë¸ ë°°í¬ ì‹œì‘...")
            
            # 1. í›ˆë ¨ ì™„ë£Œ ëª¨ë¸ í™•ì¸
            training_job = self.check_training_completion()
            if not training_job:
                logger.info("ğŸ“­ ë°°í¬í•  ëª¨ë¸ ì—†ìŒ")
                return
            
            # 2. ëª¨ë¸ ë°°í¬
            success = self.deploy_model(training_job)
            
            if success:
                logger.info("ğŸ‰ ìë™ ë°°í¬ ì™„ë£Œ!")
            else:
                logger.error("âŒ ìë™ ë°°í¬ ì‹¤íŒ¨")
                
        except Exception as e:
            logger.error(f"âŒ ìë™ ë°°í¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    deployment = AutoModelDeployment()
    deployment.run_auto_deployment()

if __name__ == "__main__":
    main()
