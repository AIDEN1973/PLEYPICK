// OpenAI Chat Completions API í”„ë¡ì‹œ
// LLM ë¶„ì„ì„ ìœ„í•œ OpenAI API í”„ë¡ì‹œ

import dotenv from 'dotenv'
import { fileURLToPath } from 'url'
import { dirname, join } from 'path'

// í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
const __filename = fileURLToPath(import.meta.url)
const __dirname = dirname(__filename)

// í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ ë¡œë“œ
dotenv.config({ path: join(__dirname, '../../../.env') })

export default async function handler(req, res) {
  // CORS í—¤ë” ì„¤ì •
  res.setHeader('Access-Control-Allow-Origin', '*')
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization')
  
  // OPTIONS ìš”ì²­ ì²˜ë¦¬
  if (req.method === 'OPTIONS') {
    return res.status(200).end()
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ 
      success: false,
      error: 'Method not allowed' 
    })
  }

  try {
    console.log('ğŸ¤– OpenAI Chat Completions API í”„ë¡ì‹œ í˜¸ì¶œë¨:', {
      method: req.method,
      body: req.body,
      headers: req.headers
    })

    const { model, messages, temperature, max_tokens, response_format } = req.body

    // ì…ë ¥ê°’ ê²€ì¦
    if (!model || !messages) {
      console.warn('âŒ í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½:', { model: !!model, messages: !!messages })
      return res.status(400).json({ 
        success: false,
        error: 'modelê³¼ messagesê°€ í•„ìš”í•©ë‹ˆë‹¤' 
      })
    }

    // OpenAI API í‚¤ í™•ì¸ (í™˜ê²½ë³€ìˆ˜ë§Œ í—ˆìš©) // ğŸ”§ ìˆ˜ì •ë¨
    const apiKey = process.env.OPENAI_API_KEY || process.env.VITE_OPENAI_API_KEY
    
    if (!apiKey) {
      console.error('âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ')
      return res.status(500).json({ 
        success: false,
        error: 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤' 
      })
    }

    console.log('ğŸ“Š OpenAI Chat Completions API í˜¸ì¶œ ì‹œì‘:', { 
      model, 
      messagesCount: messages?.length || 0,
      temperature,
      max_tokens,
      response_format
    })

    // OpenAI API í˜¸ì¶œ (GPT-5 nano ì§ì ‘ ì‚¬ìš©)
    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: model,
        messages: messages,
        max_completion_tokens: max_tokens || 300,
        response_format: response_format
      })
    })

    if (!openaiResponse.ok) {
      const errorText = await openaiResponse.text()
      console.error('âŒ OpenAI API ì˜¤ë¥˜:', {
        status: openaiResponse.status,
        statusText: openaiResponse.statusText,
        error: errorText
      })
      return res.status(openaiResponse.status).json({ 
        success: false,
        error: `OpenAI API Error: ${openaiResponse.status}`,
        details: errorText
      })
    }

    const data = await openaiResponse.json()
    
    console.log('âœ… OpenAI Chat Completions API ì„±ê³µ:', {
      model: data.model,
      choicesCount: data.choices?.length || 0,
      usage: data.usage
    })

    // ì‘ë‹µ ë°˜í™˜
    res.status(200).json(data)

  } catch (error) {
    console.error('âŒ Chat Completions API í”„ë¡ì‹œ ì˜¤ë¥˜:', error)
    res.status(500).json({ 
      success: false,
      error: error.message
    })
  }
}