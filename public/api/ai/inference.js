// AI μ¶”λ΅  API μ—”λ“ν¬μΈνΈ (Node.js μ„λ²„μ©)
import express from 'express'
import cors from 'cors'

const app = express()
const PORT = 3005 // κ³ μ • ν¬νΈ

// CORS μ„¤μ •
app.use(cors({
  origin: '*',
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization']
}))

// JSON νμ‹± λ―Έλ“¤μ›¨μ–΄
app.use(express.json())

// Health check μ—”λ“ν¬μΈνΈ
app.get('/health', (req, res) => {
  res.status(200).json({
    status: 'healthy',
    service: 'AI API',
    port: PORT,
    timestamp: new Date().toISOString()
  })
})

// OpenAI API ν”„λ΅μ‹ μ—”λ“ν¬μΈνΈ
app.post('/api/openai/v1/chat/completions', async (req, res) => {
  try {
    console.log('π¤– OpenAI API ν”„λ΅μ‹ νΈμ¶λ¨:', {
      method: req.method,
      body: req.body,
      headers: req.headers
    })

    const { model, messages, temperature, max_tokens, response_format } = req.body

    // μ…λ ¥κ°’ κ²€μ¦
    if (!model || !messages) {
      console.warn('β ν•„μ νλΌλ―Έν„° λ„λ½:', { model: !!model, messages: !!messages })
      return res.status(400).json({ 
        success: false,
        error: 'modelκ³Ό messagesκ°€ ν•„μ”ν•©λ‹λ‹¤' 
      })
    }

    // OpenAI API ν‚¤ ν™•μΈ (ν™κ²½λ³€μλ§ ν—μ©) // π”§ μμ •λ¨
    const apiKey = process.env.OPENAI_API_KEY || process.env.VITE_OPENAI_API_KEY
    
    if (!apiKey) {
      console.error('β OpenAI API ν‚¤κ°€ μ„¤μ •λμ§€ μ•μ')
      return res.status(500).json({ 
        success: false,
        error: 'OpenAI API ν‚¤κ°€ μ„¤μ •λμ§€ μ•μ•μµλ‹λ‹¤' 
      })
    }

    console.log('π“ OpenAI API νΈμ¶ μ‹μ‘:', { 
      model, 
      messagesCount: messages?.length || 0,
      temperature,
      max_tokens,
      response_format
    })

    // OpenAI API νΈμ¶
    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: model,
        messages: messages,
        max_completion_tokens: max_tokens || 4000, // ν† ν° μ μ¦κ°€
        response_format: response_format
      })
    })

    if (!openaiResponse.ok) {
      const errorText = await openaiResponse.text()
      console.error('β OpenAI API μ¤λ¥:', {
        status: openaiResponse.status,
        statusText: openaiResponse.statusText,
        error: errorText
      })
      return res.status(openaiResponse.status).json({ 
        success: false,
        error: `OpenAI API Error: ${openaiResponse.status}`,
        details: errorText
      })
    }

    const data = await openaiResponse.json()
    
    console.log('β… OpenAI API μ„±κ³µ:', {
      model: data.model,
      choicesCount: data.choices?.length || 0,
      usage: data.usage
    })

    // μ‘λ‹µ λ°ν™
    res.status(200).json(data)

  } catch (error) {
    console.error('β OpenAI API ν”„λ΅μ‹ μ¤λ¥:', error)
    res.status(500).json({ 
      success: false,
      error: error.message
    })
  }
})

// OpenAI Embeddings API ν”„λ΅μ‹ μ—”λ“ν¬μΈνΈ
app.post('/api/openai/v1/embeddings', async (req, res) => {
  try {
    console.log('π”— OpenAI Embeddings API ν”„λ΅μ‹ νΈμ¶λ¨:', {
      method: req.method,
      body: req.body,
      headers: req.headers
    })

    const { model, input } = req.body

    // μ…λ ¥κ°’ κ²€μ¦
    if (!model || !input) {
      console.warn('β ν•„μ νλΌλ―Έν„° λ„λ½:', { model: !!model, input: !!input })
      return res.status(400).json({ 
        success: false,
        error: 'modelκ³Ό inputμ΄ ν•„μ”ν•©λ‹λ‹¤' 
      })
    }

    // OpenAI API ν‚¤ ν™•μΈ (ν™κ²½λ³€μλ§ ν—μ©) // π”§ μμ •λ¨
    const apiKey = process.env.OPENAI_API_KEY || process.env.VITE_OPENAI_API_KEY
    
    if (!apiKey) {
      console.error('β OpenAI API ν‚¤κ°€ μ„¤μ •λμ§€ μ•μ')
      return res.status(500).json({ 
        success: false,
        error: 'OpenAI API ν‚¤κ°€ μ„¤μ •λμ§€ μ•μ•μµλ‹λ‹¤' 
      })
    }

    console.log('π“ OpenAI Embeddings API νΈμ¶ μ‹μ‘:', { 
      model, 
      inputType: Array.isArray(input) ? 'array' : typeof input,
      inputLength: Array.isArray(input) ? input.length : 1
    })

    // OpenAI API νΈμ¶
    const openaiResponse = await fetch('https://api.openai.com/v1/embeddings', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: model,
        input: input
      })
    })

    if (!openaiResponse.ok) {
      const errorText = await openaiResponse.text()
      console.error('β OpenAI Embeddings API μ¤λ¥:', {
        status: openaiResponse.status,
        statusText: openaiResponse.statusText,
        error: errorText
      })
      return res.status(openaiResponse.status).json({ 
        success: false,
        error: `OpenAI API Error: ${openaiResponse.status}`,
        details: errorText
      })
    }

    const data = await openaiResponse.json()
    
    console.log('β… OpenAI Embeddings API μ„±κ³µ:', {
      model: data.model,
      dataCount: data.data?.length || 0,
      usage: data.usage
    })

    // μ‘λ‹µ λ°ν™
    res.status(200).json(data)

  } catch (error) {
    console.error('β OpenAI Embeddings API ν”„λ΅μ‹ μ¤λ¥:', error)
    res.status(500).json({ 
      success: false,
      error: error.message
    })
  }
})

// AI μ¶”λ΅  μ—”λ“ν¬μΈνΈ
app.post('/api/ai/inference', async (req, res) => {
  try {
    console.log('π¤– AI μ¶”λ΅  API νΈμ¶λ¨:', {
      method: req.method,
      body: req.body,
      headers: req.headers
    })

    const { image_url, part_id } = req.body

    // μ…λ ¥κ°’ κ²€μ¦
    if (!image_url || !part_id) {
      console.warn('β ν•„μ νλΌλ―Έν„° λ„λ½:', { image_url: !!image_url, part_id: !!part_id })
      return res.status(400).json({ 
        success: false,
        error: 'image_urlκ³Ό part_idκ°€ ν•„μ”ν•©λ‹λ‹¤' 
      })
    }

    console.log('π“ AI μ¶”λ΅  μ‹μ‘:', { image_url, part_id })

    // μ‹¤μ  AI μ¶”λ΅  λ΅μ§ (ν„μ¬λ” μ‹λ®¬λ μ΄μ…)
    const startTime = Date.now()
    
    // κ°„λ‹¨ν• μ§€μ—° μ‹λ®¬λ μ΄μ… (μ‹¤μ  AI μ¶”λ΅  μ‹κ°„)
    await new Promise(resolve => setTimeout(resolve, 100))
    
    const processingTime = Date.now() - startTime

    // AI μ¶”λ΅  κ²°κ³Ό μ‹λ®¬λ μ΄μ…
    const inferenceResult = {
      accuracy: Math.random() * 0.2 + 0.8, // 0.8 ~ 1.0 μ‚¬μ΄μ μ •ν™•λ„
      detected_parts: Math.floor(Math.random() * 3) + 1, // 1 ~ 3κ° λ¶€ν’
      predictions: [
        {
          type: 'detection',
          class: 'lego_part',
          confidence: Math.random() * 0.2 + 0.8,
          bbox: [100, 100, 200, 200],
          part_id: part_id
        }
      ],
      processing_time: processingTime,
      model_version: '1.0.0',
      inference_method: 'simulation'
    }

    console.log('β… AI μ¶”λ΅  μ™„λ£:', {
      accuracy: inferenceResult.accuracy,
      detected_parts: inferenceResult.detected_parts,
      processing_time: inferenceResult.processing_time
    })

    return res.status(200).json({
      success: true,
      accuracy: inferenceResult.accuracy,
      detected_parts: inferenceResult.detected_parts,
      predictions: inferenceResult.predictions,
      processing_time: inferenceResult.processing_time,
      model_version: inferenceResult.model_version,
      inference_method: inferenceResult.inference_method
    })

  } catch (error) {
    console.error('β AI μ¶”λ΅  μ‹¤ν¨:', error)
    return res.status(500).json({ 
      success: false, 
      error: error.message,
      timestamp: new Date().toISOString()
    })
  }
})

// μ‹¤μ  μ‚¬μ© μ¤‘μΈ λ¨λΈ μ •λ³΄λ¥Ό μ €μ¥ν•  λ³€μ
let currentModel = null
let modelLoaded = false

// λ¨λΈ μ •λ³΄ μ—…λ°μ΄νΈ ν•¨μ
async function updateModelInfo() {
  try {
    // OpenAI API ν‚¤ ν™•μΈ (ν™κ²½λ³€μλ§ ν—μ©) // π”§ μμ •λ¨
    const apiKey = process.env.OPENAI_API_KEY || process.env.VITE_OPENAI_API_KEY
    
    if (!apiKey) {
      console.warn('β οΈ OpenAI API ν‚¤κ°€ μ„¤μ •λμ§€ μ•μ')
      return
    }

    // μ‹¤μ  API νΈμ¶λ΅ λ¨λΈ μ •λ³΄ ν™•μΈ
    const testResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [{ role: 'user', content: 'Hello' }],
        max_tokens: 1
      })
    })

    if (testResponse.ok) {
      const data = await testResponse.json()
      currentModel = data.model || 'gpt-4o-mini'
      modelLoaded = true
      console.log(`β… λ¨λΈ μ •λ³΄ μ—…λ°μ΄νΈ: ${currentModel}`)
    } else {
      console.warn('β οΈ λ¨λΈ μ •λ³΄ ν™•μΈ μ‹¤ν¨')
      currentModel = 'gpt-4o-mini'
      modelLoaded = false
    }
  } catch (error) {
    console.warn('β οΈ λ¨λΈ μ •λ³΄ μ—…λ°μ΄νΈ μ¤λ¥:', error.message)
    currentModel = 'gpt-4o-mini'
    modelLoaded = false
  }
}

// μ„λ²„ μ‹μ‘ μ‹ λ¨λΈ μ •λ³΄ μ—…λ°μ΄νΈ
updateModelInfo()

// ν—¬μ¤ μ²΄ν¬ μ—”λ“ν¬μΈνΈ
app.get('/api/ai/health', (req, res) => {
  res.json({ 
    status: 'healthy', 
    timestamp: new Date().toISOString(),
    model_loaded: modelLoaded,
    method: currentModel || 'gpt-4o-mini'
  })
})

// 404 ν•Έλ“¤λ¬
app.use('*', (req, res) => {
  res.status(404).json({ 
    success: false, 
    error: 'API μ—”λ“ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤' 
  })
})

// μ—λ¬ ν•Έλ“¤λ¬
app.use((error, req, res, next) => {
  console.error('β μ„λ²„ μ—λ¬:', error)
  res.status(500).json({ 
    success: false, 
    error: error.message 
  })
})

// PORTλ” μ΄λ―Έ 6λ²μ§Έ μ¤„μ—μ„ μ„ μ–Έλ¨

app.listen(PORT, () => {
  console.log(`π€ AI μ¶”λ΅  API μ„λ²„κ°€ ν¬νΈ ${PORT}μ—μ„ μ‹¤ν–‰ μ¤‘μ…λ‹λ‹¤`)
  console.log(`π“΅ API μ—”λ“ν¬μΈνΈ: http://localhost:${PORT}/api/ai/inference`)
  console.log(`π¥ ν—¬μ¤ μ²΄ν¬: http://localhost:${PORT}/api/ai/health`)
})

export default app