# FGC-Encoder ëª¨ë¸ íŒŒì¼ êµ¬ì¡°

## ğŸ“ ëª¨ë¸ íŒŒì¼ ìœ„ì¹˜

```
public/models/
â”œâ”€â”€ fgc_encoder.onnx          # ONNX ëª¨ë¸ (ìš°ì„ ìˆœìœ„ 1)
â”œâ”€â”€ fgc_encoder.trt           # TensorRT ì—”ì§„ (ìš°ì„ ìˆœìœ„ 2)
â”œâ”€â”€ fgc_encoder_cpu.json      # CPU ëª¨ë¸ (fallback)
â””â”€â”€ README.md                 # ì´ íŒŒì¼
```

## ğŸš€ ëª¨ë¸ ë¡œë“œ ìš°ì„ ìˆœìœ„

1. **ONNX Runtime** (ê¶Œì¥)
   - íŒŒì¼: `fgc_encoder.onnx`
   - ì„±ëŠ¥: ìµœê³  (GPU ê°€ì†)
   - í˜¸í™˜ì„±: ë¸Œë¼ìš°ì €/Node.js

2. **TensorRT** (ê³ ì„±ëŠ¥)
   - íŒŒì¼: `fgc_encoder.trt`
   - ì„±ëŠ¥: ë§¤ìš° ë†’ìŒ (GPU ìµœì í™”)
   - í˜¸í™˜ì„±: NVIDIA GPU í•„ìš”

3. **CPU Fallback** (í˜¸í™˜ì„±)
   - íŒŒì¼: `fgc_encoder_cpu.json`
   - ì„±ëŠ¥: ë‚®ìŒ (CPUë§Œ)
   - í˜¸í™˜ì„±: ëª¨ë“  í™˜ê²½

## ğŸ“Š ëª¨ë¸ ì‚¬ì–‘

### ì…ë ¥
- **í˜•ì‹**: RGB ì´ë¯¸ì§€
- **í¬ê¸°**: 224Ã—224 í”½ì…€
- **ì •ê·œí™”**: ImageNet í‘œì¤€ (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

### ì¶œë ¥
- **í˜•ì‹**: ì •ê·œí™”ëœ ì„ë² ë”© ë²¡í„°
- **ì°¨ì›**: 512ì°¨ì›
- **ë²”ìœ„**: [-1, 1] (L2 ì •ê·œí™”)

### ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
- **ì§€ì—°ì‹œê°„**: â‰¤ 130ms (p95)
- **ë©”ëª¨ë¦¬**: â‰¤ 500MB
- **ì •í™•ë„**: Top-1 +1.5%p ì´ìƒ

## ğŸ”§ ëª¨ë¸ ë³€í™˜ ê°€ì´ë“œ

### PyTorch â†’ ONNX
```python
import torch
import torch.onnx

# ëª¨ë¸ ë¡œë“œ
model = torch.load('fgc_encoder.pth')
model.eval()

# ONNX ë³€í™˜
dummy_input = torch.randn(1, 3, 224, 224)
torch.onnx.export(
    model,
    dummy_input,
    'fgc_encoder.onnx',
    export_params=True,
    opset_version=11,
    do_constant_folding=True,
    input_names=['input'],
    output_names=['output']
)
```

### ONNX â†’ TensorRT
```python
import tensorrt as trt

# TensorRT ì—”ì§„ ë¹Œë“œ
builder = trt.Builder(trt.Logger())
network = builder.create_network()
parser = trt.OnnxParser(network, trt.Logger())

# ONNX íŒŒì‹±
with open('fgc_encoder.onnx', 'rb') as model:
    parser.parse(model.read())

# ì—”ì§„ ë¹Œë“œ
engine = builder.build_cuda_engine(network)
with open('fgc_encoder.trt', 'wb') as f:
    f.write(engine.serialize())
```

### TensorFlow â†’ CPU ëª¨ë¸
```python
import tensorflow as tf

# ëª¨ë¸ ë¡œë“œ
model = tf.keras.models.load_model('fgc_encoder.h5')

# TensorFlow.js ë³€í™˜
import tensorflowjs as tfjs
tfjs.converters.save_keras_model(model, 'fgc_encoder_cpu')
```

## ğŸš€ ì‚¬ìš©ë²•

### ìë™ ëª¨ë¸ ë¡œë“œ
```javascript
import { useFGCEncoder } from './composables/useFGCEncoder'

const fgcEncoder = useFGCEncoder()
const model = await fgcEncoder.initializeFGCEncoder()

// ì´ë¯¸ì§€ ì¸ì½”ë”©
const embedding = await model.encode(imageData)
```

### ìˆ˜ë™ ëª¨ë¸ ì„ íƒ
```javascript
// ONNX ëª¨ë¸ë§Œ ì‚¬ìš©
const model = await fgcEncoder.initializeFGCEncoder({
  preferredModel: 'onnx'
})

// TensorRT ëª¨ë¸ë§Œ ì‚¬ìš©
const model = await fgcEncoder.initializeFGCEncoder({
  preferredModel: 'tensorrt'
})
```

## ğŸ” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ëª¨ë¸ ì„±ëŠ¥ í™•ì¸
```javascript
const stats = fgcEncoder.getStats()
console.log('ëª¨ë¸ ì„±ëŠ¥:', {
  modelType: stats.modelType,
  avgLatency: stats.avgLatency,
  totalEncodings: stats.totalEncodings
})
```

### ì„±ëŠ¥ ìµœì í™”
```javascript
// A/B ìº˜ë¦¬ë¸Œë ˆì´ì…˜
await fgcEncoder.performABCalibration(testData)

// ì„±ëŠ¥ ê²€ì¦
const validation = await fgcEncoder.validatePerformance(model)
console.log('ì„±ëŠ¥ ê²€ì¦:', validation)
```

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### ONNX ë¡œë“œ ì‹¤íŒ¨
- WebGL ì§€ì› í™•ì¸
- ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸
- ë¸Œë¼ìš°ì € í˜¸í™˜ì„± í™•ì¸

### TensorRT ë¡œë“œ ì‹¤íŒ¨
- NVIDIA GPU í™•ì¸
- CUDA ë²„ì „ í™•ì¸
- TensorRT ì„¤ì¹˜ í™•ì¸

### CPU ëª¨ë¸ ì„±ëŠ¥ ì €í•˜
- ë°°ì¹˜ í¬ê¸° ì¡°ì •
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- CPU ì½”ì–´ ìˆ˜ í™•ì¸

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

| ëª¨ë¸ íƒ€ì… | ì§€ì—°ì‹œê°„ (ms) | ë©”ëª¨ë¦¬ (MB) | ì •í™•ë„ (%) |
|-----------|---------------|-------------|------------|
| ONNX      | 45-65        | 200-300     | 98.5       |
| TensorRT  | 25-40        | 150-250     | 98.7       |
| CPU       | 200-400      | 100-150     | 97.8       |

## ğŸ”„ ëª¨ë¸ ì—…ë°ì´íŠ¸

1. ìƒˆ ëª¨ë¸ íŒŒì¼ì„ `public/models/`ì— ë°°ì¹˜
2. ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ ë°±ì—…
3. ì‹œìŠ¤í…œ ì¬ì‹œì‘
4. ì„±ëŠ¥ ê²€ì¦ ì‹¤í–‰