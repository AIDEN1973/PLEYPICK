import { ref, reactive } from 'vue'
import { supabase } from './useSupabase'
import { analyzePartWithLLM, generateTextEmbeddingsBatch, saveToMasterPartsDB } from './useMasterPartsPreprocessing'
import { useAutoImageMigration } from './useAutoImageMigration'
import { useRateLimitMonitor } from './useRateLimitMonitor'

/**
 * ë°±ê·¸ë¼ìš´ë“œ LLM ë¶„ì„ ì‹œìŠ¤í…œ
 * - OpenAI API ë¦¬ë°‹ ì¤€ìˆ˜ (RPM: 500-1000, TPM: 40,000-80,000)
 * - ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„
 * - ì‘ì—… í ê´€ë¦¬
 */

// OpenAI API ë¦¬ë°‹ ì„¤ì • (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
const API_LIMITS = {
  requestsPerMinute: 100, // 100 RPMìœ¼ë¡œ ëŒ€í­ ê°ì†Œ
  tokensPerMinute: 50000, // 50K TPMìœ¼ë¡œ ëŒ€í­ ê°ì†Œ
  maxConcurrent: 1, // ë™ì‹œ ìš”ì²­ 1ê°œë¡œ ì œí•œ (ì•ˆì •ì„± ìš°ì„ )
  requestDelay: 2000, // ìš”ì²­ ê°„ 2ì´ˆë¡œ ì¦ê°€
  retryDelay: 5000, // ì¬ì‹œë„ ì‹œ 5ì´ˆë¡œ ì¦ê°€
  maxRetries: 2, // ì¬ì‹œë„ íšŸìˆ˜ ê°ì†Œ
  rateLimitRetryDelay: 60000, // Rate limit ì‹œ 60ì´ˆ ëŒ€ê¸°
  maxRateLimitRetries: 3 // Rate limit ì¬ì‹œë„ íšŸìˆ˜ ê°ì†Œ
}

// ì‘ì—… í ìƒíƒœ
const taskQueue = reactive({
  pending: [],
  running: [],
  completed: [],
  failed: []
})

// í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…
const currentTasks = ref(new Map())
const isProcessing = ref(false)

// Rate limit ë°©ì§€ë¥¼ ìœ„í•œ ìš”ì²­ ê°„ê²© ê´€ë¦¬
let lastRequestTime = 0
const minRequestInterval = 500 // ìµœì†Œ 0.5ì´ˆ ê°„ê²©ìœ¼ë¡œ ë‹¨ì¶•

export function useBackgroundLLMAnalysis() {
  
  // Rate limit ëª¨ë‹ˆí„° ì´ˆê¸°í™”
  const rateLimitMonitor = useRateLimitMonitor()
  
  /**
   * Rate limit ë°©ì§€ë¥¼ ìœ„í•œ ìš”ì²­ ê°„ê²© ê°•ì œ
   */
  const enforceRequestInterval = async () => {
    const now = Date.now()
    const timeSinceLastRequest = now - lastRequestTime
    
    if (timeSinceLastRequest < minRequestInterval) {
      const waitTime = minRequestInterval - timeSinceLastRequest
      // ëŒ€ê¸° ì‹œê°„ì´ ì§§ìœ¼ë©´ ë¡œê·¸ ì œê±°
      if (waitTime > 100) {
        console.log(`â³ Rate limit ë°©ì§€: ${waitTime}ms ëŒ€ê¸° ì¤‘...`)
      }
      await new Promise(resolve => setTimeout(resolve, waitTime))
    }
    
    lastRequestTime = Date.now()
  }
  
  /**
   * ë°±ê·¸ë¼ìš´ë“œ LLM ë¶„ì„ ì‘ì—… ì‹œì‘
   */
  const startBackgroundAnalysis = async (setData, parts) => {
    console.log(`ğŸš€ Starting background LLM analysis for set ${setData.set_num}`)
    console.log(`ğŸ” DEBUG: Set data:`, setData)
    console.log(`ğŸ” DEBUG: Parts count:`, parts.length)
    console.log(`ğŸ” DEBUG: First few parts:`, parts.slice(0, 3))
    
    // ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì´ˆê¸°í™”)
    if (!window.imageMigrationInstance) {
      window.imageMigrationInstance = useAutoImageMigration()
    }
    const imageMigration = window.imageMigrationInstance
    
    const taskId = `llm-analysis-${setData.set_num}-${Date.now()}`
    
    const task = {
      id: taskId,
      setNum: setData.set_num,
      setName: setData.name,
      parts: parts,
      status: 'pending',
      progress: 0,
      startTime: null,
      endTime: null,
      totalParts: parts.length,
      processedParts: 0,
      failedParts: 0,
      errors: [],
      imageMigration: imageMigration // ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ ì¶”ê°€
    }
    
    console.log(`ğŸ“‹ Created task:`, task)
    
    // ì‘ì—… íì— ì¶”ê°€
    taskQueue.pending.push(task)
    console.log(`ğŸ“‹ Task added to queue. Queue length:`, taskQueue.pending.length)
    
    // ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì‹œì‘ (ë¹„ë™ê¸°)
    processTaskQueue()
    
    return taskId
  }
  
  /**
   * ì‘ì—… í ì²˜ë¦¬
   */
  const processTaskQueue = async () => {
    if (isProcessing.value) return
    if (taskQueue.pending.length === 0) return
    
    isProcessing.value = true
    
    try {
      while (taskQueue.pending.length > 0 && currentTasks.value.size < API_LIMITS.maxConcurrent) {
        const task = taskQueue.pending.shift()
        taskQueue.running.push(task)
        currentTasks.value.set(task.id, task)
        
        // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
        executeLLMAnalysis(task).catch(error => {
          console.error(`Task ${task.id} failed:`, error)
          task.status = 'failed'
          task.errors.push(error.message)
          moveTaskToCompleted(task)
        })
      }
    } finally {
      isProcessing.value = false
    }
  }
  
  /**
   * LLM ë¶„ì„ ì‹¤í–‰ (ë°°ì¹˜ ì²˜ë¦¬)
   */
  const executeLLMAnalysis = async (task) => {
    const analysisStartTime = Date.now()
    
    try {
      task.status = 'running'
      task.startTime = Date.now()
      
      console.log(`ğŸ¤– [LLM ë¶„ì„ ì‹œì‘] ${task.setNum} (${task.totalParts}ê°œ ë¶€í’ˆ)`)
      console.log(`â° [ì‹œì‘ ì‹œê°„] ${new Date().toLocaleTimeString()}`)
      
      // âœ… 1ë‹¨ê³„: LLM ë¶„ì„ (ë°°ì¹˜ í¬ê¸° ì—„ê²© ì œí•œ)
      const analysisResults = []
      const BATCH_SIZE = 2 // í•œ ë²ˆì— 2ê°œì”© ì²˜ë¦¬ (ë¬´í•œë£¨í”„ ì™„ì „ ë°©ì§€)
      
      // ë°°ì¹˜ ìƒì„±
      const batches = []
      for (let i = 0; i < task.parts.length; i += BATCH_SIZE) {
        batches.push(task.parts.slice(i, i + BATCH_SIZE))
      }
      
      console.log(`ğŸ“¦ Created ${batches.length} batches of ${BATCH_SIZE} parts each`)
      
      for (let batchIndex = 0; batchIndex < batches.length; batchIndex++) {
        const batch = batches[batchIndex]
        console.log(`ğŸ”„ Processing batch ${batchIndex + 1}/${batches.length} (${batch.length} parts)...`)
        
        // ë°°ì¹˜ ë‚´ ë¶€í’ˆì„ ìˆœì°¨ ì²˜ë¦¬ (ë¬´í•œë£¨í”„ ì™„ì „ ë°©ì§€)
        const CONCURRENT_LIMIT = 1
        const batchResults = []
        
        for (let i = 0; i < batch.length; i += CONCURRENT_LIMIT) {
          const concurrentBatch = batch.slice(i, i + CONCURRENT_LIMIT)
          
          // ë™ì‹œ ì²˜ë¦¬ ì „ì— ìš”ì²­ ê°„ê²© ì œì–´
          await enforceRequestInterval()
          
          const concurrentResults = await Promise.allSettled(
            concurrentBatch.map(async (part) => {
            try {
              // ê¸°ì¡´ ë¶„ì„ í™•ì¸ (ê°œë°œ ëª¨ë“œì—ì„œëŠ” ê°•ì œ ì¬ì‹¤í–‰)
              const existing = await checkExistingAnalysis(part.part.part_num, part.color.id)
              if (existing && !import.meta.env.DEV) {
                console.log(`â­ï¸ Skipping existing analysis for ${part.part.part_num}`)
                return { ...existing, part: part.part, color: part.color, skipped: true }
              } else if (existing && import.meta.env.DEV) {
                console.log(`ğŸ”„ DEV MODE: Re-analyzing existing part ${part.part.part_num}`)
              }
              
              // ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸° (ë²„í‚· ì´ë¯¸ì§€ ìš°ì„  ì‚¬ìš©, element_id ìš°ì„ )
              let imageUrl = null
              let imageSource = 'unknown'
              const elementId = part.element_id || null
              
              // 1. part_imagesì—ì„œ uploaded_url ì¡°íšŒ (element_id ìš°ì„ , ìµœì‹  ë²„í‚· ì´ë¯¸ì§€)
              if (elementId) {
                const { data: partImageByElement } = await supabase
                  .from('part_images')
                  .select('uploaded_url')
                  .eq('element_id', String(elementId))
                  .not('uploaded_url', 'is', null)
                  .maybeSingle()
                
                if (partImageByElement?.uploaded_url) {
                  imageUrl = partImageByElement.uploaded_url
                  imageSource = 'part_images_element_id'
                  console.log(`âœ… Supabase Storage ë²„í‚· ì´ë¯¸ì§€ ì‚¬ìš© (element_id): ${imageUrl}`)
                }
              }
              
              // element_idë¡œ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ element_idê°€ ì—†ìœ¼ë©´ part_id + color_idë¡œ ì¡°íšŒ
              if (!imageUrl) {
                const { data: partImage } = await supabase
                  .from('part_images')
                  .select('uploaded_url')
                  .eq('part_id', part.part.part_num)
                  .eq('color_id', part.color.id)
                  .maybeSingle()
                
                if (partImage?.uploaded_url) {
                  imageUrl = partImage.uploaded_url
                  imageSource = 'part_images'
                  console.log(`âœ… Supabase Storage ë²„í‚· ì´ë¯¸ì§€ ì‚¬ìš©: ${imageUrl}`)
                }
              }
              
              if (!imageUrl) {
                // 2. image_metadataì—ì„œ supabase_url ì¡°íšŒ (element_id ìš°ì„ , ê³¼ê±° í˜¸í™˜)
                if (elementId) {
                  const { data: imageMetaByElement } = await supabase
                    .from('image_metadata')
                    .select('supabase_url')
                    .eq('element_id', String(elementId))
                    .not('supabase_url', 'is', null)
                    .maybeSingle()
                  
                  if (imageMetaByElement?.supabase_url) {
                    imageUrl = imageMetaByElement.supabase_url
                    imageSource = 'image_metadata_element_id'
                    console.log(`âœ… image_metadata ë²„í‚· ì´ë¯¸ì§€ ì‚¬ìš© (element_id): ${imageUrl}`)
                  }
                }
                
                // element_idë¡œ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ element_idê°€ ì—†ìœ¼ë©´ part_num + color_idë¡œ ì¡°íšŒ
                if (!imageUrl) {
                  const { data: imageMeta } = await supabase
                    .from('image_metadata')
                    .select('supabase_url')
                    .eq('part_num', part.part.part_num)
                    .eq('color_id', part.color.id)
                    .maybeSingle()
                  
                  if (imageMeta?.supabase_url) {
                    imageUrl = imageMeta.supabase_url
                    imageSource = 'image_metadata'
                    console.log(`âœ… image_metadata ë²„í‚· ì´ë¯¸ì§€ ì‚¬ìš©: ${imageUrl}`)
                  }
                }
                
                if (!imageUrl) {
                  // 3. ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 3ì´ˆ)
                  const supabaseUrl = import.meta.env.VITE_SUPABASE_URL || 'https://npferbxuxocbfnfbpcnz.supabase.co'
                  const bucketName = 'lego_parts_images'
                  const fileName = elementId ? `${String(elementId)}.webp` : `${part.part.part_num}_${part.color.id}.webp`
                  const storageUrl = `${supabaseUrl}/storage/v1/object/public/${bucketName}/images/${fileName}`
                  
                  console.log(`â³ ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ ëŒ€ê¸° ì¤‘... (${part.part.part_num})`)
                  
                  // ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 5ì´ˆ, 500ms ê°„ê²©)
                  let imageExists = false
                  for (let attempt = 0; attempt < 10; attempt++) {
                    try {
                      const response = await fetch(storageUrl, { 
                        method: 'HEAD', // HEAD ìš”ì²­ìœ¼ë¡œ ë” ë¹ ë¥¸ í™•ì¸
                        signal: AbortSignal.timeout(1000) // 1ì´ˆ íƒ€ì„ì•„ì›ƒ
                      })
                      
                      if (response.ok) {
                        const contentType = response.headers.get('content-type')
                        const contentLength = response.headers.get('content-length')
                        const isImage = contentType && contentType.includes('image/')
                        const hasContent = contentLength && parseInt(contentLength) > 0
                        
                        if (isImage && hasContent) {
                          imageUrl = storageUrl
                          imageSource = 'storage_verified'
                          imageExists = true
                          console.log(`âœ… Supabase Storage ë²„í‚· ì´ë¯¸ì§€ ì‚¬ìš©(ëŒ€ê¸° í›„): ${imageUrl}`)
                          break
                        }
                      }
                      
                      console.log(`â³ ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ê¸° ì¤‘... (${attempt + 1}/10)`)
                      await new Promise(resolve => setTimeout(resolve, 500)) // 500ms ëŒ€ê¸°
                    } catch (fetchError) {
                      console.log(`â³ ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ê¸° ì¤‘... (${attempt + 1}/10) - ${fetchError.message}`)
                      await new Promise(resolve => setTimeout(resolve, 500)) // 500ms ëŒ€ê¸°
                    }
                  }
                  
                  if (!imageExists) {
                    // 4. ìƒì„±ëœ Storage URL ì‚¬ìš© (ê°€ì •)
                    imageUrl = storageUrl
                    imageSource = 'generated_url'
                    console.log(`âš ï¸ ìƒì„±ëœ Storage URL (ê°€ì •): ${imageUrl}`)
                  }
                }
              }
              
              // ì´ë¯¸ì§€ URLì´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
              if (!imageUrl) {
                console.warn(`âš ï¸ ${part.part.part_num} ì´ë¯¸ì§€ URL ì—†ìŒ, ê±´ë„ˆë›°ê¸°`)
                throw new Error('ì´ë¯¸ì§€ URL ì—†ìŒ')
              }
              
              // part ê°ì²´ì— ì´ë¯¸ì§€ URL ì¶”ê°€ (WebP ìš°ì„  ì‚¬ìš©)
              const partWithImage = {
                ...part,
                supabase_image_url: imageUrl,
                image_url: imageUrl,
                llm_image_url: imageUrl, // LLM ë¶„ì„ìš© WebP ì´ë¯¸ì§€
                image_source: imageSource // ì´ë¯¸ì§€ ì†ŒìŠ¤ ì¶”ì 
              }
              
              // LLM ë¶„ì„ ì‹¤í–‰ (ì¬ì‹œë„ í¬í•¨)
              console.log(`ğŸ§  Analyzing ${part.part.part_num} (ì´ë¯¸ì§€ ì†ŒìŠ¤: ${imageSource})`)
              const analysis = await analyzePartWithRetry(partWithImage)
              
              if (!analysis) {
                throw new Error(`Analysis returned null for ${part.part.part_num}`)
              }
              
              return { ...analysis, part: part.part, color: part.color }
            } catch (error) {
              throw {
                partNum: part.part.part_num,
                error: error.message
              }
            }
            })
          )
          
          batchResults.push(...concurrentResults)
        }
        
        // ë°°ì¹˜ ê²°ê³¼ ì²˜ë¦¬
        batchResults.forEach((promiseResult) => {
          if (promiseResult.status === 'fulfilled') {
            analysisResults.push(promiseResult.value)
            if (!promiseResult.value.skipped) {
              task.processedParts++
            }
          } else {
            task.failedParts++
            task.errors.push(`Error analyzing ${promiseResult.reason.partNum}: ${promiseResult.reason.error}`)
          }
        })
        
        // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        task.progress = Math.round((task.processedParts / task.totalParts) * 50)
        
        // ë°°ì¹˜ ê°„ ëŒ€ê¸° (API ë¦¬ë°‹ ì¤€ìˆ˜) - ë°°ì¹˜ë‹¹ 3ì´ˆë¡œ ì¦ê°€
        if (batchIndex < batches.length - 1) {
          console.log(`â³ ë°°ì¹˜ ê°„ ëŒ€ê¸° ì¤‘... (${API_LIMITS.requestDelay}ms)`)
          await new Promise(resolve => setTimeout(resolve, API_LIMITS.requestDelay))
        }
      }
      
      console.log(`âœ… LLM analysis completed: ${analysisResults.length} parts analyzed`)

      // ğŸ¤– ë°±ê·¸ë¼ìš´ë“œ LLM ë¶„ì„: ë©”íƒ€ë°ì´í„° ì €ì¥ í›„ ìë™ ì„ë² ë”© ìƒì„±
      console.log(`ğŸ’¾ Saving analysis results to database (embedding queued as pending)...`)
      await saveToMasterPartsDB(analysisResults)
      console.log(`âœ… Master data saved to database (worker will generate embeddings)`)

      // ğŸ¤– ë°±ê·¸ë¼ìš´ë“œ LLM ë¶„ì„: ìë™ ì„ë² ë”© íì— ì¶”ê°€
      try {
        console.log('ğŸ“¥ Queueing CLIP embeddings for saved parts (pending)...')
        const uniquePairs = new Set()
        for (const r of analysisResults) {
          const partNum = r.part_num || r.part?.part_num
          const colorId = (r.color_id !== undefined && r.color_id !== null)
            ? r.color_id
            : (r.color?.id !== undefined ? r.color.id : 0)
          if (!partNum) continue
          uniquePairs.add(`${partNum}__${colorId}`)
        }

        const updates = []
        for (const key of uniquePairs) {
          const [partNum, colorIdStr] = key.split('__')
          const colorId = Number(colorIdStr)
          updates.push(
            supabase
              .from('parts_master_features')
              .update({ embedding_status: 'pending', updated_at: new Date().toISOString() })
              .eq('part_id', partNum)
              .eq('color_id', colorId)
              .is('clip_text_emb', null)
          )
        }
        const results = await Promise.allSettled(updates)
        const ok = results.filter(r => r.status === 'fulfilled').length
        console.log(`âœ… Embedding queued: ${ok}/${updates.length}`)
      } catch (queueErr) {
        console.warn('âš ï¸ Failed to queue embeddings:', queueErr?.message)
      }

      console.log(`âœ… Master data saved; worker will generate embeddings automatically`) // ğŸ”§ ìˆ˜ì •ë¨
      
      task.progress = 100
      task.status = 'completed'
      task.endTime = Date.now()
      
      const totalTime = Date.now() - analysisStartTime
      console.log(`ğŸ‰ [LLM ë¶„ì„ ì™„ë£Œ] ${task.setNum} - ì´ ì†Œìš”ì‹œê°„: ${Math.round(totalTime / 1000)}ì´ˆ`)
      console.log(`â° [ì™„ë£Œ ì‹œê°„] ${new Date().toLocaleTimeString()}`)
      
    } catch (error) {
      console.error(`âŒ Background LLM analysis failed for ${task.setNum}:`, error)
      task.status = 'failed'
      task.errors.push(error.message)
    } finally {
      moveTaskToCompleted(task)
    }
  }
  
  /**
   * ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ LLM ë¶„ì„ (ê°•í™”ëœ Rate Limit ì²˜ë¦¬)
   */
  const analyzePartWithRetry = async (part, retryCount = 0, rateLimitRetryCount = 0) => {
    try {
      // Rate limit ë°©ì§€ë¥¼ ìœ„í•œ ìš”ì²­ ê°„ê²© ê°•ì œ
      await enforceRequestInterval()
      
      const result = await analyzePartWithLLM(part)
      
      // ì„±ê³µì ì¸ ìš”ì²­ í†µê³„ ì—…ë°ì´íŠ¸ (ëŒ€ëµì ì¸ í† í° ìˆ˜ ì¶”ì •)
      rateLimitMonitor.updateRequestStats(1000) // í‰ê·  1000 í† í°ìœ¼ë¡œ ì¶”ì •
      
      // ê²°ê³¼ê°€ nullì¸ ê²½ìš° (JSON íŒŒì‹± ì‹¤íŒ¨ ë“±) ì¬ì‹œë„
      if (result === null && retryCount < API_LIMITS.maxRetries) {
        console.warn(`âš ï¸ LLM ë¶„ì„ ê²°ê³¼ê°€ null, ì¬ì‹œë„ ì¤‘... (ì‹œë„ ${retryCount + 1})`)
        const delay = API_LIMITS.retryDelay * Math.pow(2, retryCount)
        await new Promise(resolve => setTimeout(resolve, delay))
        return await analyzePartWithRetry(part, retryCount + 1, rateLimitRetryCount)
      }
      
      return result
    } catch (error) {
      // Rate limit ì˜¤ë¥˜ ì²˜ë¦¬ (ë³„ë„ ì¹´ìš´í„° ì‚¬ìš©)
      if (error.message.includes('429') || error.message.includes('rate limit') || error.message.includes('Rate limit')) {
        if (rateLimitRetryCount < API_LIMITS.maxRateLimitRetries) {
          // Rate limit ëª¨ë‹ˆí„°ì— ì˜¤ë¥˜ ì „ë‹¬
          const waitTime = rateLimitMonitor.handleRateLimitError(error)
          
          console.warn(`â³ Rate limit exceeded. Waiting ${waitTime}ms (${(waitTime/1000).toFixed(1)}s) - ì‹œë„ ${rateLimitRetryCount + 1}/${API_LIMITS.maxRateLimitRetries}`)
          await new Promise(resolve => setTimeout(resolve, waitTime))
          return await analyzePartWithRetry(part, retryCount, rateLimitRetryCount + 1)
        } else {
          console.error(`âŒ Rate limit ì¬ì‹œë„ í•œê³„ ë„ë‹¬ (${API_LIMITS.maxRateLimitRetries}íšŒ)`)
          throw new Error(`Rate limit ì¬ì‹œë„ í•œê³„ ë„ë‹¬: ${error.message}`)
        }
      }
      
      // ì¼ë°˜ ì˜¤ë¥˜ ì¬ì‹œë„
      if (retryCount < API_LIMITS.maxRetries) {
        const delay = API_LIMITS.retryDelay * Math.pow(2, retryCount)
        console.warn(`âš ï¸ API ì˜¤ë¥˜, ì¬ì‹œë„ ì¤‘... (${delay}ms í›„ ì‹œë„ ${retryCount + 1})`)
        await new Promise(resolve => setTimeout(resolve, delay))
        return await analyzePartWithRetry(part, retryCount + 1, rateLimitRetryCount)
      }
      
      throw error
    }
  }
  
  /**
   * ê¸°ì¡´ ë¶„ì„ í™•ì¸
   */
  const checkExistingAnalysis = async (partNum, colorId) => {
    try {
      const { data, error } = await supabase
        .from('parts_master_features')
        .select('part_id,color_id,feature_json,feature_text,confidence,recognition_hints,similar_parts,distinguishing_features,has_stud,groove,center_stud')
        .eq('part_id', partNum)
        .eq('color_id', colorId)
        .maybeSingle()
      
      return error ? null : data
    } catch {
      return null
    }
  }
  
  /**
   * ì‘ì—…ì„ ì™„ë£Œ ëª©ë¡ìœ¼ë¡œ ì´ë™
   */
  const moveTaskToCompleted = (task) => {
    const runningIndex = taskQueue.running.findIndex(t => t.id === task.id)
    if (runningIndex !== -1) {
      taskQueue.running.splice(runningIndex, 1)
    }
    
    if (task.status === 'completed') {
      taskQueue.completed.push(task)
    } else {
      taskQueue.failed.push(task)
    }
    
    currentTasks.value.delete(task.id)
    
    // ë‹¤ìŒ ì‘ì—… ì²˜ë¦¬
    processTaskQueue()
  }
  
  /**
   * ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ì¡°íšŒ
   */
  const getRunningTasks = () => {
    return Array.from(currentTasks.value.values())
  }
  
  /**
   * ì‘ì—… ìƒíƒœ ì¡°íšŒ
   */
  const getTaskStatus = (taskId) => {
    return currentTasks.value.get(taskId) || 
           taskQueue.completed.find(t => t.id === taskId) ||
           taskQueue.failed.find(t => t.id === taskId)
  }
  
  /**
   * ì‘ì—… í ìƒíƒœ ì¡°íšŒ
   */
  const getQueueStatus = () => {
    return {
      pending: taskQueue.pending.length,
      running: taskQueue.running.length,
      completed: taskQueue.completed.length,
      failed: taskQueue.failed.length,
      total: taskQueue.pending.length + taskQueue.running.length + taskQueue.completed.length + taskQueue.failed.length
    }
  }
  
  /**
   * ì‘ì—… í ì´ˆê¸°í™”
   */
  const clearQueue = () => {
    taskQueue.pending = []
    taskQueue.running = []
    taskQueue.completed = []
    taskQueue.failed = []
    currentTasks.value.clear()
  }
  
  return {
    startBackgroundAnalysis,
    getRunningTasks,
    getTaskStatus,
    getQueueStatus,
    clearQueue,
    isProcessing,
    // Rate limit ì •ë³´ ì œê³µ
    getRateLimitInfo: () => ({
      limits: API_LIMITS,
      lastRequestTime,
      minRequestInterval
    }),
    // Rate limit ëª¨ë‹ˆí„° ë…¸ì¶œ
    rateLimitMonitor
  }
}
