import { ref, reactive } from 'vue'
import { supabase } from './useSupabase'
import { analyzePartWithLLM, generateTextEmbeddingsBatch, saveToMasterPartsDB } from './useMasterPartsPreprocessing'

/**
 * ë°±ê·¸ë¼ìš´ë“œ LLM ë¶„ì„ ì‹œìŠ¤í…œ
 * - OpenAI API ë¦¬ë°‹ ì¤€ìˆ˜ (RPM: 500-1000, TPM: 40,000-80,000)
 * - ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„
 * - ì‘ì—… í ê´€ë¦¬
 */

// OpenAI API ë¦¬ë°‹ ì„¤ì •
const API_LIMITS = {
  requestsPerMinute: 500, // ë³´ìˆ˜ì ìœ¼ë¡œ 500 RPM ì„¤ì •
  tokensPerMinute: 40000, // ë³´ìˆ˜ì ìœ¼ë¡œ 40K TPM ì„¤ì •
  maxConcurrent: 3, // ë™ì‹œ ìš”ì²­ ìµœëŒ€ 3ê°œ
  requestDelay: 2000, // ìš”ì²­ ê°„ 2ì´ˆ ëŒ€ê¸°
  retryDelay: 5000, // ì¬ì‹œë„ ì‹œ 5ì´ˆ ëŒ€ê¸°
  maxRetries: 3
}

// ì‘ì—… í ìƒíƒœ
const taskQueue = reactive({
  pending: [],
  running: [],
  completed: [],
  failed: []
})

// í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…
const currentTasks = ref(new Map())
const isProcessing = ref(false)

export function useBackgroundLLMAnalysis() {
  
  /**
   * ë°±ê·¸ë¼ìš´ë“œ LLM ë¶„ì„ ì‘ì—… ì‹œì‘
   */
  const startBackgroundAnalysis = async (setData, parts) => {
    console.log(`ğŸš€ Starting background LLM analysis for set ${setData.set_num}`)
    console.log(`ğŸ” DEBUG: Set data:`, setData)
    console.log(`ğŸ” DEBUG: Parts count:`, parts.length)
    console.log(`ğŸ” DEBUG: First few parts:`, parts.slice(0, 3))
    
    const taskId = `llm-analysis-${setData.set_num}-${Date.now()}`
    
    const task = {
      id: taskId,
      setNum: setData.set_num,
      setName: setData.name,
      parts: parts,
      status: 'pending',
      progress: 0,
      startTime: null,
      endTime: null,
      totalParts: parts.length,
      processedParts: 0,
      failedParts: 0,
      errors: []
    }
    
    console.log(`ğŸ“‹ Created task:`, task)
    
    // ì‘ì—… íì— ì¶”ê°€
    taskQueue.pending.push(task)
    console.log(`ğŸ“‹ Task added to queue. Queue length:`, taskQueue.pending.length)
    
    // ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì‹œì‘ (ë¹„ë™ê¸°)
    processTaskQueue()
    
    return taskId
  }
  
  /**
   * ì‘ì—… í ì²˜ë¦¬
   */
  const processTaskQueue = async () => {
    if (isProcessing.value) return
    if (taskQueue.pending.length === 0) return
    
    isProcessing.value = true
    
    try {
      while (taskQueue.pending.length > 0 && currentTasks.value.size < API_LIMITS.maxConcurrent) {
        const task = taskQueue.pending.shift()
        taskQueue.running.push(task)
        currentTasks.value.set(task.id, task)
        
        // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
        executeLLMAnalysis(task).catch(error => {
          console.error(`Task ${task.id} failed:`, error)
          task.status = 'failed'
          task.errors.push(error.message)
          moveTaskToCompleted(task)
        })
      }
    } finally {
      isProcessing.value = false
    }
  }
  
  /**
   * LLM ë¶„ì„ ì‹¤í–‰
   */
  const executeLLMAnalysis = async (task) => {
    try {
      task.status = 'running'
      task.startTime = Date.now()
      
      console.log(`ğŸ¤– Starting background LLM analysis for ${task.setNum} (${task.totalParts} parts)`)
      
      // 1ë‹¨ê³„: LLM ë¶„ì„ (ë¦¬ë°‹ ì¤€ìˆ˜)
      const analysisResults = []
      const batchSize = 1 // í•œ ë²ˆì— 1ê°œì”© ì²˜ë¦¬
      
      for (let i = 0; i < task.parts.length; i++) {
        const part = task.parts[i]
        
        try {
          // ê¸°ì¡´ ë¶„ì„ í™•ì¸ (ê°œë°œ ëª¨ë“œì—ì„œëŠ” ê°•ì œ ì¬ì‹¤í–‰)
          const existing = await checkExistingAnalysis(part.part.part_num, part.color.id)
          if (existing && !import.meta.env.DEV) {
            console.log(`â­ï¸ Skipping existing analysis for ${part.part.part_num}`)
            analysisResults.push({ ...existing, part: part.part, color: part.color })
            task.processedParts++
            task.progress = Math.round((task.processedParts / task.totalParts) * 50)
            continue
          } else if (existing && import.meta.env.DEV) {
            console.log(`ğŸ”„ DEV MODE: Re-analyzing existing part ${part.part.part_num}`)
          }
          
          // LLM ë¶„ì„ ì‹¤í–‰ (ë¦¬ë°‹ ì¤€ìˆ˜)
          console.log(`ğŸ§  Analyzing part ${i + 1}/${task.totalParts}: ${part.part.part_num}`)
          const analysis = await analyzePartWithRetry(part)
          
          if (analysis) {
            analysisResults.push({ ...analysis, part: part.part, color: part.color })
            task.processedParts++
          } else {
            task.failedParts++
            task.errors.push(`Failed to analyze ${part.part.part_num}`)
          }
          
          // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
          task.progress = Math.round((task.processedParts / task.totalParts) * 50)
          
          // API ë¦¬ë°‹ ì¤€ìˆ˜: ìš”ì²­ ê°„ ëŒ€ê¸°
          if (i < task.parts.length - 1) {
            await new Promise(resolve => setTimeout(resolve, API_LIMITS.requestDelay))
          }
          
        } catch (error) {
          console.error(`âŒ Analysis failed for ${part.part.part_num}:`, error)
          task.failedParts++
          task.errors.push(`Error analyzing ${part.part.part_num}: ${error.message}`)
        }
      }
      
      console.log(`âœ… LLM analysis completed: ${analysisResults.length} parts analyzed`)
      
      // 2ë‹¨ê³„: ì„ë² ë”© ìƒì„±
      console.log(`ğŸ”¢ Generating embeddings...`)
      const needsEmbedding = analysisResults.filter(result => !result.embedding)
      
      if (needsEmbedding.length > 0) {
        const embeddingResults = await generateTextEmbeddingsBatch(needsEmbedding)
        console.log(`âœ… Embeddings generated: ${embeddingResults.length} parts`)
        
        // ì„ë² ë”© ê²°ê³¼ ë§¤í•‘
        let embeddingIndex = 0
        const combinedResults = analysisResults.map(analysis => {
          if (!analysis.embedding && embeddingIndex < embeddingResults.length) {
            return {
              ...analysis,
              embedding: embeddingResults[embeddingIndex++]
            }
          }
          return analysis
        })
        
        // 3ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        console.log(`ğŸ’¾ Saving to database...`)
        await saveToMasterPartsDB(combinedResults)
        console.log(`âœ… Master data saved to database`)
      }
      
      task.progress = 100
      task.status = 'completed'
      task.endTime = Date.now()
      
      console.log(`ğŸ‰ Background LLM analysis completed for ${task.setNum}!`)
      
    } catch (error) {
      console.error(`âŒ Background LLM analysis failed for ${task.setNum}:`, error)
      task.status = 'failed'
      task.errors.push(error.message)
    } finally {
      moveTaskToCompleted(task)
    }
  }
  
  /**
   * ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ LLM ë¶„ì„
   */
  const analyzePartWithRetry = async (part, retryCount = 0) => {
    try {
      return await analyzePartWithLLM(part)
    } catch (error) {
      if (error.message.includes('429') || error.message.includes('rate limit')) {
        if (retryCount < API_LIMITS.maxRetries) {
          const delay = API_LIMITS.retryDelay * Math.pow(2, retryCount) // ì§€ìˆ˜ ë°±ì˜¤í”„
          console.warn(`â³ Rate limit hit, retrying in ${delay}ms (attempt ${retryCount + 1})`)
          await new Promise(resolve => setTimeout(resolve, delay))
          return await analyzePartWithRetry(part, retryCount + 1)
        }
      }
      throw error
    }
  }
  
  /**
   * ê¸°ì¡´ ë¶„ì„ í™•ì¸
   */
  const checkExistingAnalysis = async (partNum, colorId) => {
    try {
      const { data, error } = await supabase
        .from('parts_master_features')
        .select('part_id,color_id,feature_json,feature_text,confidence,recognition_hints,similar_parts,distinguishing_features,has_stud,groove,center_stud')
        .eq('part_id', partNum)
        .eq('color_id', colorId)
        .maybeSingle()
      
      return error ? null : data
    } catch {
      return null
    }
  }
  
  /**
   * ì‘ì—…ì„ ì™„ë£Œ ëª©ë¡ìœ¼ë¡œ ì´ë™
   */
  const moveTaskToCompleted = (task) => {
    const runningIndex = taskQueue.running.findIndex(t => t.id === task.id)
    if (runningIndex !== -1) {
      taskQueue.running.splice(runningIndex, 1)
    }
    
    if (task.status === 'completed') {
      taskQueue.completed.push(task)
    } else {
      taskQueue.failed.push(task)
    }
    
    currentTasks.value.delete(task.id)
    
    // ë‹¤ìŒ ì‘ì—… ì²˜ë¦¬
    processTaskQueue()
  }
  
  /**
   * ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ì¡°íšŒ
   */
  const getRunningTasks = () => {
    return Array.from(currentTasks.value.values())
  }
  
  /**
   * ì‘ì—… ìƒíƒœ ì¡°íšŒ
   */
  const getTaskStatus = (taskId) => {
    return currentTasks.value.get(taskId) || 
           taskQueue.completed.find(t => t.id === taskId) ||
           taskQueue.failed.find(t => t.id === taskId)
  }
  
  /**
   * ì‘ì—… í ìƒíƒœ ì¡°íšŒ
   */
  const getQueueStatus = () => {
    return {
      pending: taskQueue.pending.length,
      running: taskQueue.running.length,
      completed: taskQueue.completed.length,
      failed: taskQueue.failed.length,
      total: taskQueue.pending.length + taskQueue.running.length + taskQueue.completed.length + taskQueue.failed.length
    }
  }
  
  /**
   * ì‘ì—… í ì´ˆê¸°í™”
   */
  const clearQueue = () => {
    taskQueue.pending = []
    taskQueue.running = []
    taskQueue.completed = []
    taskQueue.failed = []
    currentTasks.value.clear()
  }
  
  return {
    startBackgroundAnalysis,
    getRunningTasks,
    getTaskStatus,
    getQueueStatus,
    clearQueue,
    isProcessing
  }
}
