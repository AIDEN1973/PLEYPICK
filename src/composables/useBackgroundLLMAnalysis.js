import { ref, reactive } from 'vue'
import { supabase } from './useSupabase'
import { analyzePartWithLLM, generateTextEmbeddingsBatch, saveToMasterPartsDB } from './useMasterPartsPreprocessing'
import { useAutoImageMigration } from './useAutoImageMigration'

/**
 * ë°±ê·¸ë¼ìš´ë“œ LLM ë¶„ì„ ì‹œìŠ¤í…œ
 * - OpenAI API ë¦¬ë°‹ ì¤€ìˆ˜ (RPM: 500-1000, TPM: 40,000-80,000)
 * - ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„
 * - ì‘ì—… í ê´€ë¦¬
 */

// OpenAI API ë¦¬ë°‹ ì„¤ì •
const API_LIMITS = {
  requestsPerMinute: 500, // ë³´ìˆ˜ì ìœ¼ë¡œ 500 RPM ì„¤ì •
  tokensPerMinute: 200000, // ì‹¤ì œ ì œí•œ: 200K TPM
  maxConcurrent: 2, // ë™ì‹œ ìš”ì²­ ìµœëŒ€ 2ê°œë¡œ ì¤„ì„ (rate limit ë°©ì§€)
  requestDelay: 500, // ìš”ì²­ ê°„ 500ms ëŒ€ê¸° (ì•ˆì •ì ì¸ ì²˜ë¦¬)
  retryDelay: 1000, // ì¬ì‹œë„ ì‹œ 1ì´ˆ ëŒ€ê¸° (ì§€ìˆ˜ ë°±ì˜¤í”„ë¡œ ì¦ê°€)
  maxRetries: 3
}

// ì‘ì—… í ìƒíƒœ
const taskQueue = reactive({
  pending: [],
  running: [],
  completed: [],
  failed: []
})

// í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…
const currentTasks = ref(new Map())
const isProcessing = ref(false)

export function useBackgroundLLMAnalysis() {
  
  /**
   * ë°±ê·¸ë¼ìš´ë“œ LLM ë¶„ì„ ì‘ì—… ì‹œì‘
   */
  const startBackgroundAnalysis = async (setData, parts) => {
    console.log(`ğŸš€ Starting background LLM analysis for set ${setData.set_num}`)
    console.log(`ğŸ” DEBUG: Set data:`, setData)
    console.log(`ğŸ” DEBUG: Parts count:`, parts.length)
    console.log(`ğŸ” DEBUG: First few parts:`, parts.slice(0, 3))
    
    // ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì´ˆê¸°í™”)
    if (!window.imageMigrationInstance) {
      window.imageMigrationInstance = useAutoImageMigration()
    }
    const imageMigration = window.imageMigrationInstance
    
    const taskId = `llm-analysis-${setData.set_num}-${Date.now()}`
    
    const task = {
      id: taskId,
      setNum: setData.set_num,
      setName: setData.name,
      parts: parts,
      status: 'pending',
      progress: 0,
      startTime: null,
      endTime: null,
      totalParts: parts.length,
      processedParts: 0,
      failedParts: 0,
      errors: [],
      imageMigration: imageMigration // ì´ë¯¸ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ ì¶”ê°€
    }
    
    console.log(`ğŸ“‹ Created task:`, task)
    
    // ì‘ì—… íì— ì¶”ê°€
    taskQueue.pending.push(task)
    console.log(`ğŸ“‹ Task added to queue. Queue length:`, taskQueue.pending.length)
    
    // ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì‹œì‘ (ë¹„ë™ê¸°)
    processTaskQueue()
    
    return taskId
  }
  
  /**
   * ì‘ì—… í ì²˜ë¦¬
   */
  const processTaskQueue = async () => {
    if (isProcessing.value) return
    if (taskQueue.pending.length === 0) return
    
    isProcessing.value = true
    
    try {
      while (taskQueue.pending.length > 0 && currentTasks.value.size < API_LIMITS.maxConcurrent) {
        const task = taskQueue.pending.shift()
        taskQueue.running.push(task)
        currentTasks.value.set(task.id, task)
        
        // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
        executeLLMAnalysis(task).catch(error => {
          console.error(`Task ${task.id} failed:`, error)
          task.status = 'failed'
          task.errors.push(error.message)
          moveTaskToCompleted(task)
        })
      }
    } finally {
      isProcessing.value = false
    }
  }
  
  /**
   * LLM ë¶„ì„ ì‹¤í–‰ (ë°°ì¹˜ ì²˜ë¦¬)
   */
  const executeLLMAnalysis = async (task) => {
    try {
      task.status = 'running'
      task.startTime = Date.now()
      
      console.log(`ğŸ¤– Starting background LLM analysis for ${task.setNum} (${task.totalParts} parts)`)
      
      // âœ… 1ë‹¨ê³„: LLM ë¶„ì„ (ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬)
      const analysisResults = []
      const BATCH_SIZE = 10 // í•œ ë²ˆì— 10ê°œì”© ì²˜ë¦¬
      
      // ë°°ì¹˜ ìƒì„±
      const batches = []
      for (let i = 0; i < task.parts.length; i += BATCH_SIZE) {
        batches.push(task.parts.slice(i, i + BATCH_SIZE))
      }
      
      console.log(`ğŸ“¦ Created ${batches.length} batches of ${BATCH_SIZE} parts each`)
      
      for (let batchIndex = 0; batchIndex < batches.length; batchIndex++) {
        const batch = batches[batchIndex]
        console.log(`ğŸ”„ Processing batch ${batchIndex + 1}/${batches.length} (${batch.length} parts)...`)
        
        // ë°°ì¹˜ ë‚´ ë¶€í’ˆì„ ë³‘ë ¬ë¡œ ë¶„ì„
        const batchResults = await Promise.allSettled(
          batch.map(async (part) => {
            try {
              // ê¸°ì¡´ ë¶„ì„ í™•ì¸ (ê°œë°œ ëª¨ë“œì—ì„œëŠ” ê°•ì œ ì¬ì‹¤í–‰)
              const existing = await checkExistingAnalysis(part.part.part_num, part.color.id)
              if (existing && !import.meta.env.DEV) {
                console.log(`â­ï¸ Skipping existing analysis for ${part.part.part_num}`)
                return { ...existing, part: part.part, color: part.color, skipped: true }
              } else if (existing && import.meta.env.DEV) {
                console.log(`ğŸ”„ DEV MODE: Re-analyzing existing part ${part.part.part_num}`)
              }
              
              // LLM ë¶„ì„ ì‹¤í–‰ (ì¬ì‹œë„ í¬í•¨)
              console.log(`ğŸ§  Analyzing ${part.part.part_num}`)
              const analysis = await analyzePartWithRetry(part)
              
              if (!analysis) {
                throw new Error(`Analysis returned null for ${part.part.part_num}`)
              }
              
              return { ...analysis, part: part.part, color: part.color }
            } catch (error) {
              throw {
                partNum: part.part.part_num,
                error: error.message
              }
            }
          })
        )
        
        // ë°°ì¹˜ ê²°ê³¼ ì²˜ë¦¬
        batchResults.forEach((promiseResult) => {
          if (promiseResult.status === 'fulfilled') {
            analysisResults.push(promiseResult.value)
            if (!promiseResult.value.skipped) {
              task.processedParts++
            }
          } else {
            task.failedParts++
            task.errors.push(`Error analyzing ${promiseResult.reason.partNum}: ${promiseResult.reason.error}`)
          }
        })
        
        // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        task.progress = Math.round((task.processedParts / task.totalParts) * 50)
        
        // ë°°ì¹˜ ê°„ ëŒ€ê¸° (API ë¦¬ë°‹ ì¤€ìˆ˜) - ë°°ì¹˜ë‹¹ 500msë¡œ ì¶©ë¶„
        if (batchIndex < batches.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 500))
        }
      }
      
      console.log(`âœ… LLM analysis completed: ${analysisResults.length} parts analyzed`)
      
      // 2ë‹¨ê³„: ì„ë² ë”© ìƒì„±
      console.log(`ğŸ”¢ Generating embeddings...`)
      const needsEmbedding = analysisResults.filter(result => !result.embedding)
      
      if (needsEmbedding.length > 0) {
        const embeddingResults = await generateTextEmbeddingsBatch(needsEmbedding)
        console.log(`âœ… Embeddings generated: ${embeddingResults.length} parts`)
        
        // ì„ë² ë”© ê²°ê³¼ ë§¤í•‘
        let embeddingIndex = 0
        const combinedResults = analysisResults.map(analysis => {
          if (!analysis.embedding && embeddingIndex < embeddingResults.length) {
            return {
              ...analysis,
              embedding: embeddingResults[embeddingIndex++]
            }
          }
          return analysis
        })
        
        // 3ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        console.log(`ğŸ’¾ Saving to database...`)
        await saveToMasterPartsDB(combinedResults)
        console.log(`âœ… Master data saved to database`)
      }
      
      task.progress = 100
      task.status = 'completed'
      task.endTime = Date.now()
      
      console.log(`ğŸ‰ Background LLM analysis completed for ${task.setNum}!`)
      
    } catch (error) {
      console.error(`âŒ Background LLM analysis failed for ${task.setNum}:`, error)
      task.status = 'failed'
      task.errors.push(error.message)
    } finally {
      moveTaskToCompleted(task)
    }
  }
  
  /**
   * ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ LLM ë¶„ì„
   */
  const analyzePartWithRetry = async (part, retryCount = 0) => {
    try {
      const result = await analyzePartWithLLM(part)
      
      // ê²°ê³¼ê°€ nullì¸ ê²½ìš° (JSON íŒŒì‹± ì‹¤íŒ¨ ë“±) ì¬ì‹œë„
      if (result === null && retryCount < API_LIMITS.maxRetries) {
        console.warn(`âš ï¸ LLM ë¶„ì„ ê²°ê³¼ê°€ null, ì¬ì‹œë„ ì¤‘... (ì‹œë„ ${retryCount + 1})`)
        const delay = API_LIMITS.retryDelay * Math.pow(2, retryCount)
        await new Promise(resolve => setTimeout(resolve, delay))
        return await analyzePartWithRetry(part, retryCount + 1)
      }
      
      return result
    } catch (error) {
      if (error.message.includes('429') || error.message.includes('rate limit')) {
        if (retryCount < API_LIMITS.maxRetries) {
          const delay = API_LIMITS.retryDelay * Math.pow(2, retryCount) // ì§€ìˆ˜ ë°±ì˜¤í”„
          console.warn(`â³ Rate limit hit, retrying in ${delay}ms (attempt ${retryCount + 1})`)
          await new Promise(resolve => setTimeout(resolve, delay))
          return await analyzePartWithRetry(part, retryCount + 1)
        }
      }
      throw error
    }
  }
  
  /**
   * ê¸°ì¡´ ë¶„ì„ í™•ì¸
   */
  const checkExistingAnalysis = async (partNum, colorId) => {
    try {
      const { data, error } = await supabase
        .from('parts_master_features')
        .select('part_id,color_id,feature_json,feature_text,confidence,recognition_hints,similar_parts,distinguishing_features,has_stud,groove,center_stud')
        .eq('part_id', partNum)
        .eq('color_id', colorId)
        .maybeSingle()
      
      return error ? null : data
    } catch {
      return null
    }
  }
  
  /**
   * ì‘ì—…ì„ ì™„ë£Œ ëª©ë¡ìœ¼ë¡œ ì´ë™
   */
  const moveTaskToCompleted = (task) => {
    const runningIndex = taskQueue.running.findIndex(t => t.id === task.id)
    if (runningIndex !== -1) {
      taskQueue.running.splice(runningIndex, 1)
    }
    
    if (task.status === 'completed') {
      taskQueue.completed.push(task)
    } else {
      taskQueue.failed.push(task)
    }
    
    currentTasks.value.delete(task.id)
    
    // ë‹¤ìŒ ì‘ì—… ì²˜ë¦¬
    processTaskQueue()
  }
  
  /**
   * ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ì¡°íšŒ
   */
  const getRunningTasks = () => {
    return Array.from(currentTasks.value.values())
  }
  
  /**
   * ì‘ì—… ìƒíƒœ ì¡°íšŒ
   */
  const getTaskStatus = (taskId) => {
    return currentTasks.value.get(taskId) || 
           taskQueue.completed.find(t => t.id === taskId) ||
           taskQueue.failed.find(t => t.id === taskId)
  }
  
  /**
   * ì‘ì—… í ìƒíƒœ ì¡°íšŒ
   */
  const getQueueStatus = () => {
    return {
      pending: taskQueue.pending.length,
      running: taskQueue.running.length,
      completed: taskQueue.completed.length,
      failed: taskQueue.failed.length,
      total: taskQueue.pending.length + taskQueue.running.length + taskQueue.completed.length + taskQueue.failed.length
    }
  }
  
  /**
   * ì‘ì—… í ì´ˆê¸°í™”
   */
  const clearQueue = () => {
    taskQueue.pending = []
    taskQueue.running = []
    taskQueue.completed = []
    taskQueue.failed = []
    currentTasks.value.clear()
  }
  
  return {
    startBackgroundAnalysis,
    getRunningTasks,
    getTaskStatus,
    getQueueStatus,
    clearQueue,
    isProcessing
  }
}
