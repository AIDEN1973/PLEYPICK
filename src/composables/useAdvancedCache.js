/**
 * ğŸš€ ê³ ê¸‰ ìºì‹± ì‹œìŠ¤í…œ
 * 
 * Redis ê¸°ë°˜ ë¶„ì‚° ìºì‹± + ë©”ëª¨ë¦¬ ìºì‹± í•˜ì´ë¸Œë¦¬ë“œ
 * - LRU ìºì‹œ (ë©”ëª¨ë¦¬)
 * - Redis ìºì‹œ (ë¶„ì‚°)
 * - ìë™ ë§Œë£Œ ë° ê°±ì‹ 
 * - ìºì‹œ ë¬´íš¨í™” ì „ëµ
 */

import { ref, computed } from 'vue'
import { useSupabase } from './useSupabase'

// ì „ì—­ ìºì‹œ ìƒíƒœ
const memoryCache = new Map()
const cacheStats = ref({
  hits: 0,
  misses: 0,
  evictions: 0,
  size: 0
})

// ìºì‹œ ì„¤ì •
const CACHE_CONFIG = {
  // ë©”ëª¨ë¦¬ ìºì‹œ ì„¤ì •
  MEMORY_MAX_SIZE: 1000,
  MEMORY_TTL: 5 * 60 * 1000, // 5ë¶„
  
  // Redis ìºì‹œ ì„¤ì •
  REDIS_TTL: 60 * 60 * 1000, // 1ì‹œê°„
  REDIS_PREFIX: 'brickbox:',
  
  // ìºì‹œ ì „ëµ
  STRATEGY: 'hybrid', // 'memory', 'redis', 'hybrid'
  
  // ìë™ ê°±ì‹ 
  AUTO_REFRESH: true,
  REFRESH_THRESHOLD: 0.8 // 80% TTL ê²½ê³¼ ì‹œ ê°±ì‹ 
}

export function useAdvancedCache() {
  const { supabase } = useSupabase()
  const loading = ref(false)
  const error = ref(null)

  /**
   * ìºì‹œ í‚¤ ìƒì„±
   */
  const generateCacheKey = (prefix, ...params) => {
    const key = params
      .filter(Boolean)
      .map(p => typeof p === 'object' ? JSON.stringify(p) : String(p))
      .join(':')
    return `${CACHE_CONFIG.REDIS_PREFIX}${prefix}:${key}`
  }

  /**
   * ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ ì¡°íšŒ
   */
  const getFromMemory = (key) => {
    const item = memoryCache.get(key)
    if (!item) return null
    
    // TTL í™•ì¸
    if (Date.now() > item.expires) {
      memoryCache.delete(key)
      cacheStats.value.evictions++
      return null
    }
    
    cacheStats.value.hits++
    return item.data
  }

  /**
   * ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
   */
  const setToMemory = (key, data, ttl = CACHE_CONFIG.MEMORY_TTL) => {
    // LRU ì •ì±…: ìµœëŒ€ í¬ê¸° ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ í•­ëª© ì œê±°
    if (memoryCache.size >= CACHE_CONFIG.MEMORY_MAX_SIZE) {
      const oldestKey = memoryCache.keys().next().value
      memoryCache.delete(oldestKey)
      cacheStats.value.evictions++
    }
    
    memoryCache.set(key, {
      data,
      expires: Date.now() + ttl,
      created: Date.now()
    })
    
    cacheStats.value.size = memoryCache.size
  }

  /**
   * Redis ìºì‹œì—ì„œ ì¡°íšŒ
   */
  const getFromRedis = async (key) => {
    try {
      const { data, error } = await supabase
        .from('cache_store')
        .select('value, expires_at')
        .eq('key', key)
        .gt('expires_at', new Date().toISOString())
        .maybeSingle()
      
      if (error || !data) return null
      
      cacheStats.value.hits++
      return JSON.parse(data.value)
    } catch (err) {
      console.warn('Redis ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨:', err)
      return null
    }
  }

  /**
   * Redis ìºì‹œì— ì €ì¥
   */
  const setToRedis = async (key, data, ttl = CACHE_CONFIG.REDIS_TTL) => {
    try {
      const expiresAt = new Date(Date.now() + ttl).toISOString()
      
      await supabase
        .from('cache_store')
        .upsert({
          key,
          value: JSON.stringify(data),
          expires_at: expiresAt,
          created_at: new Date().toISOString()
        })
      
      return true
    } catch (err) {
      console.warn('Redis ìºì‹œ ì €ì¥ ì‹¤íŒ¨:', err)
      return false
    }
  }

  /**
   * í•˜ì´ë¸Œë¦¬ë“œ ìºì‹œ ì¡°íšŒ
   */
  const get = async (key, fetcher, options = {}) => {
    const {
      ttl = CACHE_CONFIG.MEMORY_TTL,
      strategy = CACHE_CONFIG.STRATEGY,
      autoRefresh = CACHE_CONFIG.AUTO_REFRESH
    } = options

    // 1. ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ ì¡°íšŒ
    if (strategy === 'memory' || strategy === 'hybrid') {
      const memoryData = getFromMemory(key)
      if (memoryData) {
        // ìë™ ê°±ì‹  ì²´í¬
        if (autoRefresh && shouldRefresh(key)) {
          refreshInBackground(key, fetcher, ttl)
        }
        return memoryData
      }
    }

    // 2. Redis ìºì‹œì—ì„œ ì¡°íšŒ
    if (strategy === 'redis' || strategy === 'hybrid') {
      const redisData = await getFromRedis(key)
      if (redisData) {
        // ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
        if (strategy === 'hybrid') {
          setToMemory(key, redisData, ttl)
        }
        return redisData
      }
    }

    // 3. ìºì‹œ ë¯¸ìŠ¤ - ë°ì´í„° í˜ì²˜ ì‹¤í–‰
    cacheStats.value.misses++
    loading.value = true
    
    try {
      const data = await fetcher()
      
      // ìºì‹œì— ì €ì¥
      if (strategy === 'memory' || strategy === 'hybrid') {
        setToMemory(key, data, ttl)
      }
      
      if (strategy === 'redis' || strategy === 'hybrid') {
        await setToRedis(key, data, ttl)
      }
      
      return data
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  /**
   * ìë™ ê°±ì‹  í•„ìš” ì—¬ë¶€ í™•ì¸
   */
  const shouldRefresh = (key) => {
    const item = memoryCache.get(key)
    if (!item) return false
    
    const elapsed = Date.now() - item.created
    const threshold = item.expires - item.created
    return elapsed > (threshold * CACHE_CONFIG.REFRESH_THRESHOLD)
  }

  /**
   * ë°±ê·¸ë¼ìš´ë“œ ê°±ì‹ 
   */
  const refreshInBackground = async (key, fetcher, ttl) => {
    try {
      const data = await fetcher()
      
      // ìºì‹œ ì—…ë°ì´íŠ¸
      setToMemory(key, data, ttl)
      await setToRedis(key, data, ttl)
      
      console.log(`ğŸ”„ ìºì‹œ ë°±ê·¸ë¼ìš´ë“œ ê°±ì‹  ì™„ë£Œ: ${key}`)
    } catch (err) {
      console.warn(`âš ï¸ ìºì‹œ ë°±ê·¸ë¼ìš´ë“œ ê°±ì‹  ì‹¤íŒ¨: ${key}`, err)
    }
  }

  /**
   * ìºì‹œ ë¬´íš¨í™”
   */
  const invalidate = async (pattern) => {
    // ë©”ëª¨ë¦¬ ìºì‹œ ë¬´íš¨í™”
    if (pattern.includes('*')) {
      // ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´
      const regex = new RegExp(pattern.replace(/\*/g, '.*'))
      for (const key of memoryCache.keys()) {
        if (regex.test(key)) {
          memoryCache.delete(key)
          cacheStats.value.evictions++
        }
      }
    } else {
      // ì •í™•í•œ í‚¤
      memoryCache.delete(pattern)
    }
    
    // Redis ìºì‹œ ë¬´íš¨í™”
    try {
      await supabase
        .from('cache_store')
        .delete()
        .like('key', pattern)
    } catch (err) {
      console.warn('Redis ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨:', err)
    }
    
    cacheStats.value.size = memoryCache.size
  }

  /**
   * ìºì‹œ í†µê³„
   */
  const getStats = () => {
    const total = cacheStats.value.hits + cacheStats.value.misses
    const hitRate = total > 0 ? (cacheStats.value.hits / total * 100).toFixed(2) : 0
    
    return {
      ...cacheStats.value,
      hitRate: `${hitRate}%`,
      memoryUsage: `${memoryCache.size}/${CACHE_CONFIG.MEMORY_MAX_SIZE}`
    }
  }

  /**
   * ìºì‹œ í´ë¦¬ì–´
   */
  const clear = () => {
    memoryCache.clear()
    cacheStats.value = {
      hits: 0,
      misses: 0,
      evictions: 0,
      size: 0
    }
  }

  /**
   * ë¶€í’ˆ ë©”íƒ€ë°ì´í„° ìºì‹±
   */
  const getPartMetadata = async (partId, colorId) => {
    const key = generateCacheKey('part_metadata', partId, colorId)
    
    return await get(key, async () => {
      const { data, error } = await supabase
        .from('parts_master_features')
        .select('*')
        .eq('part_id', partId)
        .eq('color_id', colorId)
        .single()
      
      if (error) throw error
      return data
    }, {
      ttl: 30 * 60 * 1000, // 30ë¶„
      strategy: 'hybrid'
    })
  }

  /**
   * ì„¸íŠ¸ ì •ë³´ ìºì‹±
   */
  const getSetInfo = async (setNum) => {
    const key = generateCacheKey('set_info', setNum)
    
    return await get(key, async () => {
      const { data, error } = await supabase
        .from('lego_sets')
        .select('*')
        .eq('set_num', setNum)
        .single()
      
      if (error) throw error
      return data
    }, {
      ttl: 60 * 60 * 1000, // 1ì‹œê°„
      strategy: 'hybrid'
    })
  }

  /**
   * ê²€ìƒ‰ ê²°ê³¼ ìºì‹±
   */
  const getSearchResults = async (query, filters = {}) => {
    const key = generateCacheKey('search', query, filters)
    
    return await get(key, async () => {
      let queryBuilder = supabase
        .from('parts_master_features')
        .select('*')
      
      // í•„í„° ì ìš©
      if (filters.shape_tag) {
        queryBuilder = queryBuilder.eq('shape_tag', filters.shape_tag)
      }
      if (filters.series) {
        queryBuilder = queryBuilder.eq('series', filters.series)
      }
      
      const { data, error } = await queryBuilder
      
      if (error) throw error
      return data
    }, {
      ttl: 10 * 60 * 1000, // 10ë¶„
      strategy: 'hybrid'
    })
  }

  return {
    // ê¸°ë³¸ ìºì‹œ í•¨ìˆ˜
    get,
    invalidate,
    clear,
    
    // íŠ¹í™”ëœ ìºì‹œ í•¨ìˆ˜
    getPartMetadata,
    getSetInfo,
    getSearchResults,
    
    // ìƒíƒœ ë° í†µê³„
    loading,
    error,
    getStats,
    
    // ì„¤ì •
    config: CACHE_CONFIG
  }
}

// ìºì‹œ ìŠ¤í† ì–´ í…Œì´ë¸” ìƒì„± SQL
export const CACHE_STORE_SQL = `
-- ìºì‹œ ìŠ¤í† ì–´ í…Œì´ë¸” ìƒì„±
CREATE TABLE IF NOT EXISTS cache_store (
  key TEXT PRIMARY KEY,
  value TEXT NOT NULL,
  expires_at TIMESTAMPTZ NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX IF NOT EXISTS idx_cache_store_expires ON cache_store(expires_at);
CREATE INDEX IF NOT EXISTS idx_cache_store_created ON cache_store(created_at);

-- ë§Œë£Œëœ ìºì‹œ ìë™ ì •ë¦¬ í•¨ìˆ˜
CREATE OR REPLACE FUNCTION cleanup_expired_cache()
RETURNS INTEGER
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  deleted_count INTEGER;
BEGIN
  DELETE FROM cache_store WHERE expires_at < NOW();
  GET DIAGNOSTICS deleted_count = ROW_COUNT;
  RETURN deleted_count;
END;
$$;

-- RLS ì •ì±…
ALTER TABLE cache_store ENABLE ROW LEVEL SECURITY;

CREATE POLICY cache_store_policy ON cache_store
FOR ALL TO authenticated
USING (true);
`;
