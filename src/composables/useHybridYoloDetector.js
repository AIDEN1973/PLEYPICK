/**
 * ðŸš€ BrickBox 2ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ YOLO11s-seg ê²€ì¶œê¸°
 * 
 * 1ì°¨: YOLO11n-seg (ë¹ ë¥¸ ì „ì²´ ìŠ¤ìº”)
 * 2ì°¨: YOLO11s-seg (ì •ë°€ ê²€ì¦)
 * 
 * íŠ¹ì§•:
 * - ë™ì  ëª¨ë¸ ë¡œë”©
 * - ë©”ëª¨ë¦¬ ìµœì í™”
 * - ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
 * - í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼ í†µí•©
 */

import { ref, computed, onMounted, onUnmounted } from 'vue'
import { useSupabase } from './useSupabase.js'

export function useHybridYoloDetector() {
  const { supabase } = useSupabase()
  
  // ìƒíƒœ ê´€ë¦¬
  const isInitialized = ref(false)
  const isStage1Ready = ref(false)
  const isStage2Ready = ref(false)
  const isDetecting = ref(false)
  const currentSession = ref(null)
  
  // ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
  const performanceMetrics = ref({
    stage1_fps: 0,
    stage2_fps: 0,
    total_processing_time: 0,
    memory_usage: 0,
    detection_accuracy: 0
  })
  
  // ONNX ëŸ°íƒ€ìž„
  let ort = null
  let stage1Session = null
  let stage2Session = null
  let stage1ModelInfo = null
  let stage2ModelInfo = null
  
  /**
   * í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¶œê¸° ì´ˆê¸°í™”
   */
  const initializeHybridDetector = async () => {
    try {
      console.log('ðŸš€ í•˜ì´ë¸Œë¦¬ë“œ YOLO ê²€ì¶œê¸° ì´ˆê¸°í™” ì‹œìž‘...')
      
      // ONNX ëŸ°íƒ€ìž„ ë¡œë“œ
      if (!ort) {
        ort = await import('onnxruntime-web')
        console.log('âœ… ONNX Runtime ë¡œë“œ ì™„ë£Œ')
      }
      
      // í™œì„± ëª¨ë¸ ì •ë³´ ì¡°íšŒ
      const { data: activeModels, error } = await supabase
        .from('active_models')
        .select(`
          *,
          stage1_model:model_registry!stage1_model_id(*),
          stage2_model:model_registry!stage2_model_id(*)
        `)
        .eq('hybrid_mode', true)
        .single()
      
      if (error || !activeModels) {
        throw new Error('í™œì„± í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
      }
      
      stage1ModelInfo = activeModels.stage1_model
      stage2ModelInfo = activeModels.stage2_model
      
      console.log('ðŸ“Š í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì •ë³´:', {
        stage1: stage1ModelInfo?.model_name,
        stage2: stage2ModelInfo?.model_name
      })
      
      // 1ì°¨ ëª¨ë¸ ë¡œë“œ (í•­ìƒ ë¡œë“œ)
      await loadStage1Model()
      
      // 2ì°¨ ëª¨ë¸ì€ í•„ìš”ì‹œì—ë§Œ ë¡œë“œ
      console.log('âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ')
      isInitialized.value = true
      
    } catch (error) {
      console.error('âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¶œê¸° ì´ˆê¸°í™” ì‹¤íŒ¨:', error)
      throw error
    }
  }
  
  /**
   * 1ì°¨ ëª¨ë¸ ë¡œë“œ (YOLO11n-seg)
   */
  const loadStage1Model = async () => {
    try {
      console.log('ðŸ”§ 1ì°¨ ëª¨ë¸ ë¡œë“œ ì¤‘...')
      
      if (!stage1ModelInfo) {
        throw new Error('1ì°¨ ëª¨ë¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
      }
      
      // ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (Supabase Storage)
      const modelPath = stage1ModelInfo.model_path || import.meta.env.VITE_DEFAULT_MODEL_URL || 'https://your-supabase-url.supabase.co/storage/v1/object/public/models/your-model-path/default_model.onnx'
      
      // ONNX ì„¸ì…˜ ìƒì„±
      stage1Session = await ort.InferenceSession.create(modelPath, {
        executionProviders: ['webgl', 'cpu'],
        graphOptimizationLevel: 'all'
      })
      
      console.log('âœ… 1ì°¨ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ:', stage1ModelInfo.model_name)
      isStage1Ready.value = true
      
    } catch (error) {
      console.error('âŒ 1ì°¨ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error)
      throw error
    }
  }
  
  /**
   * 2ì°¨ ëª¨ë¸ ë¡œë“œ (YOLO11s-seg)
   */
  const loadStage2Model = async () => {
    try {
      if (isStage2Ready.value) return
      
      console.log('ðŸ”§ 2ì°¨ ëª¨ë¸ ë¡œë“œ ì¤‘...')
      
      if (!stage2ModelInfo) {
        throw new Error('2ì°¨ ëª¨ë¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
      }
      
      // ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (Supabase Storage)
      const modelPath = stage2ModelInfo.model_path || import.meta.env.VITE_DEFAULT_MODEL_URL || 'https://your-supabase-url.supabase.co/storage/v1/object/public/models/your-model-path/default_model.onnx'
      
      // ONNX ì„¸ì…˜ ìƒì„±
      stage2Session = await ort.InferenceSession.create(modelPath, {
        executionProviders: ['webgl', 'cpu'],
        graphOptimizationLevel: 'all'
      })
      
      console.log('âœ… 2ì°¨ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ:', stage2ModelInfo.model_name)
      isStage2Ready.value = true
      
    } catch (error) {
      console.error('âŒ 2ì°¨ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error)
      throw error
    }
  }
  
  /**
   * 2ì°¨ ëª¨ë¸ ì–¸ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½)
   */
  const unloadStage2Model = () => {
    if (stage2Session) {
      stage2Session = null
      isStage2Ready.value = false
      console.log('ðŸ—‘ï¸ 2ì°¨ ëª¨ë¸ ì–¸ë¡œë“œ ì™„ë£Œ')
    }
  }
  
  /**
   * í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¶œ ì‹¤í–‰
   */
  const detectHybrid = async (imageData, options = {}) => {
    if (!isInitialized.value || !isStage1Ready.value) {
      throw new Error('í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    }
    
    const startTime = performance.now()
    currentSession.value = crypto.randomUUID()
    
    try {
      console.log('ðŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¶œ ì‹œìž‘...')
      isDetecting.value = true
      
      // 1ì°¨ ê²€ì¶œ: ë¹ ë¥¸ ì „ì²´ ìŠ¤ìº”
      const stage1Results = await executeStage1Analysis(imageData, options)
      console.log(`1ì°¨ ê²€ì¶œ ì™„ë£Œ: ${stage1Results.length}ê°œ ê°ì²´`)
      
      // ëˆ„ë½ í›„ë³´ ì˜ì—­ ì‹ë³„
      const suspiciousRegions = identifySuspiciousRegions(stage1Results, options)
      console.log(`ì˜ì‹¬ ì˜ì—­ ì‹ë³„: ${suspiciousRegions.length}ê°œ`)
      
      let stage2Results = []
      let finalResults = stage1Results
      
      // 2ì°¨ ê²€ì¦: í›„ë³´ ì˜ì—­ì´ ìžˆì„ ë•Œë§Œ ì‹¤í–‰
      if (suspiciousRegions.length > 0) {
        console.log('ðŸ” 2ì°¨ ì •ë°€ ê²€ì¦ ì‹œìž‘...')
        
        // 2ì°¨ ëª¨ë¸ ë¡œë“œ (í•„ìš”ì‹œ)
        if (!isStage2Ready.value) {
          await loadStage2Model()
        }
        
        stage2Results = await executeStage2Analysis(imageData, suspiciousRegions, options)
        console.log(`2ì°¨ ê²€ì¦ ì™„ë£Œ: ${stage2Results.length}ê°œ ê°ì²´`)
        
        // ê²°ê³¼ í†µí•©
        finalResults = integrateResults(stage1Results, stage2Results, suspiciousRegions)
      }
      
      // ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
      const processingTime = performance.now() - startTime
      updatePerformanceMetrics(processingTime, stage1Results.length, stage2Results.length)
      
      // ê²€ì¶œ ë¡œê·¸ ì €ìž¥
      await saveDetectionLog(currentSession.value, {
        stage1_results: stage1Results,
        stage2_results: stage2Results,
        final_results: finalResults,
        processing_time_ms: Math.round(processingTime),
        memory_usage_mb: getMemoryUsage(),
        fps_achieved: calculateFPS(processingTime)
      })
      
      console.log('âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¶œ ì™„ë£Œ')
      return finalResults
      
    } catch (error) {
      console.error('âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ì¶œ ì‹¤íŒ¨:', error)
      throw error
    } finally {
      isDetecting.value = false
    }
  }
  
  /**
   * 1ì°¨ ê²€ì¶œ ì‹¤í–‰ (YOLO11n-seg)
   */
  const executeStage1Analysis = async (imageData, options) => {
    try {
      // ì´ë¯¸ì§€ ì „ì²˜ë¦¬
      const processedImage = await preprocessImage(imageData, 640)
      
      // ONNX ì¶”ë¡  ì‹¤í–‰
      const feeds = { [stage1Session.inputNames[0]]: processedImage }
      const results = await stage1Session.run(feeds)
      
      // ê²°ê³¼ í›„ì²˜ë¦¬
      const detections = postprocessDetections(
        results[stage1Session.outputNames[0]], 
        processedImage.width, 
        processedImage.height,
        options.stage1_config || stage1ModelInfo.hybrid_config
      )
      
      return detections
      
    } catch (error) {
      console.error('âŒ 1ì°¨ ê²€ì¶œ ì‹¤íŒ¨:', error)
      throw error
    }
  }
  
  /**
   * 2ì°¨ ê²€ì¦ ì‹¤í–‰ (YOLO11s-seg)
   */
  const executeStage2Analysis = async (imageData, suspiciousRegions, options) => {
    try {
      if (!isStage2Ready.value) {
        throw new Error('2ì°¨ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
      }
      
      const verifications = []
      
      // ê° ì˜ì‹¬ ì˜ì—­ì— ëŒ€í•´ ì •ë°€ ê²€ì¦
      for (const region of suspiciousRegions) {
        // ì˜ì—­ í¬ë¡­
        const croppedImage = await cropImageRegion(imageData, region)
        
        // ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        const processedImage = await preprocessImage(croppedImage, 640)
        
        // ONNX ì¶”ë¡  ì‹¤í–‰
        const feeds = { [stage2Session.inputNames[0]]: processedImage }
        const results = await stage2Session.run(feeds)
        
        // ê²°ê³¼ í›„ì²˜ë¦¬ (Segmentation ë§ˆìŠ¤í¬ í¬í•¨)
        const detections = postprocessSegmentationDetections(
          results[stage2Session.outputNames[0]],
          processedImage.width,
          processedImage.height,
          options.stage2_config || stage2ModelInfo.hybrid_config
        )
        
        // ì›ë³¸ ì¢Œí‘œë¡œ ë³€í™˜
        const transformedDetections = transformToOriginalCoordinates(detections, region)
        verifications.push(...transformedDetections)
      }
      
      return verifications
      
    } catch (error) {
      console.error('âŒ 2ì°¨ ê²€ì¦ ì‹¤íŒ¨:', error)
      throw error
    }
  }
  
  /**
   * ì˜ì‹¬ ì˜ì—­ ì‹ë³„
   */
  const identifySuspiciousRegions = (stage1Results, options) => {
    const threshold = options.suspicious_threshold || 0.3
    const minArea = options.min_suspicious_area || 0.01
    
    return stage1Results.filter(detection => 
      detection.confidence < threshold || 
      detection.area < minArea ||
      detection.classId === 0 // ëˆ„ë½ í´ëž˜ìŠ¤
    )
  }
  
  /**
   * ê²°ê³¼ í†µí•©
   */
  const integrateResults = (stage1Results, stage2Results, suspiciousRegions) => {
    // 1ì°¨ ê²°ê³¼ì—ì„œ ì˜ì‹¬ ì˜ì—­ ì œì™¸
    const cleanStage1Results = stage1Results.filter(detection => 
      !suspiciousRegions.some(region => 
        isOverlapping(detection, region)
      )
    )
    
    // 2ì°¨ ê²€ì¦ ê²°ê³¼ ì¶”ê°€
    const integratedResults = [...cleanStage1Results, ...stage2Results]
    
    // ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    return removeDuplicates(integratedResults)
      .sort((a, b) => b.confidence - a.confidence)
  }
  
  /**
   * ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
   */
  const updatePerformanceMetrics = (processingTime, stage1Count, stage2Count) => {
    performanceMetrics.value = {
      stage1_fps: stage1Count / (processingTime / 1000),
      stage2_fps: stage2Count / (processingTime / 1000),
      total_processing_time: processingTime,
      memory_usage: getMemoryUsage(),
      detection_accuracy: calculateAccuracy(stage1Count, stage2Count)
    }
  }
  
  /**
   * ê²€ì¶œ ë¡œê·¸ ì €ìž¥
   */
  const saveDetectionLog = async (sessionId, logData) => {
    try {
      await supabase
        .from('hybrid_detection_logs')
        .insert({
          session_id: sessionId,
          ...logData
        })
    } catch (error) {
      console.warn('âš ï¸ ê²€ì¶œ ë¡œê·¸ ì €ìž¥ ì‹¤íŒ¨:', error)
    }
  }
  
  /**
   * ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
   */
  const getMemoryUsage = () => {
    if (performance.memory) {
      return Math.round(performance.memory.usedJSHeapSize / 1024 / 1024)
    }
    return 0
  }
  
  /**
   * FPS ê³„ì‚°
   */
  const calculateFPS = (processingTime) => {
    return Math.round(1000 / processingTime)
  }
  
  /**
   * ì •í™•ë„ ê³„ì‚°
   */
  const calculateAccuracy = (stage1Count, stage2Count) => {
    if (stage1Count === 0) return 0
    return Math.round((stage2Count / stage1Count) * 100) / 100
  }
  
  // ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
  const preprocessImage = async (imageData, size) => {
    // ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë¡œì§
    return { width: size, height: size, data: new Float32Array(size * size * 3) }
  }
  
  const postprocessDetections = (output, width, height, config) => {
    // Detection í›„ì²˜ë¦¬ ë¡œì§
    return []
  }
  
  const postprocessSegmentationDetections = (output, width, height, config) => {
    // Segmentation í›„ì²˜ë¦¬ ë¡œì§
    return []
  }
  
  const cropImageRegion = async (imageData, region) => {
    // ì´ë¯¸ì§€ ì˜ì—­ í¬ë¡­ ë¡œì§
    return imageData
  }
  
  const transformToOriginalCoordinates = (detections, region) => {
    // ì¢Œí‘œ ë³€í™˜ ë¡œì§
    return detections
  }
  
  const isOverlapping = (detection, region) => {
    // ê²¹ì¹¨ ê²€ì‚¬ ë¡œì§
    return false
  }
  
  const removeDuplicates = (detections) => {
    // ì¤‘ë³µ ì œê±° ë¡œì§
    return detections
  }
  
  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  onUnmounted(() => {
    if (stage1Session) {
      stage1Session = null
    }
    if (stage2Session) {
      stage2Session = null
    }
  })
  
  return {
    // ìƒíƒœ
    isInitialized: computed(() => isInitialized.value),
    isStage1Ready: computed(() => isStage1Ready.value),
    isStage2Ready: computed(() => isStage2Ready.value),
    isDetecting: computed(() => isDetecting.value),
    performanceMetrics: computed(() => performanceMetrics.value),
    
    // ë©”ì„œë“œ
    initializeHybridDetector,
    detectHybrid,
    loadStage2Model,
    unloadStage2Model
  }
}
