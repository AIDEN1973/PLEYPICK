import { ref } from 'vue'
import { supabase } from './useSupabase'

export function useDatabase() {
  const loading = ref(false)
  const error = ref(null)


  // ì¤‘ë³µ ì„¸íŠ¸ ì‚­ì œ (ì¬ë“±ë¡ ì‹œ)
  const deleteSetAndParts = async (setId, setNum, deleteLLMAnalysis = false) => {
    try {
      // 1. ë¶€í’ˆ ì´ë¯¸ì§€ ì‚­ì œ
      const { data: setParts, error: partsError } = await supabase
        .from('set_parts')
        .select('part_id, color_id')
        .eq('set_id', setId)

      if (!partsError && setParts) {
        // Storage ë²„í‚·ì—ì„œ ì‹¤ì œ íŒŒì¼ë“¤ ì‚­ì œ
        console.log('ğŸ—‚ï¸ Storage ë²„í‚·ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ ì¤‘...')
        
        // ë¨¼ì € Storage ë²„í‚·ì˜ í˜„ì¬ íŒŒì¼ ëª©ë¡ í™•ì¸
        try {
          const { data: bucketFiles, error: listError } = await supabase.storage
            .from('lego_parts_images')
            .list('images', { limit: 1000 })
          
          if (listError) {
            console.warn('âš ï¸ Storage ë²„í‚· ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', listError)
          } else {
            console.log('ğŸ“ Storage ë²„í‚· í˜„ì¬ íŒŒì¼ ìˆ˜:', bucketFiles?.length || 0)
            console.log('ğŸ“ Storage ë²„í‚· íŒŒì¼ ìƒ˜í”Œ:', bucketFiles?.slice(0, 5)?.map(f => f.name))
          }
        } catch (listErr) {
          console.warn('âš ï¸ Storage ë²„í‚· ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜:', listErr)
        }
        
        const filesToDelete = []
        
        for (const part of setParts) {
          try {
            // part_images í…Œì´ë¸”ì—ì„œ íŒŒì¼ ê²½ë¡œ ì¡°íšŒ
            const { data: partImages, error: imagesError } = await supabase
              .from('part_images')
              .select('uploaded_url, local_path, filename')
              .eq('part_id', part.part_id)
              .eq('color_id', part.color_id)
            
            if (imagesError) {
              console.warn(`âš ï¸ part_images ì¡°íšŒ ì‹¤íŒ¨ (${part.part_id}, ${part.color_id}):`, imagesError.message)
              continue // ë‹¤ìŒ ë¶€í’ˆìœ¼ë¡œ ë„˜ì–´ê°
            }
            
            if (partImages && partImages.length > 0) {
              for (const image of partImages) {
                // uploaded_urlì—ì„œ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
                if (image.uploaded_url) {
                  // URLì—ì„œ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ (ì˜ˆ: https://...supabase.co/storage/v1/object/public/lego_parts_images/images/3001_72.webp)
                  const urlParts = image.uploaded_url.split('/')
                  const fileName = urlParts[urlParts.length - 1]
                  if (fileName) {
                    filesToDelete.push(`images/${fileName}`)
                  }
                }
                // local_pathê°€ ìˆë‹¤ë©´ ì‚¬ìš©
                else if (image.local_path) {
                  filesToDelete.push(image.local_path)
                }
                // filenameë§Œ ìˆë‹¤ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
                else if (image.filename) {
                  filesToDelete.push(`images/${image.filename}`)
                }
              }
            }
          } catch (partError) {
            console.warn(`âš ï¸ ë¶€í’ˆ ${part.part_id} ì´ë¯¸ì§€ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜:`, partError.message)
            continue // ë‹¤ìŒ ë¶€í’ˆìœ¼ë¡œ ë„˜ì–´ê°
          }
        }
        
        // Storageì—ì„œ íŒŒì¼ë“¤ ì‚­ì œ
        if (filesToDelete.length > 0) {
          console.log('ğŸ—‘ï¸ ì‚­ì œí•  íŒŒì¼ ëª©ë¡:', filesToDelete)
          try {
            const { data: deleteData, error: deleteError } = await supabase.storage
              .from('lego_parts_images')
              .remove(filesToDelete)
            
            if (deleteError) {
              console.error('âŒ Storage íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨:', deleteError)
              console.error('ì‚­ì œ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:', filesToDelete)
            } else {
              console.log(`âœ… Storageì—ì„œ ${filesToDelete.length}ê°œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ`)
              console.log('ì‚­ì œëœ íŒŒì¼ë“¤:', deleteData)
            }
          } catch (storageError) {
            console.error('âŒ Storage íŒŒì¼ ì‚­ì œ ì¤‘ ì˜ˆì™¸ ë°œìƒ:', storageError)
            console.error('ì‚­ì œ ì‹œë„í•œ íŒŒì¼ë“¤:', filesToDelete)
          }
        } else {
          console.log('â„¹ï¸ ì‚­ì œí•  Storage íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')
        }
        
        // part_images í…Œì´ë¸”ì—ì„œ ê´€ë ¨ ì´ë¯¸ì§€ ì‚­ì œ
        for (const part of setParts) {
          try {
            const { error: deleteError } = await supabase
              .from('part_images')
              .delete()
              .eq('part_id', part.part_id)
              .eq('color_id', part.color_id)
            
            if (deleteError) {
              console.warn(`âš ï¸ part_images ì‚­ì œ ì‹¤íŒ¨ (${part.part_id}, ${part.color_id}):`, deleteError.message)
            }
          } catch (deleteErr) {
            console.warn(`âš ï¸ ë¶€í’ˆ ${part.part_id} ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜:`, deleteErr.message)
          }
        }
        
        // LLM ë¶„ì„ ë°ì´í„° ì‚­ì œ (ì˜µì…˜)
        if (deleteLLMAnalysis) {
          console.log('ğŸ§  LLM ë¶„ì„ ë°ì´í„° ì‚­ì œ ì¤‘...')
          for (const part of setParts) {
            try {
              const { error: llmDeleteError } = await supabase
                .from('parts_master_features')
                .delete()
                .eq('part_id', part.part_id)
                .eq('color_id', part.color_id)
              
              if (llmDeleteError) {
                console.warn(`âš ï¸ LLM ë¶„ì„ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨ (${part.part_id}, ${part.color_id}):`, llmDeleteError.message)
              }
            } catch (llmErr) {
              console.warn(`âš ï¸ ë¶€í’ˆ ${part.part_id} LLM ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜:`, llmErr.message)
            }
          }
          console.log('âœ… LLM ë¶„ì„ ë°ì´í„° ì‚­ì œ ì™„ë£Œ')
        }
      }

      // 2. ì„¸íŠ¸ ì´ë¯¸ì§€ë„ Storageì—ì„œ ì‚­ì œ
      console.log('ğŸ–¼ï¸ ì„¸íŠ¸ ì´ë¯¸ì§€ ì‚­ì œ ì¤‘...')
      try {
        const { data: setData, error: setError } = await supabase
          .from('lego_sets')
          .select('set_img_url, webp_image_url')
          .eq('id', setId)
          .single()
        
        if (!setError && setData) {
          const setFilesToDelete = []
          
          // WebP ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ì‚­ì œ ëŒ€ìƒì— ì¶”ê°€
          if (setData.webp_image_url) {
            // URLì—ì„œ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
            const urlParts = setData.webp_image_url.split('/')
            const fileName = urlParts[urlParts.length - 1]
            if (fileName) {
              setFilesToDelete.push(`sets/${fileName}`)
            }
          }
          
          if (setFilesToDelete.length > 0) {
            console.log('ğŸ—‘ï¸ ì‚­ì œí•  ì„¸íŠ¸ ì´ë¯¸ì§€ ëª©ë¡:', setFilesToDelete)
            const { data: deleteSetData, error: deleteSetError } = await supabase.storage
              .from('lego_parts_images')
              .remove(setFilesToDelete)
            
            if (deleteSetError) {
              console.error('âŒ ì„¸íŠ¸ ì´ë¯¸ì§€ ì‚­ì œ ì‹¤íŒ¨:', deleteSetError)
              console.error('ì‚­ì œ ì‹¤íŒ¨í•œ ì„¸íŠ¸ ì´ë¯¸ì§€ë“¤:', setFilesToDelete)
            } else {
              console.log(`âœ… ì„¸íŠ¸ ì´ë¯¸ì§€ ${setFilesToDelete.length}ê°œ ì‚­ì œ ì™„ë£Œ`)
              console.log('ì‚­ì œëœ ì„¸íŠ¸ ì´ë¯¸ì§€ë“¤:', deleteSetData)
            }
          } else {
            console.log('â„¹ï¸ ì‚­ì œí•  ì„¸íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.')
          }
        }
      } catch (setImageError) {
        console.warn('âš ï¸ ì„¸íŠ¸ ì´ë¯¸ì§€ ì‚­ì œ ì¤‘ ì˜¤ë¥˜:', setImageError)
      }

      // 3. set_parts ì‚­ì œ
      await supabase
        .from('set_parts')
        .delete()
        .eq('set_id', setId)

      // 4. ì„¸íŠ¸ ì‚­ì œ
      await supabase
        .from('lego_sets')
        .delete()
        .eq('id', setId)

      console.log(`âœ… Deleted existing set ${setNum} and all related data`)
      return true
    } catch (err) {
      console.error('Error deleting existing set:', err)
      return false
    }
  }

  // ë ˆê³  ì„¸íŠ¸ ì €ì¥
  const saveLegoSet = async (setData) => {
    loading.value = true
    error.value = null

    try {
      const { data, error: dbError } = await supabase
        .from('lego_sets')
        .upsert({
          set_num: setData.set_num,
          name: setData.name,
          year: setData.year,
          theme_id: setData.theme_id,
          num_parts: setData.num_parts,
          set_img_url: setData.set_img_url,
          set_url: setData.set_url,
          last_modified_dt: setData.last_modified_date || setData.last_modified_dt
        }, {
          onConflict: 'set_num'
        })
        .select()

      if (dbError) throw dbError
      return data[0]
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // ë ˆê³  ë¶€í’ˆ ì €ì¥
  const saveLegoPart = async (partData) => {
    loading.value = true
    error.value = null

    try {
      const { data, error: dbError } = await supabase
        .from('lego_parts')
        .upsert({
          part_num: partData.part_num,
          name: partData.name,
          part_cat_id: partData.part_cat_id,
          part_url: partData.part_url,
          part_img_url: partData.part_img_url,
          external_ids: partData.external_ids,
          print_of: partData.print_of
        }, {
          onConflict: 'part_num'
        })
        .select()

      if (dbError) throw dbError
      return data[0]
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // ìƒ‰ìƒ ì €ì¥
  const saveLegoColor = async (colorData) => {
    loading.value = true
    error.value = null

    try {
      const { data, error: dbError } = await supabase
        .from('lego_colors')
        .upsert({
          color_id: colorData.id,
          name: colorData.name,
          rgb: colorData.rgb,
          is_trans: colorData.is_trans,
          external_ids: colorData.external_ids
        }, {
          onConflict: 'color_id'
        })
        .select()

      if (dbError) throw dbError
      return data[0]
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // ì„¸íŠ¸-ë¶€í’ˆ ê´€ê³„ ì €ì¥ (ì¤‘ë³µ ë°©ì§€)
  const saveSetPart = async (setId, partId, colorId, quantity, isSpare = false, elementId = null, numSets = 1) => {
    loading.value = true
    error.value = null

    try {
      console.log(`Inserting set-part relationship: set_id=${setId}, part_id=${partId}, color_id=${colorId}, element_id=${elementId}`)

      // 1) element_idê°€ ìˆëŠ” ê²½ìš°, ì „ì—­ì ìœ¼ë¡œ element_id ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬ (ë‹¤ë¥¸ ì„¸íŠ¸ì— ì´ë¯¸ ë“±ë¡ëœ ê²½ìš°)
      if (elementId) {
        // ë¨¼ì € í˜„ì¬ ì„¸íŠ¸ì—ì„œ ë™ì¼ element_idê°€ ìˆëŠ”ì§€ í™•ì¸
        const { data: existingInSet, error: setElementError } = await supabase
          .from('set_parts')
          .select('id, quantity, part_id, color_id')
          .eq('set_id', setId)
          .eq('element_id', elementId)
          .maybeSingle()

        if (setElementError && setElementError.code !== 'PGRST116') {
          console.warn('Warning checking existing set-part by element_id in set:', setElementError)
        }

        if (existingInSet) {
          console.log(`Duplicate set-part detected by element_id=${elementId} in same set, skipping insert`)
          return { id: existingInSet.id, set_id: setId, part_id: existingInSet.part_id, color_id: existingInSet.color_id, quantity: existingInSet.quantity }
        }

        // ë‹¤ë¥¸ ì„¸íŠ¸ì—ì„œ ë™ì¼ element_idê°€ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        const { data: existingInOtherSet, error: globalElementError } = await supabase
          .from('set_parts')
          .select('id, set_id, part_id, color_id')
          .eq('element_id', elementId)
          .neq('set_id', setId)
          .limit(1)
          .maybeSingle()

        if (globalElementError && globalElementError.code !== 'PGRST116') {
          console.warn('Warning checking existing set-part by element_id globally:', globalElementError)
        }

        if (existingInOtherSet) {
          console.log(`âš ï¸ ë™ì¼ element_id=${elementId} ë¶€í’ˆì´ ë‹¤ë¥¸ ì„¸íŠ¸(set_id=${existingInOtherSet.set_id})ì— ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì„¸íŠ¸-ë¶€í’ˆ ê´€ê³„ë§Œ ì €ì¥í•©ë‹ˆë‹¤.`)
          // ë‹¤ë¥¸ ì„¸íŠ¸ì— ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆì–´ë„ í˜„ì¬ ì„¸íŠ¸ì˜ set_partsì—ëŠ” ì €ì¥í•´ì•¼ í•¨
          // (ì„¸íŠ¸ë³„ ë¶€í’ˆ ì •ë³´ëŠ” í•„ìš”í•˜ë¯€ë¡œ)
        }
      }

      // 2) element_idê°€ ì—†ê±°ë‚˜ element_id ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µì´ ì—†ëŠ” ê²½ìš°, set_id + part_id + color_id ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
      const { data: existing, error: existError } = await supabase
        .from('set_parts')
        .select('id, quantity')
        .eq('set_id', setId)
        .eq('part_id', partId)
        .eq('color_id', colorId)
        .maybeSingle()

      if (existError) {
        console.warn('Warning checking existing set-part:', existError)
        // PGRST116: multiple or no rows when requesting object â†’ ì¤‘ë³µì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì¼€ì´ìŠ¤ë¡œ ê°„ì£¼í•˜ê³  ìŠ¤í‚µ
        if (existError.code === 'PGRST116') {
          console.log('Duplicate set-part detected by PGRST116, skipping insert')
          return { id: 'duplicate', set_id: setId, part_id: partId, color_id: colorId }
        }
      }

      if (existing) {
        console.log('Duplicate set-part detected, skipping insert')
        return { id: existing.id, set_id: setId, part_id: partId, color_id: colorId, quantity: existing.quantity }
      }

      // 2) ì‹ ê·œ ì‚½ì…
      const { data, error: insertError } = await supabase
        .from('set_parts')
        .insert({
          set_id: setId,
          part_id: partId,
          color_id: colorId,
          quantity: quantity,
          is_spare: isSpare,
          element_id: elementId,
          num_sets: numSets
        })
        .select()

      if (insertError) {
        console.error('Error inserting set-part relationship:', insertError)
        // ì¤‘ë³µ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
        if (insertError.code === '23505') {
          console.log('Duplicate entry ignored, continuing...')
          return { id: 'duplicate', set_id: setId, part_id: partId, color_id: colorId }
        }
        throw insertError
      }
      console.log('Set-part relationship inserted successfully')
      return data[0]
    } catch (err) {
      console.error('saveSetPart error:', err)
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // ë¶€í’ˆ ì´ë¯¸ì§€ ì •ë³´ ì €ì¥ (element_id ì§€ì›)
  const savePartImage = async (imageData) => {
    loading.value = true
    error.value = null

    try {
      const { data, error: dbError } = await supabase
        .from('part_images')
        .insert({
          part_id: imageData.part_id,
          color_id: imageData.color_id,
          original_url: imageData.original_url,
          uploaded_url: imageData.uploaded_url,
          local_path: imageData.local_path,
          filename: imageData.filename,
          file_size: imageData.file_size,
          image_width: imageData.image_width,
          image_height: imageData.image_height,
          download_status: imageData.download_status || 'pending',
          upload_status: imageData.upload_status || 'pending',
          error_message: imageData.error_message,
          ...(imageData.element_id && { element_id: String(imageData.element_id) })
        })
        .select()

      if (dbError) throw dbError
      return data[0]
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // ì‘ì—… ë¡œê·¸ ì €ì¥ (ì™„ì „ ë¹„í™œì„±í™” - RLS ì •ì±… ë¬¸ì œ)
  const saveOperationLog = async (operationData) => {
    // operation_logs í…Œì´ë¸”ì˜ RLS ì •ì±… ë¬¸ì œë¡œ ì¸í•´ ì™„ì „íˆ ë¹„í™œì„±í™”
    // ì½˜ì†”ì—ë§Œ ë¡œê·¸ ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹… ê°€ëŠ¥
    console.log('ğŸ“ Operation log (disabled due to RLS policy):', {
      operation_type: operationData.operation_type,
      target_type: operationData.target_type,
      status: operationData.status,
      message: operationData.message?.substring(0, 100) + '...'
    })
    return null
  }

  // ì„¸íŠ¸ ëª©ë¡ ì¡°íšŒ
  const getLegoSets = async (page = 1, pageSize = 50) => {
    loading.value = true
    error.value = null

    try {
      const from = (page - 1) * pageSize
      const to = from + pageSize - 1

      const { data, error: dbError } = await supabase
        .from('lego_sets')
        .select('*, webp_image_url, theme_id')
        .order('created_at', { ascending: false })
        .range(from, to)

      if (dbError) throw dbError
      
      // theme ì •ë³´ë¥¼ ë³„ë„ë¡œ ì¡°íšŒ
      const themeIds = [...new Set((data || []).map(s => s.theme_id).filter(Boolean))]
      let themesMap = new Map()
      if (themeIds.length > 0) {
        const { data: themesData } = await supabase
          .from('lego_themes')
          .select('theme_id, name')
          .in('theme_id', themeIds)
        
        if (themesData) {
          themesMap = new Map(themesData.map(t => [t.theme_id, t.name]))
        }
      }
      
      // theme_name ì¶”ê°€
      return (data || []).map(set => ({
        ...set,
        theme_name: set.theme_id ? themesMap.get(set.theme_id) : null
      }))
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // íŠ¹ì • ì„¸íŠ¸ì˜ ë¶€í’ˆ ëª©ë¡ ì¡°íšŒ (ëª¨ë“  ë¶€í’ˆ ê°€ì ¸ì˜¤ê¸°)
  const getSetParts = async (setId) => {
    loading.value = true
    error.value = null

    try {
      console.log(`Loading parts for set ID: ${setId}`)
      
      // ë°©ë²• 1: ë‹¨ìˆœí•˜ê²Œ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì œí•œ ì—†ì´)
      // ì™¸ë˜ í‚¤ ì œì•½ ì¡°ê±´ ì œê±°ë¡œ ì¸í•œ ê´€ê³„ ì¸ì‹ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë‹¨ê³„ë³„ ì¡°íšŒ
      const { data: setParts, error: setPartsError, count } = await supabase
        .from('set_parts')
        .select('*', { count: 'exact' })
        .eq('set_id', setId)
      
      if (setPartsError) {
        console.error('Database error:', setPartsError)
        throw setPartsError
      }
      
      if (!setParts || setParts.length === 0) {
        return { data: [], count: 0 }
      }
      
      // part_idì™€ color_id ëª©ë¡ ì¶”ì¶œ
      const partIds = [...new Set(setParts.map(sp => sp.part_id))]
      const colorIds = [...new Set(setParts.map(sp => sp.color_id))]
      
      // lego_partsì™€ lego_colors ë³„ë„ ì¡°íšŒ
      const { data: legoParts, error: legoPartsError } = await supabase
        .from('lego_parts')
        .select('part_num, name, part_cat_id, part_img_url')
        .in('part_num', partIds)
      
      const { data: legoColors, error: legoColorsError } = await supabase
        .from('lego_colors')
        .select('color_id, name, rgb')
        .in('color_id', colorIds)
      
      if (legoPartsError || legoColorsError) {
        console.error('Related data error:', legoPartsError || legoColorsError)
        throw legoPartsError || legoColorsError
      }
      
      // ë°ì´í„° ì¡°í•©
      const data = setParts.map(sp => ({
        ...sp,
        lego_parts: legoParts.find(lp => lp.part_num === sp.part_id),
        lego_colors: legoColors.find(lc => lc.color_id === sp.color_id)
      }))

      console.log(`Direct query returned ${data ? data.length : 0} parts`)
      console.log(`Total count in database: ${count}`)

      // ë§Œì•½ ì œí•œì´ ìˆë‹¤ë©´ í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„
      if (data && data.length < count) {
        console.log('Direct query returned fewer results than expected, trying pagination...')
        
        const allParts = []
        let from = 0
        const pageSize = 1000
        let hasMore = true
        let pageCount = 0

        while (hasMore && pageCount < 5) { // ìµœëŒ€ 5í˜ì´ì§€ê¹Œì§€ë§Œ
          pageCount++
          console.log(`Fetching page ${pageCount}, range: ${from} to ${from + pageSize - 1}`)
          
          const { data: pageData, error: pageError } = await supabase
            .from('set_parts')
            .select(`
              *,
              lego_parts(*),
              lego_colors(*)
            `)
            .eq('set_id', setId)
            .range(from, from + pageSize - 1)

          if (pageError) {
            console.error('Page error:', pageError)
            throw pageError
          }

          console.log(`Page ${pageCount} returned ${pageData ? pageData.length : 0} parts`)

          if (pageData && pageData.length > 0) {
            allParts.push(...pageData)
            console.log(`Total parts collected so far: ${allParts.length}`)
            from += pageSize
            
            if (pageData.length < pageSize) {
              hasMore = false
              console.log('No more data available, stopping pagination')
            }
          } else {
            hasMore = false
            console.log('No data returned, stopping pagination')
          }
        }

        console.log(`Pagination result: Loaded ${allParts.length} parts for set ${setId}`)
        return allParts
      }

      console.log(`Final result: Loaded ${data ? data.length : 0} parts for set ${setId}`)
      return data || []
      
    } catch (err) {
      console.error('Error loading set parts:', err)
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // ë¶€í’ˆ ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ (element_id ìš°ì„  ì§€ì›)
  const getPartImages = async (partId, colorId = null, elementId = null) => {
    loading.value = true
    error.value = null

    try {
      let query = supabase
        .from('part_images')
        .select(`
          *,
          lego_parts(*),
          lego_colors(*)
        `)

      // element_idê°€ ìˆìœ¼ë©´ element_idë¡œ ìš°ì„  ì¡°íšŒ
      if (elementId) {
        query = query.eq('element_id', String(elementId))
      } else {
        // element_idê°€ ì—†ìœ¼ë©´ part_id + color_idë¡œ ì¡°íšŒ
        query = query.eq('part_id', partId)
        if (colorId) {
          query = query.eq('color_id', colorId)
        }
      }

      const { data, error: dbError } = await query

      if (dbError) throw dbError
      return data
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // ì‘ì—… ë¡œê·¸ ì¡°íšŒ
  const getOperationLogs = async (page = 1, pageSize = 50) => {
    loading.value = true
    error.value = null

    try {
      const from = (page - 1) * pageSize
      const to = from + pageSize - 1

      const { data, error: dbError } = await supabase
        .from('operation_logs')
        .select(`
          *,
          admin_users(*)
        `)
        .order('created_at', { ascending: false })
        .range(from, to)

      if (dbError) throw dbError
      return data
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // ì´ë¯¸ ë“±ë¡ëœ ì„¸íŠ¸ì¸ì§€ í™•ì¸
  const checkSetExists = async (setNum) => {
    try {
      const { data, error: dbError } = await supabase
        .from('lego_sets')
        .select('id, set_num, name, year, num_parts, created_at')
        .eq('set_num', setNum)
        .maybeSingle()

      if (dbError) throw dbError
      return data
    } catch (err) {
      console.error('Error checking set existence:', err)
      return null
    }
  }

  // ì—¬ëŸ¬ ì„¸íŠ¸ì˜ ë“±ë¡ ìƒíƒœë¥¼ í•œ ë²ˆì— í™•ì¸
  const checkMultipleSetsExist = async (setNums) => {
    loading.value = true
    error.value = null

    try {
      const { data, error: dbError } = await supabase
        .from('lego_sets')
        .select('id, set_num, name, created_at')
        .in('set_num', setNums)

      if (dbError) throw dbError
      return data || []
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // ëª¨ë“  Storage ë²„í‚· ì •ë¦¬ (models ë²„í‚· ì œì™¸)
  const clearAllStorageBuckets = async () => {
    try {
      console.log('ğŸ§¹ ëª¨ë“  Storage ë²„í‚· ì •ë¦¬ ì‹œì‘...')
      
      const bucketsToClean = [
        'lego_parts_images',
        'lego-synthetic',
        'temp',
        'uploads'
      ]
      
      const results = {
        totalFiles: 0,
        deletedFiles: 0,
        errors: []
      }
      
      for (const bucketName of bucketsToClean) {
        console.log(`ğŸ—‚ï¸ ${bucketName} ë²„í‚· ì •ë¦¬ ì¤‘...`)
        
        try {
          // ë²„í‚·ì˜ ë£¨íŠ¸ ë ˆë²¨ í•­ëª© ì¡°íšŒ
          const { data: rootItems, error: listError } = await supabase.storage
            .from(bucketName)
            .list('', { limit: 10000 })
          
          if (listError) {
            console.warn(`âš ï¸ ${bucketName} ë²„í‚· ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:`, listError)
            results.errors.push(`${bucketName}: ${listError.message}`)
            continue
          }
          
          if (!rootItems || rootItems.length === 0) {
            console.log(`âœ… ${bucketName} ë²„í‚·ì´ ì´ë¯¸ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.`)
            continue
          }
          
          console.log(`ğŸ“ ${bucketName} ë²„í‚·ì—ì„œ ${rootItems.length}ê°œ ë£¨íŠ¸ í•­ëª© ë°œê²¬`)
          
          // ì•Œë ¤ì§„ í´ë” êµ¬ì¡°ë¥¼ ì§ì ‘ íƒìƒ‰
          const allFilePaths = []
          const knownFolders = ['images', 'sets', 'synthetic', 'temp', 'uploads']
          
          for (const folderName of knownFolders) {
            console.log(`ğŸ” ì•Œë ¤ì§„ í´ë” íƒìƒ‰: ${folderName}`)
            
            try {
              const { data: folderItems, error: folderError } = await supabase.storage
                .from(bucketName)
                .list(folderName, { limit: 1000 })
              
              if (folderError) {
                console.log(`âŒ í´ë” ${folderName} ì ‘ê·¼ ì‹¤íŒ¨:`, folderError.message)
                continue
              }
              
              if (!folderItems || folderItems.length === 0) {
                console.log(`ğŸ“ ë¹ˆ í´ë”: ${folderName}`)
                continue
              }
              
              console.log(`ğŸ“ í´ë” ${folderName}ì—ì„œ ${folderItems.length}ê°œ í•­ëª© ë°œê²¬`)
              
              for (const item of folderItems) {
                const fullPath = `${folderName}/${item.name}`
                console.log(`ğŸ“„ í•­ëª©: ${item.name}, ì „ì²´ ê²½ë¡œ: ${fullPath}`)
                console.log(`ğŸ“„ ë©”íƒ€ë°ì´í„°:`, item)
                
                if (item.metadata?.size > 0) {
                  allFilePaths.push(fullPath)
                  console.log(`âœ… íŒŒì¼ ì¶”ê°€: ${fullPath}`)
                } else {
                  // í•˜ìœ„ í´ë”ì¸ ê²½ìš° ë” ê¹Šì´ íƒìƒ‰
                  console.log(`ğŸ“ í•˜ìœ„ í´ë” íƒìƒ‰: ${fullPath}`)
                  
                  try {
                    const { data: subItems, error: subError } = await supabase.storage
                      .from(bucketName)
                      .list(fullPath, { limit: 1000 })
                    
                    if (subError) {
                      console.log(`âŒ í•˜ìœ„ í´ë” ${fullPath} ì ‘ê·¼ ì‹¤íŒ¨:`, subError.message)
                    } else if (subItems && subItems.length > 0) {
                      console.log(`ğŸ“ í•˜ìœ„ í´ë” ${fullPath}ì—ì„œ ${subItems.length}ê°œ í•­ëª© ë°œê²¬`)
                      
                      for (const subItem of subItems) {
                        const subPath = `${fullPath}/${subItem.name}`
                        console.log(`ğŸ“„ í•˜ìœ„ í•­ëª©: ${subItem.name}, ì „ì²´ ê²½ë¡œ: ${subPath}`)
                        
                        if (subItem.metadata?.size > 0) {
                          allFilePaths.push(subPath)
                          console.log(`âœ… í•˜ìœ„ íŒŒì¼ ì¶”ê°€: ${subPath}`)
                        } else {
                          console.log(`ğŸ“ í•˜ìœ„ í´ë” ë˜ëŠ” ë¹ˆ í•­ëª©: ${subPath}`)
                        }
                      }
                    } else {
                      console.log(`ğŸ“ ë¹ˆ í•˜ìœ„ í´ë”: ${fullPath}`)
                    }
                  } catch (subError) {
                    console.log(`âŒ í•˜ìœ„ í´ë” ${fullPath} íƒìƒ‰ ì¤‘ ì˜¤ë¥˜:`, subError.message)
                  }
                }
              }
            } catch (error) {
              console.log(`âŒ í´ë” ${folderName} íƒìƒ‰ ì¤‘ ì˜¤ë¥˜:`, error.message)
            }
          }
          
          console.log(`ğŸ“‹ ìˆ˜ì§‘ëœ íŒŒì¼ ê²½ë¡œ: ${allFilePaths.length}ê°œ`)
          console.log(`ğŸ“‹ íŒŒì¼ ëª©ë¡:`, allFilePaths)
          
          results.totalFiles += allFilePaths.length
          
          if (allFilePaths.length > 0) {
            console.log(`ğŸ—‘ï¸ ${bucketName} ë²„í‚·ì—ì„œ ${allFilePaths.length}ê°œ íŒŒì¼ ì‚­ì œ ì¤‘...`)
            
            // ë°°ì¹˜ë¡œ íŒŒì¼ ì‚­ì œ (í•œ ë²ˆì— 10ê°œì”©ìœ¼ë¡œ ì¤„ì„)
            const batchSize = 10
            for (let i = 0; i < allFilePaths.length; i += batchSize) {
              const batch = allFilePaths.slice(i, i + batchSize)
              console.log(`ğŸ—‘ï¸ ì‚­ì œ ì‹œë„: ${batch.join(', ')}`)
              
              const { data: deleteData, error: deleteError } = await supabase.storage
                .from(bucketName)
                .remove(batch)
              
              console.log(`ì‚­ì œ ê²°ê³¼:`, { deleteData, deleteError })
              
              if (deleteError) {
                console.error(`âŒ ${bucketName} ë²„í‚· íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨:`, deleteError)
                console.error(`ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:`, batch)
                results.errors.push(`${bucketName}: ${deleteError.message}`)
              } else {
                console.log(`âœ… ${bucketName} ë²„í‚·ì—ì„œ ${batch.length}ê°œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ`)
                console.log(`ì‚­ì œëœ íŒŒì¼ë“¤:`, deleteData)
                results.deletedFiles += batch.length
              }
              
              // API í˜¸ì¶œ ì œí•œ ë°©ì§€
              if (i + batchSize < allFilePaths.length) {
                await new Promise(resolve => setTimeout(resolve, 200))
              }
            }
          }
          
        } catch (bucketError) {
          console.error(`âŒ ${bucketName} ë²„í‚· ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:`, bucketError)
          results.errors.push(`${bucketName}: ${bucketError.message}`)
        }
      }
      
      console.log('ğŸ‰ Storage ë²„í‚· ì •ë¦¬ ì™„ë£Œ!')
      console.log(`ğŸ“Š ì´ ${results.totalFiles}ê°œ íŒŒì¼ ì¤‘ ${results.deletedFiles}ê°œ ì‚­ì œ`)
      
      if (results.errors.length > 0) {
        console.warn('âš ï¸ ì¼ë¶€ ì˜¤ë¥˜ ë°œìƒ:', results.errors)
      }
      
      return results
      
    } catch (error) {
      console.error('âŒ Storage ë²„í‚· ì •ë¦¬ ì¤‘ ì˜¤ë¥˜:', error)
      throw error
    }
  }

  // ë°ì´í„°ë² ì´ìŠ¤ë§Œ ì´ˆê¸°í™” (Storage ì œì™¸)
  const resetDatabaseOnly = async () => {
    try {
      console.log('ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...')
      
      const results = {
        deletedRecords: 0,
        errors: [],
        steps: []
      }
      
      // ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì •ë¦¬ (ì™¸ë˜í‚¤ ìˆœì„œ ê³ ë ¤)
      const tablesToClean = [
        // ì˜ì¡´ì„±ì´ ìˆëŠ” í…Œì´ë¸”ë“¤ë¶€í„° ì‚­ì œ
        'parts_master_features',  // LLM ë¶„ì„ ë°ì´í„°
        'part_images',            // ë¶€í’ˆ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°
        'set_parts',              // ì„¸íŠ¸-ë¶€í’ˆ ê´€ê³„
        'lego_sets',              // ë ˆê³  ì„¸íŠ¸
        'lego_parts',             // ë ˆê³  ë¶€í’ˆ
        'lego_colors',            // ë ˆê³  ìƒ‰ìƒ
        'operation_logs',         // ì‘ì—… ë¡œê·¸
        'image_metadata',         // ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°
        'set_training_status',    // í›ˆë ¨ ìƒíƒœ
        'training_jobs',          // í›ˆë ¨ ì‘ì—…
        'training_metrics',       // í›ˆë ¨ ë©”íŠ¸ë¦­
        'model_registry'          // ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
      ]
      
      // ëª¨ë“  í…Œì´ë¸”ì„ ì •ìƒì ì¸ ë°©ì‹ìœ¼ë¡œ ì‚­ì œ
      const allTablesToClean = [
        // ì˜ì¡´ì„±ì´ ìˆëŠ” í…Œì´ë¸”ë“¤ë¶€í„° ì‚­ì œ
        'parts_master_features',  // LLM ë¶„ì„ ë°ì´í„°
        'part_images',            // ë¶€í’ˆ ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°
        'set_parts',              // ì„¸íŠ¸-ë¶€í’ˆ ê´€ê³„
        'lego_sets',              // ë ˆê³  ì„¸íŠ¸
        'lego_parts',             // ë ˆê³  ë¶€í’ˆ
        'lego_colors',            // ë ˆê³  ìƒ‰ìƒ
        'operation_logs',         // ì‘ì—… ë¡œê·¸
        'synthetic_dataset',      // í•©ì„± ë°ì´í„°ì…‹
        'synthetic_part_stats',   // í•©ì„± ë¶€í’ˆ í†µê³„
        'image_metadata',         // ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°
        'set_training_status',    // í›ˆë ¨ ìƒíƒœ
        'training_jobs',          // í›ˆë ¨ ì‘ì—…
        'training_metrics',       // í›ˆë ¨ ë©”íŠ¸ë¦­
        'model_registry'          // ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
      ]
      
      // ëª¨ë“  í…Œì´ë¸”ì„ í•˜ë‚˜ì˜ ë£¨í”„ì—ì„œ ì²˜ë¦¬
      for (const tableName of allTablesToClean) {
        console.log(`ğŸ—‘ï¸ ${tableName} í…Œì´ë¸” ì •ë¦¬ ì¤‘...`)
        
        try {
          // ë¨¼ì € í˜„ì¬ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
          const { count: beforeCount, error: beforeError } = await supabase
            .from(tableName)
            .select('*', { count: 'exact', head: true })
          
          console.log(`ğŸ“Š ${tableName} ì‚­ì œ ì „ ë ˆì½”ë“œ ìˆ˜: ${beforeCount || 0}ê°œ`)
          
          if (beforeCount === 0) {
            console.log(`â­ï¸ ${tableName} í…Œì´ë¸”ì´ ì´ë¯¸ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.`)
            results.steps.push(`${tableName}: ì´ë¯¸ ë¹„ì–´ìˆìŒ`)
            continue
          }
          
          // ê°„ë‹¨í•œ ì¡°ê±´ìœ¼ë¡œ ëª¨ë“  ë ˆì½”ë“œ ì‚­ì œ ì‹œë„
          let deleteQuery = supabase.from(tableName).delete()
          
          // í…Œì´ë¸”ë³„ë¡œ ì ì ˆí•œ ì¡°ê±´ ì‚¬ìš©
          if (tableName === 'parts_master_features' || 
              tableName === 'set_training_status' || 
              tableName === 'training_jobs' || 
              tableName === 'training_metrics' || 
              tableName === 'model_registry' ||
              tableName === 'synthetic_dataset') {
            // integer ID í…Œì´ë¸”ë“¤
            deleteQuery = deleteQuery.gte('id', 0)
          } else if (tableName === 'synthetic_part_stats') {
            // synthetic_part_statsëŠ” íŠ¹ë³„í•œ ì²˜ë¦¬
            deleteQuery = deleteQuery.not('part_id', 'is', null)
          } else {
            // UUID ID í…Œì´ë¸”ë“¤
            deleteQuery = deleteQuery.neq('id', '00000000-0000-0000-0000-000000000000')
          }
          
          const { count, error: deleteError } = await deleteQuery
          
          if (deleteError) {
            console.error(`âŒ ${tableName} í…Œì´ë¸” ì •ë¦¬ ì‹¤íŒ¨:`, deleteError)
            results.errors.push(`${tableName}: ${deleteError.message}`)
          } else {
            console.log(`âœ… ${tableName} í…Œì´ë¸” ì •ë¦¬ ì™„ë£Œ`)
            
            // ì‹¤ì œ ì‚­ì œ í™•ì¸ì„ ìœ„í•´ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
            try {
              const { count: remainingCount, error: countError } = await supabase
                .from(tableName)
                .select('*', { count: 'exact', head: true })
              
              if (countError) {
                console.warn(`âš ï¸ ${tableName} ë ˆì½”ë“œ ìˆ˜ í™•ì¸ ì‹¤íŒ¨:`, countError.message)
              } else {
                console.log(`ğŸ“Š ${tableName} ë‚¨ì€ ë ˆì½”ë“œ ìˆ˜: ${remainingCount || 0}ê°œ`)
                if (remainingCount > 0) {
                  console.warn(`âš ï¸ ${tableName} í…Œì´ë¸”ì— ${remainingCount}ê°œ ë ˆì½”ë“œê°€ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤!`)
                  results.errors.push(`${tableName}: ${remainingCount}ê°œ ë ˆì½”ë“œê°€ ë‚¨ì•„ìˆìŒ`)
                }
              }
            } catch (countErr) {
              console.warn(`âš ï¸ ${tableName} ë ˆì½”ë“œ ìˆ˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜:`, countErr.message)
            }
            
            results.steps.push(`${tableName}: í…Œì´ë¸” ì •ë¦¬ ì™„ë£Œ`)
          }
        } catch (tableError) {
          console.error(`âŒ ${tableName} í…Œì´ë¸” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:`, tableError)
          results.errors.push(`${tableName}: ${tableError.message}`)
        }
      }
      
      // 3. ì‹œí€€ìŠ¤ ë¦¬ì…‹ (PostgreSQL ì‹œí€€ìŠ¤) - ê±´ë„ˆë›°ê¸°
      console.log('â­ï¸ ì‹œí€€ìŠ¤ ë¦¬ì…‹ ê±´ë„ˆë›°ê¸° (RPC í•¨ìˆ˜ ì—†ìŒ)')
      results.steps.push('ì‹œí€€ìŠ¤ ë¦¬ì…‹ ê±´ë„ˆë›°ê¸°')
      
      console.log('ğŸ‰ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!')
      console.log(`ğŸ“Š ì²˜ë¦¬ëœ ë‹¨ê³„: ${results.steps.length}ê°œ`)
      console.log(`âŒ ì˜¤ë¥˜: ${results.errors.length}ê°œ`)
      
      if (results.errors.length > 0) {
        console.warn('âš ï¸ ì¼ë¶€ ì˜¤ë¥˜ ë°œìƒ:', results.errors)
      }
      
      return results
      
    } catch (error) {
      console.error('âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜:', error)
      throw error
    }
  }

  // í”„ë¡œì íŠ¸ ë°ì´í„° ì™„ì „ ì´ˆê¸°í™” (Storage + Database)
  const resetAllProjectData = async () => {
    try {
      console.log('ğŸ”„ í”„ë¡œì íŠ¸ ë°ì´í„° ì™„ì „ ì´ˆê¸°í™” ì‹œì‘...')
      
      const results = {
        deletedRecords: 0,
        errors: [],
        steps: []
      }
      
      // 1. Storage ë²„í‚· ì •ë¦¬ (models ì œì™¸)
      console.log('ğŸ—‚ï¸ Storage ë²„í‚· ì •ë¦¬ ì¤‘...')
      try {
        const storageResults = await clearAllStorageBuckets()
        results.deletedRecords += storageResults.deletedFiles
        results.steps.push(`Storage: ${storageResults.deletedFiles}ê°œ íŒŒì¼ ì‚­ì œ`)
      } catch (storageError) {
        console.error('Storage ì •ë¦¬ ì‹¤íŒ¨:', storageError)
        results.errors.push(`Storage: ${storageError.message}`)
      }
      
      // 2. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
      console.log('ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...')
      try {
        const dbResults = await resetDatabaseOnly()
        results.steps.push(...dbResults.steps)
        results.errors.push(...dbResults.errors)
      } catch (dbError) {
        console.error('ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨:', dbError)
        results.errors.push(`Database: ${dbError.message}`)
      }
      
      console.log('ğŸ‰ í”„ë¡œì íŠ¸ ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ!')
      console.log(`ğŸ“Š ì²˜ë¦¬ëœ ë‹¨ê³„: ${results.steps.length}ê°œ`)
      console.log(`âŒ ì˜¤ë¥˜: ${results.errors.length}ê°œ`)
      
      if (results.errors.length > 0) {
        console.warn('âš ï¸ ì¼ë¶€ ì˜¤ë¥˜ ë°œìƒ:', results.errors)
      }
      
      return results
      
    } catch (error) {
      console.error('âŒ í”„ë¡œì íŠ¸ ë°ì´í„° ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜:', error)
      throw error
    }
  }

  return {
    loading,
    error,
    saveLegoSet,
    saveLegoPart,
    saveLegoColor,
    saveSetPart,
    savePartImage,
    saveOperationLog,
    getLegoSets,
    getSetParts,
    getPartImages,
    getOperationLogs,
    checkSetExists,
    checkMultipleSetsExist,
    deleteSetAndParts,
    clearAllStorageBuckets,
    resetDatabaseOnly,
    resetAllProjectData
  }
}
