import { ref } from 'vue'
import { supabase } from './useSupabase'
import { useEnhancedRecognition } from './useEnhancedRecognition'
import { usePartClassification } from './usePartClassification'

// LLM API ÏÑ§Ï†ï (ÌïòÏù¥Î∏åÎ¶¨Îìú Ï†ÑÎûµÏö©)
const LLM_CONFIG = {
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  baseUrl: 'https://api.openai.com/v1',
  model: 'gpt-4o-mini',
  maxTokens: 1000,
  temperature: 0.1
}

// ÌôòÍ≤Ω Î≥ÄÏàò ÎîîÎ≤ÑÍπÖ (ÌîÑÎ°úÎçïÏÖòÏóêÏÑúÎèÑ ÌëúÏãú)
console.log('üîç Environment Debug:', {
  VITE_OPENAI_API_KEY: import.meta.env.VITE_OPENAI_API_KEY ? 'Present' : 'Missing',
  apiKey: LLM_CONFIG.apiKey ? 'Present' : 'Missing',
  allEnv: Object.keys(import.meta.env).filter(key => key.startsWith('VITE_')),
  // Ï∂îÍ∞Ä ÎîîÎ≤ÑÍπÖ Ï†ïÎ≥¥
  importMetaEnv: import.meta.env,
  nodeEnv: import.meta.env.MODE,
  dev: import.meta.env.DEV,
  prod: import.meta.env.PROD
})

// ÌïòÏù¥Î∏åÎ¶¨Îìú ÏÑ§Ï†ï: 1Ï∞®(4o-mini) Í≤∞Í≥ºÍ∞Ä Î™®Ìò∏ÌïòÎ©¥ 2Ï∞®(4.1-mini)Î°ú Î≥¥Í∞ï
const HYBRID_CONFIG = {
  enabled: false,
  secondaryModel: 'gpt-4.1-mini'
}

// OpenAI ÌÖçÏä§Ìä∏ ÏûÑÎ≤†Îî© ÏÑ§Ï†ï (ÏÇ¨Ï†Ñ Î∂ÑÏÑùÎêú feature_textÏö©)
const CLIP_CONFIG = {
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  baseUrl: 'https://api.openai.com/v1',
  model: 'text-embedding-3-small',
  dimensions: 768
}

// Í∞úÎ≥Ñ Ìï®ÏàòÎì§ÏùÑ exportÌïòÍ∏∞ ÏúÑÌï¥ Ìï®ÏàòÎì§ÏùÑ Î∞ñÏúºÎ°ú Ïù¥Îèô
export async function analyzePartWithLLM(part) {
  try {
    // API ÌÇ§ Í≤ÄÏ¶ù
    if (!LLM_CONFIG.apiKey || LLM_CONFIG.apiKey === 'undefined') {
      console.warn('‚ö†Ô∏è OpenAI API key is missing, skipping LLM analysis')
      console.warn('üîç Environment check:', {
        VITE_OPENAI_API_KEY: import.meta.env.VITE_OPENAI_API_KEY ? 'Present' : 'Missing',
        allEnv: Object.keys(import.meta.env).filter(key => key.startsWith('VITE_'))
      })
      return null // LLM Î∂ÑÏÑù Ïä§ÌÇµ
    }
    
    if (import.meta.env.DEV) {
      console.log('Î∂ÑÏÑùÌï† Î∂ÄÌíà Ï†ïÎ≥¥:', part)
    }
    
    // Î∂ÄÌíà Ï†ïÎ≥¥ ÌôïÏù∏ Î∞è Ï†ïÎ¶¨
    const partName = part.part?.name || part.name || 'Unknown'
    const partNum = part.part_num || part.part?.part_num || 'Unknown'
    const partImgUrl = part.part?.part_img_url || part.part_img_url || null
    const colorName = part.color?.name || part.color_name || 'Unknown'
    const colorId = part.color?.id ?? part.color_id ?? null
    const elementId = part.element_id || part.inv_part_id || null
    
    // Î†àÍ≥† Í≥µÏãù Î∂ÄÌíàÎ≤àÌò∏ ÌôïÏù∏ (external_idsÏóêÏÑú Ï∂îÏ∂ú)
    const externalIds = part.part?.external_ids || part.external_ids || {}
    const legoPartNumber = externalIds.lego || externalIds.Lego || null
    
    if (import.meta.env.DEV) {
      console.log('Ï†ïÎ¶¨Îêú Î∂ÄÌíà Ï†ïÎ≥¥:', { partName, partNum, partImgUrl, legoPartNumber })
    }
    
    // Ïù¥ÎØ∏ÏßÄ URLÏù¥ ÏóÜÏúºÎ©¥ Í∏∞Î≥∏ Î∂ÑÏÑùÎßå ÏàòÌñâ
    if (!partImgUrl) {
      console.warn(`Î∂ÄÌíà ${partNum}Ïùò Ïù¥ÎØ∏ÏßÄ URLÏù¥ ÏóÜÏäµÎãàÎã§. ÌÖçÏä§Ìä∏ÎßåÏúºÎ°ú Î∂ÑÏÑùÌï©ÎãàÎã§.`)
      return createTextOnlyAnalysis(part, partName, partNum)
    }
    
    const prompt = `Analyze LEGO part ${partName} (${partNum}) and return JSON:

{
  "shape": "basic shape",
  "center_stud": true/false,
  "groove": true/false,
  "connection": "connection type",
  "function": "main function",
  "feature_text": "brief description",
  "recognition_hints": {
    "top_view": "top view description",
    "side_view": "side view description",
    "unique_features": ["key features"]
  },
  "similar_parts": ["similar part numbers"],
  "distinguishing_features": ["distinguishing features"],
  "stud_count_top": 0,
  "tube_count_bottom": 0,
  "size_category": "duplo|system|minifig|technic",
  "keypoints": ["important shape points"],
  "confusions": ["confusing similar parts"],
  "color_expectation": "observed color summary",
  "confidence": 0.95
}`

    const requestBody = {
      model: LLM_CONFIG.model,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: prompt
            },
            {
              type: 'image_url',
              image_url: {
                url: partImgUrl,
                detail: 'high'
              }
            }
          ]
        }
      ],
      max_tokens: LLM_CONFIG.maxTokens,
      temperature: LLM_CONFIG.temperature,
      response_format: { type: 'json_object' }
    }

    if (import.meta.env.DEV) {
      console.log('API ÏöîÏ≤≠ Ï†ïÎ≥¥:', {
        model: LLM_CONFIG.model,
        apiKey: LLM_CONFIG.apiKey ? 'ÏÑ§Ï†ïÎê®' : 'ÏóÜÏùå',
        imageUrl: partImgUrl,
        promptLength: prompt.length
      })
    }

    const response = await fetch(`${LLM_CONFIG.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${LLM_CONFIG.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('API Ïò§Î•ò ÏùëÎãµ:', errorText)
      
      // Rate limit ÎåÄÏùë (Í∞úÏÑ†Îêú Î≤ÑÏ†Ñ)
      if (response.status === 429) {
        const errorData = JSON.parse(errorText)
        
        // retry_after Ìó§Îçî Ïö∞ÏÑ† ÌôïÏù∏, ÏóÜÏúºÎ©¥ ÏùëÎãµÏóêÏÑú Ï∂îÏ∂ú
        const retryAfterHeader = response.headers.get('retry-after')
        const retryAfterFromError = errorData.error?.retry_after
        const retryAfter = retryAfterHeader ? parseInt(retryAfterHeader) : (retryAfterFromError || 60)
        
        // ÏµúÏÜå 60Ï¥à, ÏµúÎåÄ 300Ï¥à ÎåÄÍ∏∞
        const waitTime = Math.min(Math.max(retryAfter, 60), 300)
        console.warn(`‚è≥ Rate limit exceeded. Waiting ${waitTime} seconds...`)
        await new Promise(resolve => setTimeout(resolve, waitTime * 1000))
        
        // Ïû¨ÏãúÎèÑ
        const retryResponse = await fetch(`${LLM_CONFIG.baseUrl}/chat/completions`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${LLM_CONFIG.apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(requestBody)
        })
        
        if (!retryResponse.ok) {
          const retryErrorText = await retryResponse.text()
          throw new Error(`LLM API Error (retry failed): ${retryResponse.status} - ${retryErrorText}`)
        }
        
        // Ïû¨ÏãúÎèÑ ÏÑ±Í≥µ Ïãú ÏùëÎãµ Ï≤òÎ¶¨
        const retryData = await retryResponse.json()
        if (!retryData.choices || !retryData.choices[0] || !retryData.choices[0].message) {
          console.error('Ïû¨ÏãúÎèÑ ÏùëÎãµ Íµ¨Ï°∞ Ïò§Î•ò:', retryData)
          return null
        }
        
        let retryParsed
        try {
          retryParsed = JSON.parse(retryData.choices[0].message.content)
        } catch (e) {
          const retryLlmResponse = retryData.choices[0].message.content || ''
          let retryJsonText = retryLlmResponse
          const retryJsonBlockMatch = retryLlmResponse.match(/```json\s*([\s\S]*?)\s*```/)
          if (retryJsonBlockMatch) {
            retryJsonText = retryJsonBlockMatch[1].trim()
          } else {
            const retryJsonObjectMatch = retryLlmResponse.match(/\{[\s\S]*\}/)
            if (retryJsonObjectMatch) retryJsonText = retryJsonObjectMatch[0]
          }
          try {
            retryParsed = JSON.parse(retryJsonText)
          } catch (err) {
            console.error('Ïû¨ÏãúÎèÑ JSON ÌååÏã± Ïã§Ìå®:', err)
            return null
          }
        }
        
        retryParsed.part_num = partNum
        return retryParsed
      }
      
      throw new Error(`LLM API Error: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    if (import.meta.env.DEV) {
      console.log('LLM raw response:', data)
    }
    
    // ÏùëÎãµ Íµ¨Ï°∞ ÌôïÏù∏
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      console.error('ÏùëÎãµ Íµ¨Ï°∞ Ïò§Î•ò:', data)
      return null
    }
    
    // JSON ÏùëÎãµ Í∞ïÏ†ú Î™®Îìú: contentÎäî JSON Î¨∏ÏûêÏó¥Ïù¥Ïñ¥Ïïº Ìï®
    let parsed
    try {
      parsed = JSON.parse(data.choices[0].message.content)
    } catch (e) {
      // ÏòàÏô∏Ï†ÅÏúºÎ°ú Ìè¨Îß∑Ïù¥ Ïñ¥Í∏ãÎÇòÎäî Í≤ΩÏö∞ Í∏∞Ï°¥ ÌååÏÑúÎ°ú Ìè¥Î∞±
      const llmResponse = data.choices[0].message.content || ''
      let jsonText = llmResponse
      const jsonBlockMatch = llmResponse.match(/```json\s*([\s\S]*?)\s*```/)
      if (jsonBlockMatch) {
        jsonText = jsonBlockMatch[1].trim()
      } else {
        const jsonObjectMatch = llmResponse.match(/\{[\s\S]*\}/)
        if (jsonObjectMatch) jsonText = jsonObjectMatch[0]
      }
      try {
        parsed = JSON.parse(jsonText)
      } catch (err) {
        console.error('JSON ÌååÏã± Ïã§Ìå®:', err)
        return null
      }
    }

    // 1Ï∞® Í≤∞Í≥º
    parsed.part_num = partNum

    // Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï†ïÍ∑úÌôî(ÌòïÏãù Î≥¥Ï†ï Î∞è ÌïÑÏàò ÌïÑÎìú Î≥¥Ï°¥)
    const normalizeArray = (v) => Array.isArray(v) ? v : (v ? [v] : [])
    const toBoolean = (v) => typeof v === 'boolean' ? v : (String(v).toLowerCase() === 'true')
    const toNumber = (v) => {
      const n = Number(v)
      return Number.isFinite(n) ? n : null
    }
    const normalizeAnalysis = (obj) => {
      const normalized = { ...obj }
      normalized.shape = typeof obj.shape === 'string' ? obj.shape : (obj.shape?.toString?.() || '')
      normalized.center_stud = toBoolean(obj.center_stud ?? false)
      normalized.groove = toBoolean(obj.groove ?? false)
      normalized.connection = typeof obj.connection === 'string' ? obj.connection : (obj.connection?.toString?.() || 'unknown')
      normalized.function = typeof obj.function === 'string' ? obj.function : (obj.function?.toString?.() || 'unknown')
      normalized.feature_text = typeof obj.feature_text === 'string' ? obj.feature_text : (obj.feature_text?.toString?.() || '')
      normalized.recognition_hints = {
        ...(obj.recognition_hints || {}),
        top_view: obj.recognition_hints?.top_view ?? '',
        side_view: obj.recognition_hints?.side_view ?? '',
        unique_features: normalizeArray(obj.recognition_hints?.unique_features)
      }
      normalized.similar_parts = normalizeArray(obj.similar_parts)
      normalized.distinguishing_features = normalizeArray(obj.distinguishing_features)
      normalized.keypoints = normalizeArray(obj.keypoints)
      normalized.confusions = normalizeArray(obj.confusions)
      normalized.color_expectation = (typeof obj.color_expectation === 'string' ? obj.color_expectation : (obj.color_expectation?.toString?.() || null))
      normalized.stud_count_top = toNumber(obj.stud_count_top)
      normalized.tube_count_bottom = toNumber(obj.tube_count_bottom)
      return normalized
    }
    parsed = normalizeAnalysis(parsed)

    // ÌïòÏù¥Î∏åÎ¶¨Îìú Î≥¥Í∞ï Ìä∏Î¶¨Í±∞: ÎÇÆÏùÄ confidence(<0.8), feature_text ÏßßÏùå(<40Ïûê), key ÌïÑÎìú ÎàÑÎùΩ Ïãú
    const needRefine = HYBRID_CONFIG.enabled && (
      (typeof parsed.confidence === 'number' && parsed.confidence < 0.8) ||
      (!parsed.feature_text || String(parsed.feature_text).length < 40) ||
      !parsed.recognition_hints || !parsed.distinguishing_features || !parsed.similar_parts ||
      (Array.isArray(parsed.keypoints) ? parsed.keypoints.length === 0 : true) ||
      (Array.isArray(parsed.confusions) ? parsed.confusions.length === 0 : true) ||
      (parsed.stud_count_top === null) || (parsed.tube_count_bottom === null) ||
      (!parsed.color_expectation)
    )

    if (!needRefine) return parsed

    // 2Ï∞® Î™®Îç∏(4.1-mini)Î°ú Î≥¥Í∞ï ÏöîÏ≤≠
    const refinePrompt = `Îã§Ïùå JSONÏùÑ Î≥¥Í∞ïÌïòÏÑ∏Ïöî. ÎàÑÎùΩÎêú ÌïÑÎìúÎ•º Ï±ÑÏö∞Í≥†, plate/brickÏùò stud/tube, Í∞ÅÎèÑ(ÏûàÎã§Î©¥), ÏÉâÏÉÅÎ™Ö(ÌëúÏ§ÄÎ™Ö), ÌòºÎèôÎêòÎäî Ïú†ÏÇ¨Î∂ÄÌíàÏùÑ Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú Í∏∞Ïà†ÌïòÏÑ∏Ïöî. JSONÎßå ÏùëÎãµ.

ÏõêÎ≥∏ JSON:\n${JSON.stringify(parsed)}`

    const refineBody = {
      model: HYBRID_CONFIG.secondaryModel,
      messages: [ { role: 'user', content: [ { type: 'text', text: refinePrompt } ] } ],
      max_tokens: LLM_CONFIG.maxTokens,
      temperature: 0.2,
      response_format: { type: 'json_object' }
    }

    const refineResp = await fetch(`${LLM_CONFIG.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${LLM_CONFIG.apiKey}`, 'Content-Type': 'application/json' },
      body: JSON.stringify(refineBody)
    })

    if (!refineResp.ok) return parsed
    let refined
    try {
      const refineData = await refineResp.json()
      refined = JSON.parse(refineData.choices[0].message.content)
    } catch {
      return parsed
    }

    // Î≥ëÌï©: 2Ï∞® Í∞íÏù¥ ÏûàÏúºÎ©¥ Ïö∞ÏÑ†, ÏóÜÏúºÎ©¥ 1Ï∞® Ïú†ÏßÄ + Ï†ïÍ∑úÌôî Î≥¥Ï°¥
    const mergedRaw = {
      ...parsed,
      ...refined,
      recognition_hints: { ...(parsed.recognition_hints || {}), ...(refined.recognition_hints || {}) },
      similar_parts: Array.isArray(refined?.similar_parts) && refined.similar_parts.length > 0 ? refined.similar_parts : parsed.similar_parts,
      distinguishing_features: Array.isArray(refined?.distinguishing_features) && refined.distinguishing_features.length > 0 ? refined.distinguishing_features : parsed.distinguishing_features,
      keypoints: Array.isArray(refined?.keypoints) && refined.keypoints.length > 0 ? refined.keypoints : parsed.keypoints,
      confusions: Array.isArray(refined?.confusions) && refined.confusions.length > 0 ? refined.confusions : parsed.confusions,
      stud_count_top: (refined?.stud_count_top ?? parsed.stud_count_top),
      tube_count_bottom: (refined?.tube_count_bottom ?? parsed.tube_count_bottom),
      color_expectation: (refined?.color_expectation ?? parsed.color_expectation)
    }

    const merged = normalizeAnalysis(mergedRaw)
    merged.part_num = partNum
    return merged
    
    } catch (error) {
      console.error('LLM Î∂ÑÏÑù Ïã§Ìå®:', error)
      return null // LLM Î∂ÑÏÑù Ïã§Ìå® Ïãú null Î∞òÌôò
    }
}

// Í∏∞Î≥∏ Î∂ÑÏÑù Í≤∞Í≥º ÏÉùÏÑ± (Îçî Ïù¥ÏÉÅ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏùå - LLM Ïã§Ìå® Ïãú null Î∞òÌôò)
// function createDefaultAnalysis(part, partName = null, partNum = null) {
//   const name = partName || part.part?.name || part.name || 'Unknown'
//   const num = partNum || part.part_num || part.part?.part_num || 'Unknown'
//   
//   return {
//     shape: `Î∂ÑÏÑù Ïã§Ìå®: ${name}`,
//     center_stud: false,
//     groove: false,
//     connection: 'unknown',
//     function: 'unknown',
//     feature_text: `Î∂ÄÌíà ${num}Ïùò ÏûêÎèô ÏÉùÏÑ±Îêú Í∏∞Î≥∏ ÏÑ§Î™Ö`,
//     recognition_hints: {
//       top_view: 'Í∏∞Î≥∏ ÌòïÌÉú',
//       side_view: 'Í∏∞Î≥∏ ÌòïÌÉú',
//       unique_features: ['Í∏∞Î≥∏ ÌäπÏßï']
//     },
//     similar_parts: [],
//     distinguishing_features: ['Í∏∞Î≥∏ ÌäπÏßï'],
//     confidence: 0.1,
//     part_num: num
//   }
// }

// ÌÖçÏä§Ìä∏ÎßåÏúºÎ°ú Î∂ÑÏÑù
function createTextOnlyAnalysis(part, partName, partNum) {
  return {
    shape: `ÌÖçÏä§Ìä∏ Î∂ÑÏÑù: ${partName}`,
    center_stud: false,
    groove: false,
    connection: 'unknown',
    function: 'unknown',
    feature_text: `Î∂ÄÌíà ${partNum}Ïùò ÌÖçÏä§Ìä∏ Í∏∞Î∞ò Í∏∞Î≥∏ ÏÑ§Î™Ö`,
    recognition_hints: {
      top_view: 'ÌÖçÏä§Ìä∏ Í∏∞Î∞ò Ï∂îÏ†ï',
      side_view: 'ÌÖçÏä§Ìä∏ Í∏∞Î∞ò Ï∂îÏ†ï',
      unique_features: ['ÌÖçÏä§Ìä∏ Í∏∞Î∞ò ÌäπÏßï']
    },
    similar_parts: [],
    distinguishing_features: ['ÌÖçÏä§Ìä∏ Í∏∞Î∞ò ÌäπÏßï'],
    confidence: 0.3,
    part_num: partNum
  }
}

// ÏûÑÎ≤†Îî© ÏÉùÏÑ± Ìï®Ïàò export
// ÌÖçÏä§Ìä∏ ÏûÑÎ≤†Îî© Î∞∞Ïπò + Ï∫êÏãú
export async function generateTextEmbeddingsBatch(analysisResults) {
  const results = []

  // 0) ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Ï§ëÎ≥µ Ï†úÍ±∞: (part_num, color_id) Ï°∞Ìï© Í∏∞Ï§ÄÏúºÎ°ú Ï§ëÎ≥µ Ï†úÍ±∞
  const uniqueResults = []
  const seenEmbeddingKeys = new Set()
  
  for (const item of analysisResults) {
    const partNum = item.part_num || 'unknown'
    const colorId = item.color_id !== undefined ? item.color_id : (item.color?.id !== undefined ? item.color.id : null)
    const key = `${partNum}_${colorId}`
    
    if (!seenEmbeddingKeys.has(key)) {
      seenEmbeddingKeys.add(key)
      uniqueResults.push(item)
    } else {
      console.warn(`‚ö†Ô∏è Duplicate embedding input found for part_num=${partNum}, color_id=${colorId}, skipping`)
    }
  }
  
  console.log(`üìä Embedding input deduplication: ${analysisResults.length} -> ${uniqueResults.length} results`)
  analysisResults = uniqueResults

  // 1) Í∏∞Ï°¥ ÏûÑÎ≤†Îî© Î≥¥Ïú†/feature_text ÎàÑÎùΩ ÏÑ†Î∂ÑÎ•ò
  const needsEmbedding = []
  for (const item of analysisResults) {
    const partNum = item.part_num || 'unknown'
    
    // part_idÍ∞Ä 'unknown'Ïù∏ Í≤ΩÏö∞ Ïä§ÌÇµ
    if (partNum === 'unknown' || partNum === 'Unknown') {
      console.warn(`‚ö†Ô∏è Skipping embedding for unknown part_num: ${partNum}`)
      continue
    }
    
    if (item.has_embedding === true) {
      console.log(`‚è≠Ô∏è Skipping embedding for ${partNum} - already has embedding`)
      results.push({ part_num: partNum, embedding: item.existing_embedding || null, feature_text: item.feature_text })
      continue
    }
    if (!item.feature_text) {
      console.warn(`‚ö†Ô∏è No feature text for ${partNum}, skipping embedding`)
      results.push({ part_num: partNum, embedding: null, error: 'feature_text missing' })
      continue
    }
    needsEmbedding.push(item)
  }

  if (needsEmbedding.length === 0) return results

  // 2) ÌÖçÏä§Ìä∏ Ìï¥Ïãú Ï∫êÏãúÎ°ú Ï§ëÎ≥µ Ï†úÍ±∞
  const textToIndices = new Map()
  const uniqueTexts = []
  needsEmbedding.forEach((item, idx) => {
    const key = stableTextKey(item.feature_text)
    if (!textToIndices.has(key)) {
      textToIndices.set(key, [])
      uniqueTexts.push(item.feature_text)
    }
    textToIndices.get(key).push(idx)
  })

  // 3) OpenAI Embeddings API Îã§Ï§ë ÏûÖÎ†• Î∞∞Ïπò Ìò∏Ï∂ú
  try {
    const response = await fetch(`${CLIP_CONFIG.baseUrl}/embeddings`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${CLIP_CONFIG.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: CLIP_CONFIG.model,
        input: uniqueTexts,
        dimensions: CLIP_CONFIG.dimensions
      })
    })

    if (!response.ok) throw new Error(`Embedding API Error: ${response.status}`)
    const data = await response.json()

    // 4) Í≤∞Í≥º Îß§Ìïë: ÎèôÏùº ÌÖçÏä§Ìä∏ Í≥µÏú† Ïù∏Îç±Ïä§Ïóê ÎèôÏùº ÏûÑÎ≤†Îî© Î≥µÏ†ú
    uniqueTexts.forEach((text, uIdx) => {
      const embedding = data.data[uIdx].embedding
      const targetIndices = textToIndices.get(stableTextKey(text))
      for (const idx of targetIndices) {
        const src = needsEmbedding[idx]
        const enhancedText = buildEnhancedEmbeddingText({
          partName: src.part?.name,
          partNum: src.part_num,
          colorName: src.color?.name,
          featureText: src.feature_text,
          keypoints: src.keypoints,
          distinguishing: src.distinguishing_features,
          legoPartNumber: src.part?.external_ids?.lego || src.part?.external_ids?.Lego || null
        })
        results.push({ part_num: src.part_num || 'unknown', embedding, feature_text: enhancedText })
      }
    })
  } catch (error) {
    console.error('‚ùå Batch embeddings failed:', error)
    // Ïã§Ìå® Ïãú Í∞úÎ≥Ñ Ìò∏Ï∂ú Ìè¥Î∞±(ÏµúÏÜåÌïúÏùò ÌíàÏßà Ïú†ÏßÄ)
    for (const src of needsEmbedding) {
      try {
        const r = await fetch(`${CLIP_CONFIG.baseUrl}/embeddings`, {
          method: 'POST',
          headers: { 'Authorization': `Bearer ${CLIP_CONFIG.apiKey}`, 'Content-Type': 'application/json' },
          body: JSON.stringify({ model: CLIP_CONFIG.model, input: src.feature_text, dimensions: CLIP_CONFIG.dimensions })
        })
        if (!r.ok) throw new Error(`Embedding API Error: ${r.status}`)
        const j = await r.json()
        const enhancedText = buildEnhancedEmbeddingText({
          partName: src.part?.name,
          partNum: src.part_num,
          colorName: src.color?.name,
          featureText: src.feature_text,
          keypoints: src.keypoints,
          distinguishing: src.distinguishing_features,
          legoPartNumber: src.part?.external_ids?.lego || src.part?.external_ids?.Lego || null
        })
        results.push({ part_num: src.part_num || 'unknown', embedding: j.data[0].embedding, feature_text: enhancedText })
      } catch (e) {
        results.push({ part_num: src.part_num || 'unknown', embedding: null, error: e.message })
      }
    }
  }

  return results
}

function stableTextKey(text) {
  return String(text).trim().toLowerCase()
}

// ÌëúÏ§Ä ÌÉúÍ∑∏ Ï†ïÍ∑úÌôî (Í≤ÄÏÉâ¬∑ÌõÑÏ≤òÎ¶¨ ÏµúÏ†ÅÌôî)
function normalizeShapeTag(raw) {
  const t = String(raw || '').toLowerCase()
  if (/(plate|ÌîåÎ†àÏù¥Ìä∏)/.test(t)) return 'plate'
  if (/(brick|Î∏åÎ¶≠)/.test(t)) return 'brick'
  if (/(slope|Í≤ΩÏÇ¨)/.test(t)) return 'slope'
  if (/(tile|ÌÉÄÏùº)/.test(t)) return 'tile'
  if (/(animal|ÎèôÎ¨º)/.test(t)) return 'animal_figure'
  if (/(leaf|plant|Ïûé|ÏãùÎ¨º)/.test(t)) return 'plant_leaf'
  if (/(technic|ÌÖåÌÅ¨Îãâ)/.test(t)) return 'technic'
  return t || 'unknown'
}

function normalizeFunctionTag(raw) {
  const t = String(raw || '').toLowerCase()
  if (/(basic|Í∏∞Î≥∏|building|Íµ¨ÏÑ±)/.test(t)) return 'building'
  if (/(decoration|Ïû•Ïãù)/.test(t)) return 'decoration'
  if (/(figure|ÌîºÍ∑úÏñ¥)/.test(t)) return 'figure'
  if (/(slope|Í≤ΩÏÇ¨)/.test(t)) return 'slope'
  return t || 'unknown'
}

// CLIP Ïä§ÌÉÄÏùº Î¨∏Íµ¨(ÏßßÍ≥† ÌïµÏã¨Ïñ¥ ÏúÑÏ£º)Î°ú Î≥ÄÌôò
function clipifyPhrases(arr) {
  if (!Array.isArray(arr)) return []
  return arr
    .map(s => String(s || '').toLowerCase().trim())
    .filter(Boolean)
    .map(s => s
      .replace(/\b(with|and|the|of|for|a|an|in|on|to|by|from)\b/g, '')
      .replace(/\s+/g, ' ')
      .trim()
    )
    .map(s => s.length > 40 ? s.slice(0, 40) : s)
}

function buildEnhancedEmbeddingText({ partName, partNum, colorName, featureText, keypoints, distinguishing, legoPartNumber }) {
  const header = [
    partName ? `name:${partName}` : null,
    partNum ? `part:${partNum}` : null,
    legoPartNumber ? `lego:${legoPartNumber}` : null,
    colorName ? `color:${colorName}` : null
  ].filter(Boolean).join(' ')

  const keypointsText = Array.isArray(keypoints) && keypoints.length > 0
    ? ` keypoints:${keypoints.join('|')}`
    : ''
  const distinguishingText = Array.isArray(distinguishing) && distinguishing.length > 0
    ? ` distinguishing:${distinguishing.join('|')}`
    : ''

  return `${header} features:${featureText || ''}${keypointsText}${distinguishingText}`.trim()
}

// Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï†ÄÏû• Ìï®Ïàò export
export async function saveToMasterPartsDB(analysisResults) {
  try {
    // 0) ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Ï§ëÎ≥µ Ï†úÍ±∞: (part_num, color_id) Ï°∞Ìï© Í∏∞Ï§ÄÏúºÎ°ú Ï§ëÎ≥µ Ï†úÍ±∞
    const uniqueResults = []
    const seenAnalysisKeys = new Set()
    
    for (const result of analysisResults) {
      const partNum = result.part_num || 'unknown'
      const colorId = result.color_id !== undefined ? result.color_id : (result.color?.id !== undefined ? result.color.id : null)
      
      // part_idÍ∞Ä nullÏù¥Í±∞ÎÇò 'unknown'Ïù∏ Í≤ΩÏö∞ Ïä§ÌÇµ
      if (!partNum || partNum === 'unknown' || partNum === 'Unknown') {
        console.warn(`‚ö†Ô∏è Skipping result with invalid part_num: ${partNum}`)
        continue
      }
      
      const key = `${partNum}_${colorId}`
      
      if (!seenAnalysisKeys.has(key)) {
        seenAnalysisKeys.add(key)
        uniqueResults.push(result)
      } else {
        console.warn(`‚ö†Ô∏è Duplicate analysis result found for part_num=${partNum}, color_id=${colorId}, skipping`)
      }
    }
    
    console.log(`üìä Input deduplication: ${analysisResults.length} -> ${uniqueResults.length} results`)
    analysisResults = uniqueResults

    // 1) ÎàÑÎùΩ ÏûÑÎ≤†Îî© Î≥¥Ï∂©: embedding ÏóÜÎäî Í≤∞Í≥ºÎì§Îßå Î∞∞Ïπò ÏÉùÏÑ±
    const missingEmb = analysisResults.filter(r => !Array.isArray(r.embedding) || r.embedding.length === 0)
    if (missingEmb.length > 0) {
      try {
        const embResults = await generateTextEmbeddingsBatch(missingEmb)
        const embMap = new Map()
        for (const e of embResults) {
          if (Array.isArray(e.embedding)) embMap.set(e.part_num, e.embedding)
        }
        analysisResults.forEach(r => {
          if (!Array.isArray(r.embedding) || r.embedding.length === 0) {
            const emb = embMap.get(r.part_num)
            if (emb) r.embedding = emb
          }
        })
      } catch (e) {
        console.warn('‚ö†Ô∏è Failed to backfill embeddings; proceeding without some embeddings', e)
      }
    }

    // Î∂ÑÎ•òÍ∏∞ Ï¥àÍ∏∞Ìôî (Tier/Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÏÇ∞Ï∂ú)
    const classifier = usePartClassification()

    // color_id ÌôïÏ†ï: result.color_id ÎòêÎäî result.color?.idÏóêÏÑú Ï∂îÏ∂ú, ÏóÜÏúºÎ©¥ Ï†ÄÏû• Ïä§ÌÇµ
    const mapped = analysisResults.map(result => {
      const resolvedColorId = (result.color_id !== undefined && result.color_id !== null)
        ? result.color_id
        : (result.color?.id !== undefined ? result.color.id : null)

      const partName = result.part?.name || result.name || ''
      const partNum = result.part_num || result.part?.part_num || ''

      // Tier Î∂ÑÎ•ò Î∞è Ìñ•ÏÉÅ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Í≥ÑÏÇ∞
      const tierClassification = classifier.classifyPartTier({ name: partName, part_num: partNum })
      const enhancedMetadata = classifier.generateEnhancedMetadata({ name: partName, part_num: partNum }, tierClassification)

      // ÌÉúÍ∑∏ Ï†ïÍ∑úÌôî + CLIP Ïä§ÌÉÄÏùº Î¨∏Íµ¨ Î≥ÄÌôò
      const normalizedShape = normalizeShapeTag(result.shape)
      const normalizedFunction = normalizeFunctionTag(result.function)
      const clipDistinguishing = clipifyPhrases(result.distinguishing_features)
      const clipHints = {
        ...result.recognition_hints,
        unique_features: clipifyPhrases(result.recognition_hints?.unique_features)
      }

      return {
        part_id: result.part_num,
        part_name: result.part?.name || 'Unknown',
        part_category: result.part?.part_cat_id || null,
        color_id: resolvedColorId,
        // 3-Tier Ïö¥ÏòÅ Ïª¨Îüº Ï†ÄÏû• (ÌÜµÍ≥Ñ/Ïö¥ÏòÅÏö©)
        tier: tierClassification.tier,
        orientation_sensitive: tierClassification.orientation_sensitive,
        complexity_level: enhancedMetadata.complexity_level,
        feature_json: {
          shape: result.shape,
          center_stud: result.center_stud,
          groove: result.groove,
          connection: result.connection,
          function: result.function,
          recognition_hints: result.recognition_hints,
          similar_parts: result.similar_parts,
          distinguishing_features: result.distinguishing_features,
          keypoints: result.keypoints || [],
          confusions: result.confusions || [],
          stud_count_top: (typeof result.stud_count_top === 'number' ? result.stud_count_top : null),
          tube_count_bottom: (typeof result.tube_count_bottom === 'number' ? result.tube_count_bottom : null),
          color_expectation: result.color_expectation || null,
          shape_tag: normalizedShape,
          function_tag: normalizedFunction,
          clip_distinguishing: clipDistinguishing,
          clip_unique_features: clipHints.unique_features
        },
        feature_text: result.feature_text,
        clip_text_emb: Array.isArray(result.embedding) ? result.embedding : null,
        // Î≥ÑÎèÑ Ïª¨ÎüºÏúºÎ°úÎèÑ Ï†ÄÏû•ÌïòÏó¨ Í≤ÄÏÉâ ÏµúÏ†ÅÌôî
        recognition_hints: result.recognition_hints || null,
        similar_parts: result.similar_parts || null,
        distinguishing_features: clipDistinguishing || null,
        confidence: result.confidence || 0.5
      }
    })

    // color_idÍ∞Ä ÏóÜÎäî Î†àÏΩîÎìúÎäî Ï†ÄÏû• Ïä§ÌÇµ (Ï§ëÎ≥µ/Ïû¨Î∂ÑÏÑù Ïú†Î∞ú Î∞©ÏßÄ)
    const validRecords = mapped.filter(r => r.color_id !== null && r.color_id !== undefined)
    const skipped = mapped.length - validRecords.length

    // Ï§ëÎ≥µ Ï†úÍ±∞: (part_id, color_id) Ï°∞Ìï©Ïù¥ Ï§ëÎ≥µÎêòÎäî Í≤ΩÏö∞ ÎßàÏßÄÎßâ Í≤ÉÎßå Ïú†ÏßÄ
    const uniqueRecords = []
    const seenRecordKeys = new Set()
    
    // Ïó≠ÏàúÏúºÎ°ú ÏàúÌöåÌïòÏó¨ Ï§ëÎ≥µÎêú ÌÇ§Ïùò Í≤ΩÏö∞ ÎßàÏßÄÎßâ(ÏµúÏã†) Î†àÏΩîÎìúÎßå Ïú†ÏßÄ
    for (let i = validRecords.length - 1; i >= 0; i--) {
      const record = validRecords[i]
      const key = `${record.part_id}_${record.color_id}`
      
      if (!seenRecordKeys.has(key)) {
        seenRecordKeys.add(key)
        uniqueRecords.unshift(record) // ÏàúÏÑú Ïú†ÏßÄÎ•º ÏúÑÌï¥ unshift ÏÇ¨Ïö©
      } else {
        console.warn(`‚ö†Ô∏è Duplicate record found for part_id=${record.part_id}, color_id=${record.color_id}, skipping`)
      }
    }

    const records = uniqueRecords
    const duplicatesRemoved = validRecords.length - records.length

    console.log(`üíæ Saving ${records.length} records to parts_master_features...`)
    if (skipped > 0) {
      console.warn(`‚ö†Ô∏è Skipping ${skipped} records without color_id to avoid null-color duplicates`)
    }
    if (duplicatesRemoved > 0) {
      console.warn(`‚ö†Ô∏è Removed ${duplicatesRemoved} duplicate records to avoid constraint violations`)
    }
    
    const { data, error } = await supabase
      .from('parts_master_features')
      .upsert(records, { 
        onConflict: 'part_id,color_id',
        ignoreDuplicates: false 
      })

    if (error) throw error

    console.log(`‚úÖ Successfully saved ${records.length} records to parts_master_features`)
    
    // Ï∫êÏãú ÏóÖÎç∞Ïù¥Ìä∏
    records.forEach(record => {
      const cacheKey = `${record.part_id}_${record.color_id}`
      const result = {
        part_num: record.part_id,
        color_id: record.color_id,
        shape: record.feature_json?.shape || 'unknown',
        center_stud: record.feature_json?.center_stud || false,
        groove: record.feature_json?.groove || false,
        connection: record.feature_json?.connection || 'unknown',
        function: record.feature_json?.function || 'unknown',
        feature_text: record.feature_text,
        recognition_hints: record.feature_json?.recognition_hints || {},
        similar_parts: record.feature_json?.similar_parts || [],
        distinguishing_features: record.feature_json?.distinguishing_features || [],
        confidence: record.confidence || 0.5,
        embedding: record.clip_text_emb
      }
      analysisCache.set(cacheKey, result)
    })
    
    return { success: true, count: records.length }
    
  } catch (error) {
    console.error('‚ùå Database save failed:', error)
    throw error
  }
}

// Í∏∞Ï°¥ Î∂ÑÏÑù ÌôïÏù∏ Ìï®Ïàò export
export async function checkExistingAnalysis(partNum, colorId) {
  try {
    const cacheKey = `${partNum}_${colorId}`
    console.log(`üîç Checking existing analysis for ${partNum} (color: ${colorId})`)
    
    // colorIdÍ∞Ä ÏóÜÏúºÎ©¥, null-colorÎ°ú Ï†ÄÏû•Îêú Í∏∞Ï°¥ Î†àÏΩîÎ¶¨ÎèÑ Ï°¥Ïû¨Î°ú Í∞ÑÏ£ºÌïòÏó¨ Ï¶âÏãú Ïä§ÌÇµ
    if (colorId === null || colorId === undefined) {
      console.warn(`‚ö†Ô∏è colorId is missing for ${partNum}; treating as existing to avoid duplicate LLM runs`)
      return { part_num: partNum, color_id: null, feature_text: '', embedding: null }
    }

    // 1. Î®ºÏ†Ä Ï∫êÏãúÏóêÏÑú ÌôïÏù∏
    if (analysisCache.has(cacheKey)) {
      console.log(`‚úÖ Found in cache for ${partNum} (color: ${colorId})`)
      return analysisCache.get(cacheKey)
    }
    
    // 2. Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú ÌôïÏù∏
    const { data, error: dbError } = await supabase
      .from('parts_master_features')
      .select('part_id, color_id, feature_json, feature_text, clip_text_emb, confidence')
      .eq('part_id', partNum)
      .eq('color_id', parseInt(colorId))
      .maybeSingle()
    
    console.log(`üîç Query result for ${partNum} (color: ${colorId}):`, { data, error: dbError })

    if (dbError) {
      console.warn(`‚ö†Ô∏è Database error checking existing analysis:`, dbError)
      return null // Ïò§Î•ò Ïãú ÏÉàÎ°ú Î∂ÑÏÑù
    }
    
    // Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÎäî Í≤ΩÏö∞
    if (!data) {
      console.log(`üìù No existing analysis found for ${partNum} (color: ${colorId})`)
      return null
    }
    
    console.log(`‚úÖ Found existing analysis for ${partNum} (color: ${colorId})`)
    console.log(`üìä Existing data: part_id=${data.part_id}, confidence=${data.confidence}, has_embedding=${!!data.clip_text_emb}`)
    
    // part_idÍ∞Ä nullÏù∏ Í≤ΩÏö∞ Ï≤òÎ¶¨
    if (!data.part_id) {
      console.log(`‚ö†Ô∏è Found record but part_id is null for ${partNum} (color: ${colorId}), skipping`)
      return null
    }
    
    // Í∏∞Ï°¥ Î∂ÑÏÑù Í≤∞Í≥ºÎ•º ÌòÑÏû¨ ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò
    const result = {
      part_num: data.part_id,
      color_id: data.color_id,
      shape: data.feature_json?.shape || 'unknown',
      center_stud: data.feature_json?.center_stud || false,
      groove: data.feature_json?.groove || false,
      connection: data.feature_json?.connection || 'unknown',
      function: data.feature_json?.function || 'unknown',
      feature_text: data.feature_text,
      recognition_hints: data.feature_json?.recognition_hints || {},
      similar_parts: data.feature_json?.similar_parts || [],
      distinguishing_features: data.feature_json?.distinguishing_features || [],
      confidence: data.confidence || 0.5,
      embedding: data.clip_text_emb,
      has_embedding: !!data.clip_text_emb,
      existing_embedding: data.clip_text_emb
    }
    
    // Ï∫êÏãúÏóê Ï†ÄÏû•
    analysisCache.set(cacheKey, result)
    return result
    
  } catch (error) {
    console.error('‚ùå Check existing analysis failed:', error)
    return null
  }
}

// Ï†ÑÏó≠ Ï∫êÏãúÎ°ú Ï§ëÎ≥µ Ï≤¥ÌÅ¨
const analysisCache = new Map()

export function useMasterPartsPreprocessing() {
  const loading = ref(false)
  const error = ref(null)
  const processing = ref(false)
  
  // Ìñ•ÏÉÅÎêú Ïù∏Ïãù ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî
  const enhancedRecognition = useEnhancedRecognition()
  const progress = ref(0)

  // Î™®Îì† Rebrickable Î∂ÄÌíà ÏàòÏßë
  const collectAllRebrickableParts = async () => {
    loading.value = true
    error.value = null

    try {
      const allParts = []
      let page = 1
      const pageSize = 1000

      while (true) {
        const response = await fetch(`https://rebrickable.com/api/v3/lego/parts/?page=${page}&page_size=${pageSize}`, {
          headers: {
            'Authorization': `key ${import.meta.env.VITE_REBRICKABLE_API_KEY}`,
            'Content-Type': 'application/json'
          }
        })

        if (!response.ok) break

        const data = await response.json()
        if (!data.results || data.results.length === 0) break

        allParts.push(...data.results)
        page++

        // API Ï†úÌïú Í≥†Î†§
        await new Promise(resolve => setTimeout(resolve, 100))
      }

      console.log(`Collected ${allParts.length} parts from Rebrickable`)
      return allParts
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      loading.value = false
    }
  }

  // Rate Limit ÏÉÅÌÉú Ï∂îÏ†Å
  let rateLimitCount = 0
  let lastRateLimitTime = 0
  
  // Î∂ÄÌíàÎ≥Ñ LLM Î∂ÑÏÑù (Î∞∞Ïπò Ï≤òÎ¶¨ - Rate Limit ÎåÄÏùë)
  const analyzePartsBatch = async (parts, batchSize = 2) => {
    processing.value = true
    error.value = null
    progress.value = 0

    try {
      const results = []
      const errors = []
      
      // Rate Limit ÏÉÅÌÉúÏóê Îî∞Î•∏ ÎèôÏ†Å Ï°∞Ï†ï
      const currentTime = Date.now()
      const timeSinceLastRateLimit = currentTime - lastRateLimitTime
      
      let DELAY_BETWEEN_BATCHES = 10000 // Í∏∞Î≥∏ 10Ï¥à
      let DELAY_BETWEEN_REQUESTS = 2000  // Í∏∞Î≥∏ 2Ï¥à
      
      // ÏµúÍ∑º Rate Limit Î∞úÏÉù Ïãú Îçî Í∏¥ ÏßÄÏó∞
      if (rateLimitCount > 0 && timeSinceLastRateLimit < 300000) { // 5Î∂Ñ Ïù¥ÎÇ¥
        DELAY_BETWEEN_BATCHES = 30000 // 30Ï¥à
        DELAY_BETWEEN_REQUESTS = 5000  // 5Ï¥à
        console.warn(`‚ö†Ô∏è Rate limit detected recently, using extended delays: ${DELAY_BETWEEN_BATCHES}ms batches, ${DELAY_BETWEEN_REQUESTS}ms requests`)
      }

      for (let i = 0; i < parts.length; i += batchSize) {
        const batch = parts.slice(i, i + batchSize)
        console.log(`Processing batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(parts.length / batchSize)}`)

        const batchPromises = batch.map(async (part, index) => {
          // ÏöîÏ≤≠ Í∞Ñ ÏßÄÏó∞
          if (index > 0) {
            await new Promise(resolve => setTimeout(resolve, DELAY_BETWEEN_REQUESTS))
          }
          
          try {
            const analysis = await analyzePartWithLLM(part)
            if (analysis === null) {
              console.log(`‚è≠Ô∏è Skipping LLM analysis for ${part.part_num} - API key missing`)
              return { part, analysis: null, success: true, skipped: true }
            }
            return { part, analysis, success: true }
          } catch (err) {
            console.error(`Failed to analyze part ${part.part_num}:`, err)
            
            // Rate Limit ÏóêÎü¨ Ï∂îÏ†Å
            if (err.message.includes('429') || err.message.includes('rate_limit')) {
              rateLimitCount++
              lastRateLimitTime = Date.now()
              console.warn(`üö® Rate limit error #${rateLimitCount} detected for part ${part.part_num}`)
            }
            
            return { part, error: err.message, success: false }
          }
        })

        const batchResults = await Promise.all(batchPromises)
        
        for (const result of batchResults) {
          if (result.success) {
            if (result.skipped) {
              console.log(`‚è≠Ô∏è Skipped LLM analysis for ${result.part.part_num} - using existing data only`)
            }
            results.push(result)
          } else {
            errors.push(result)
          }
        }

        // Î∞∞Ïπò Í∞Ñ ÏßÄÏó∞ (ÎßàÏßÄÎßâ Î∞∞Ïπò Ï†úÏô∏)
        if (i + batchSize < parts.length) {
          console.log(`‚è≥ Waiting ${DELAY_BETWEEN_BATCHES/1000}s before next batch... (Rate limit count: ${rateLimitCount})`)
          await new Promise(resolve => setTimeout(resolve, DELAY_BETWEEN_BATCHES))
        }

        // ÏßÑÌñâÎ•† ÏóÖÎç∞Ïù¥Ìä∏
        progress.value = Math.round((i + batchSize) / parts.length * 100)

        // API Ï†úÌïúÏùÑ ÏúÑÌïú ÏßÄÏó∞
        await new Promise(resolve => setTimeout(resolve, 2000))
      }

      return { results, errors }
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      processing.value = false
    }
  }

  // Í∞úÎ≥Ñ Î∂ÄÌíà LLM Î∂ÑÏÑù (ÌïòÏù¥Î∏åÎ¶¨Îìú Ï†ÑÎûµ AÎã®Í≥Ñ)
  const analyzePartWithLLM = async (part) => {
    try {
      if (import.meta.env.DEV) {
      console.log('Î∂ÑÏÑùÌï† Î∂ÄÌíà Ï†ïÎ≥¥:', part)
    }
      
      // Î∂ÄÌíà Ï†ïÎ≥¥ ÌôïÏù∏ Î∞è Ï†ïÎ¶¨
      const partName = part.part?.name || part.name || 'Unknown'
      const partNum = part.part_num || part.part?.part_num || 'Unknown'
      const partImgUrl = part.part?.part_img_url || part.part_img_url || null
      
      // part_idÍ∞Ä 'Unknown'Ïù∏ Í≤ΩÏö∞ Ïä§ÌÇµ
      if (partNum === 'Unknown') {
        console.warn(`‚ö†Ô∏è Skipping part with unknown part_num: ${partName}`)
        return null
      }
      
      console.log('Ï†ïÎ¶¨Îêú Î∂ÄÌíà Ï†ïÎ≥¥:', { partName, partNum, partImgUrl })
      
      // Ïù¥ÎØ∏ÏßÄ URLÏù¥ ÏóÜÏúºÎ©¥ Í∏∞Î≥∏ Î∂ÑÏÑùÎßå ÏàòÌñâ
      if (!partImgUrl) {
        console.warn(`Î∂ÄÌíà ${partNum}Ïùò Ïù¥ÎØ∏ÏßÄ URLÏù¥ ÏóÜÏäµÎãàÎã§. ÌÖçÏä§Ìä∏ÎßåÏúºÎ°ú Î∂ÑÏÑùÌï©ÎãàÎã§.`)
        return createTextOnlyAnalysis(part, partName, partNum)
      }
      
      const prompt = `Îã§Ïùå Î†àÍ≥† Î∂ÄÌíàÏùÑ Î∂ÑÏÑùÌïòÏó¨ JSON ÌòïÌÉúÎ°úÎßå ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî. Îã§Î•∏ ÏÑ§Î™Ö ÏóÜÏù¥ JSONÎßå Î∞òÌôòÌïòÏÑ∏Ïöî.

Î∂ÄÌíà Ï†ïÎ≥¥:
- Î∂ÄÌíàÎ™Ö: ${partName}
- Î∂ÄÌíà Î≤àÌò∏: ${partNum}

ÏùëÎãµ ÌòïÏãù:
{
  "shape": "Î∂ÄÌíàÏùò Í∏∞Î≥∏ ÌòïÌÉú",
  "center_stud": true/false,
  "groove": true/false,
  "connection": "Ïó∞Í≤∞ Î∞©Ïãù",
  "function": "Ï£ºÏöî Í∏∞Îä•",
  "feature_text": "Î∂ÄÌíà ÌäπÏßïÏùÑ ÏÑ§Î™ÖÌïòÎäî ÌÖçÏä§Ìä∏",
  "recognition_hints": {
    "top_view": "ÏúÑÏóêÏÑú Î≥∏ Î™®Ïäµ",
    "side_view": "ÏòÜÏóêÏÑú Î≥∏ Î™®Ïäµ",
    "unique_features": ["Í≥†Ïú† ÌäπÏßïÎì§"]
  },
  "similar_parts": ["Ïú†ÏÇ¨Ìïú Î∂ÄÌíà Î≤àÌò∏Îì§"],
  "distinguishing_features": ["Íµ¨Î≥ÑÎêòÎäî ÌäπÏßïÎì§"],
  "confidence": 0.95
}

Ïã†Î¢∞ÎèÑ(confidence) Í∏∞Ï§Ä:
- 0.9-1.0: Îß§Ïö∞ Î™ÖÌôïÌïú Î∂ÄÌíà (Í∏∞Î≥∏ Î∏îÎ°ù, ÌîåÎ†àÏù¥Ìä∏ Îì±)
- 0.7-0.9: ÎπÑÍµêÏ†Å Î™ÖÌôïÌïú Î∂ÄÌíà (ÌäπÏàò Î∂ÄÌíà, Ïû•Ïãù ÏöîÏÜå)
- 0.5-0.7: Ïï†Îß§Ìïú Î∂ÄÌíà (Î≥µÏû°Ìïú ÌòïÌÉú, Ïù∏ÏáÑÍ∞Ä ÏûàÎäî Î∂ÄÌíà)
- 0.3-0.5: Î∂àÌôïÏã§Ìïú Î∂ÄÌíà (Ïù¥ÎØ∏ÏßÄÍ∞Ä ÌùêÎ¶¨Í±∞ÎÇò Í∞ÅÎèÑÍ∞Ä ÎÇòÏÅ®)
- 0.0-0.3: Î∂ÑÏÑù Î∂àÍ∞ÄÎä• (Ïù¥ÎØ∏ÏßÄ ÏóÜÏùå ÎòêÎäî ÎÑàÎ¨¥ ÌùêÎ¶º)`

      const requestBody = {
        model: LLM_CONFIG.model,
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: prompt
              },
              {
                type: 'image_url',
                image_url: {
                  url: partImgUrl,
                  detail: 'high'
                }
              }
            ]
          }
        ],
        max_tokens: LLM_CONFIG.maxTokens,
        temperature: LLM_CONFIG.temperature
      }

      console.log('API ÏöîÏ≤≠ Ï†ïÎ≥¥:', {
        model: LLM_CONFIG.model,
        apiKey: LLM_CONFIG.apiKey ? 'ÏÑ§Ï†ïÎê®' : 'ÏóÜÏùå',
        imageUrl: partImgUrl,
        promptLength: prompt.length
      })

      const response = await fetch(`${LLM_CONFIG.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${LLM_CONFIG.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody)
      })

      if (!response.ok) {
        const errorText = await response.text()
        console.error('API Ïò§Î•ò ÏùëÎãµ:', errorText)
        throw new Error(`LLM API Error: ${response.status} - ${errorText}`)
      }

      const data = await response.json()
      if (import.meta.env.DEV) {
      console.log('LLM raw response:', data)
    }
      
      // ÏùëÎãµ Íµ¨Ï°∞ ÌôïÏù∏
      if (!data.choices || !data.choices[0] || !data.choices[0].message) {
        console.error('ÏùëÎãµ Íµ¨Ï°∞ Ïò§Î•ò:', data)
        return null
      }
      
      const llmResponse = data.choices[0].message.content
      console.log('LLM ÏùëÎãµ ÎÇ¥Ïö©:', llmResponse)

      // JSON Î∂ÄÎ∂ÑÎßå Ï∂îÏ∂ú (```json ... ``` ÎòêÎäî { ... } Ìå®ÌÑ¥ Ï∞æÍ∏∞)
      let jsonText = llmResponse
      
      // ```json ... ``` Ìå®ÌÑ¥ Ï∞æÍ∏∞
      const jsonBlockMatch = llmResponse.match(/```json\s*([\s\S]*?)\s*```/)
      if (jsonBlockMatch) {
        jsonText = jsonBlockMatch[1].trim()
        console.log('Ï∂îÏ∂úÎêú JSON Î∏îÎ°ù:', jsonText)
      } else {
        // ```json Ìå®ÌÑ¥Ïù¥ ÏóÜÏúºÎ©¥ { ... } Ìå®ÌÑ¥ Ï∞æÍ∏∞
        const jsonObjectMatch = llmResponse.match(/\{[\s\S]*\}/)
        if (jsonObjectMatch) {
          jsonText = jsonObjectMatch[0]
          console.log('Ï∂îÏ∂úÎêú JSON Í∞ùÏ≤¥:', jsonText)
        }
      }

      // JSON ÌååÏã±
      let analysisResult
      try {
        analysisResult = JSON.parse(jsonText)
        // part_num Ï∂îÍ∞Ä (LLM ÏùëÎãµÏóêÎäî ÏóÜÏúºÎØÄÎ°ú ÏàòÎèô Ï∂îÍ∞Ä)
        analysisResult.part_num = partNum
        console.log('ÌååÏã±Îêú Î∂ÑÏÑù Í≤∞Í≥º:', analysisResult)
      } catch (parseError) {
        console.error('JSON ÌååÏã± Ïã§Ìå®:', parseError)
        console.log('Ï∂îÏ∂úÎêú JSON ÌÖçÏä§Ìä∏:', jsonText)
        console.log('ÏõêÎ≥∏ ÏùëÎãµ:', llmResponse)
        // JSON ÌååÏã± Ïã§Ìå® Ïãú null Î∞òÌôò
        analysisResult = null
      }

      return analysisResult
    } catch (err) {
      console.error('LLM analysis failed:', err)
      return null
    }
  }

  // Í∏∞Î≥∏ Î∂ÑÏÑù Í≤∞Í≥º ÏÉùÏÑ± (Îçî Ïù¥ÏÉÅ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏùå - LLM Ïã§Ìå® Ïãú null Î∞òÌôò)
  // const createDefaultAnalysis = (part) => {
  //   const partNum = part.part_num || part.part?.part_num || 'unknown'
  //   return {
  //     part_num: partNum,
  //     shape: `Î∂ÑÏÑù Ïã§Ìå®: ${part.name || part.part?.name}`,
  //     center_stud: false,
  //     groove: false,
  //     connection: 'unknown',
  //     function: 'unknown',
  //     feature_text: `Î∂ÑÏÑù Ïã§Ìå®: ${part.name || part.part?.name}`,
  //     recognition_hints: {
  //       top_view: 'Î∂ÑÏÑù Ïã§Ìå®',
  //       side_view: 'Î∂ÑÏÑù Ïã§Ìå®',
  //       unique_features: []
  //     },
  //     similar_parts: [],
  //     distinguishing_features: [],
  //     confidence: 0.3
  //   }
  // }

  // ÌÖçÏä§Ìä∏ÎßåÏúºÎ°ú Î∂ÑÏÑù (Ïù¥ÎØ∏ÏßÄ URLÏù¥ ÏóÜÏùÑ Îïå)
  const createTextOnlyAnalysis = (part, partName, partNum) => {
    return {
      part_num: partNum,
      shape: `ÌÖçÏä§Ìä∏ Î∂ÑÏÑù: ${partName}`,
      center_stud: false,
      groove: false,
      connection: 'unknown',
      function: 'unknown',
      feature_text: `ÌÖçÏä§Ìä∏ Î∂ÑÏÑù: ${partName}`,
      recognition_hints: {
        top_view: 'Ïù¥ÎØ∏ÏßÄ ÏóÜÏùå',
        side_view: 'Ïù¥ÎØ∏ÏßÄ ÏóÜÏùå',
        unique_features: []
      },
      similar_parts: [],
      distinguishing_features: [],
      confidence: 0.3
    }
  }

  // CLIP ÌÖçÏä§Ìä∏ ÏûÑÎ≤†Îî© ÏÉùÏÑ± (ÌïòÏù¥Î∏åÎ¶¨Îìú Ï†ÑÎûµÏö©)
  const generateClipTextEmbedding = async (featureText) => {
    try {
      if (!CLIP_CONFIG.apiKey) {
        throw new Error('Missing VITE_OPENAI_API_KEY')
      }
      const response = await fetch(`${CLIP_CONFIG.baseUrl}/embeddings`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${CLIP_CONFIG.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: CLIP_CONFIG.model,
          input: featureText,
          dimensions: CLIP_CONFIG.dimensions
        })
      })

      if (!response.ok) {
        throw new Error(`CLIP API Error: ${response.status}`)
      }

      const data = await response.json()
      return data.data[0].embedding
    } catch (err) {
      console.error('CLIP text embedding generation failed:', err)
      throw err
    }
  }

  // CLIP Ïù¥ÎØ∏ÏßÄ ÏûÑÎ≤†Îî© ÏÉùÏÑ± (Ïã§ÏãúÍ∞Ñ Îß§Ïπ≠Ïö©)
  const generateClipImageEmbedding = async (imageUrl) => {
    try {
      // Ïù¥ÎØ∏ÏßÄ ÏûÑÎ≤†Îî©ÏùÄ ÏÑúÎ≤Ñ/Ïô∏Î∂Ä APIÏóêÏÑú Ï≤òÎ¶¨Ìï¥Ïïº Ìï©ÎãàÎã§.
      // ÌôòÍ≤ΩÎ≥ÄÏàò: VITE_CLIP_IMAGE_API_URL (POST base64 or URL)
      const endpoint = import.meta.env.VITE_CLIP_IMAGE_API_URL
      if (!endpoint) {
        throw new Error('Missing VITE_CLIP_IMAGE_API_URL')
      }
      const response = await fetch(endpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ image_url: imageUrl, dimensions: CLIP_CONFIG.dimensions })
      })
      if (!response.ok) throw new Error(`Image embedding API Error: ${response.status}`)
      const data = await response.json()
      if (!data.embedding) throw new Error('Image embedding API response missing embedding')
      return data.embedding
    } catch (err) {
      console.error('CLIP image embedding generation failed:', err)
      throw err
    }
  }

  // ÎßàÏä§ÌÑ∞ Î∂ÄÌíà DBÏóê Ï†ÄÏû• (ÌïòÏù¥Î∏åÎ¶¨Îìú Ï†ÑÎûµÏö©)
  const saveToMasterPartsDB = async (analysisResults) => {
    try {
      const records = analysisResults.map(result => ({
        part_id: result.part_num,
        part_name: result.part?.name || 'Unknown',
        part_category: result.part?.part_cat_id || null,
        color_id: result.color?.id || null,
        feature_json: {
          shape: result.shape,
          center_stud: result.center_stud,
          groove: result.groove,
          connection: result.connection,
          function: result.function
        },
        feature_text: result.feature_text,
        clip_text_emb: result.clip_text_emb,
        recognition_hints: result.recognition_hints,
        similar_parts: result.similar_parts,
        distinguishing_features: result.distinguishing_features,
        confidence: result.confidence,
        usage_frequency: 0,
        detection_accuracy: 0.0,
        created_at: new Date().toISOString()
      }))

      const { data, error: dbError } = await supabase
        .from('parts_master_features')
        .upsert(records, {
          onConflict: 'part_id,color_id'
        })
        .select()

      if (dbError) throw dbError
      return data
    } catch (err) {
      error.value = err.message
      throw err
    }
  }

  // Ï†ÑÏ≤¥ ÎßàÏä§ÌÑ∞ DB Íµ¨Ï∂ï ÌîÑÎ°úÏÑ∏Ïä§
  const buildMasterPartsDatabase = async () => {
    processing.value = true
    error.value = null
    progress.value = 0

    try {
      console.log('Starting master parts database construction...')

      // 1. Î™®Îì† Rebrickable Î∂ÄÌíà ÏàòÏßë
      console.log('Step 1: Collecting all Rebrickable parts...')
      const allParts = await collectAllRebrickableParts()
      console.log(`Collected ${allParts.length} parts`)

      // 2. Î∂ÄÌíàÎ≥Ñ LLM Î∂ÑÏÑù (Î∞∞Ïπò Ï≤òÎ¶¨)
      console.log('Step 2: Analyzing parts with LLM...')
      const analysisResults = await analyzePartsBatch(allParts, 5) // ÏûëÏùÄ Î∞∞Ïπò ÌÅ¨Í∏∞
      console.log(`Analyzed ${analysisResults.results.length} parts successfully`)
      console.log(`Failed to analyze ${analysisResults.errors.length} parts`)

      // 3. CLIP ÌÖçÏä§Ìä∏ ÏûÑÎ≤†Îî© ÏÉùÏÑ±
      console.log('Step 3: Generating CLIP text embeddings...')
      const embeddingResults = await generateTextEmbeddingsBatch(analysisResults.results)

      // 4. ÎßàÏä§ÌÑ∞ DBÏóê Ï†ÄÏû•
      console.log('Step 4: Saving to master database...')
      const savedRecords = await saveToMasterPartsDB(embeddingResults)

      console.log(`Master parts database construction completed!`)
      console.log(`Total records saved: ${savedRecords.length}`)

      return {
        totalParts: allParts.length,
        analyzedParts: analysisResults.results.length,
        failedParts: analysisResults.errors.length,
        savedRecords: savedRecords.length
      }
    } catch (err) {
      error.value = err.message
      throw err
    } finally {
      processing.value = false
    }
  }

  // CLIP ÌÖçÏä§Ìä∏ ÏûÑÎ≤†Îî© Î∞∞Ïπò ÏÉùÏÑ± (ÌïòÏù¥Î∏åÎ¶¨Îìú Ï†ÑÎûµÏö©)
  const generateTextEmbeddingsBatch = async (analysisResults) => {
    const results = []

    for (const result of analysisResults) {
      try {
        // part_num ÌôïÏù∏ Î∞è Ï≤òÎ¶¨
        const partNum = result.part_num || 'unknown'
        
        if (!result.feature_text) {
          console.warn(`Î∂ÄÌíà ${partNum}Ïùò feature_textÍ∞Ä ÏóÜÏäµÎãàÎã§.`)
          results.push({
            ...result,
            clip_text_emb: null
          })
          continue
        }

        const textEmbedding = await generateClipTextEmbedding(result.feature_text)
        results.push({
          ...result,
          clip_text_emb: textEmbedding
        })
      } catch (err) {
        const partNum = result.part_num || 'unknown'
        console.error(`Failed to generate text embedding for ${partNum}:`, err)
        results.push({
          ...result,
          clip_text_emb: null
        })
      }
    }

    return results
  }

  // ÎßàÏä§ÌÑ∞ DB ÏÉÅÌÉú ÌôïÏù∏ (ÌïòÏù¥Î∏åÎ¶¨Îìú Ï†ÑÎûµÏö©)
  const checkMasterDBStatus = async () => {
    try {
      const { data, error: dbError } = await supabase
        .from('parts_master_features')
        .select('part_id, created_at, confidence, usage_frequency, detection_accuracy')
        .order('created_at', { ascending: false })
        .limit(1000)

      if (dbError) throw dbError

      const stats = {
        totalRecords: data.length,
        averageConfidence: data.reduce((sum, record) => sum + (record.confidence || 0), 0) / data.length,
        lastUpdated: data[0]?.created_at,
        highConfidence: data.filter(r => r.confidence > 0.8).length,
        lowConfidence: data.filter(r => r.confidence < 0.5).length,
        averageUsageFrequency: data.reduce((sum, record) => sum + (record.usage_frequency || 0), 0) / data.length,
        averageDetectionAccuracy: data.reduce((sum, record) => sum + (record.detection_accuracy || 0), 0) / data.length
      }

      return stats
    } catch (err) {
      error.value = err.message
      throw err
    }
  }

  // Í∏∞Ï°¥ Î∂ÑÏÑù Í≤∞Í≥º ÌôïÏù∏ (Ï§ëÎ≥µ Î∞©ÏßÄÏö©)
  const checkExistingAnalysis = async (partColorPairs) => {
    try {
      const { data, error: dbError } = await supabase
        .from('parts_master_features')
        .select('part_id, color_id, feature_json, feature_text, clip_text_emb, confidence')
        .in('part_id', partColorPairs.map(p => p.part_num))
        .in('color_id', partColorPairs.map(p => p.color_id))

      if (dbError) throw dbError
      
      // Í∏∞Ï°¥ Î∂ÑÏÑù Í≤∞Í≥ºÎ•º ÌòÑÏû¨ ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò
      const existingResults = data.map(record => ({
        part_num: record.part_id,
        color_id: record.color_id,
        shape: record.feature_json?.shape || 'unknown',
        center_stud: record.feature_json?.center_stud || false,
        groove: record.feature_json?.groove || false,
        connection: record.feature_json?.connection || 'unknown',
        function: record.feature_json?.function || 'unknown',
        feature_text: record.feature_text,
        recognition_hints: record.feature_json?.recognition_hints || {},
        similar_parts: record.feature_json?.similar_parts || [],
        distinguishing_features: record.feature_json?.distinguishing_features || [],
        confidence: record.confidence,
        clip_text_emb: record.clip_text_emb,
        is_existing: true // Í∏∞Ï°¥ Î∂ÑÏÑù Í≤∞Í≥ºÏûÑÏùÑ ÌëúÏãú
      }))
      
      console.log(`Í∏∞Ï°¥ Î∂ÑÏÑù Í≤∞Í≥º ${existingResults.length}Í∞ú Î∞úÍ≤¨`)
      return existingResults
    } catch (err) {
      console.error('Í∏∞Ï°¥ Î∂ÑÏÑù Í≤∞Í≥º ÌôïÏù∏ Ïã§Ìå®:', err)
      return []
    }
  }

  return {
    loading,
    error,
    processing,
    progress,
    collectAllRebrickableParts,
    analyzePartsBatch,
    analyzePartWithLLM,
    generateClipTextEmbedding,
    generateClipImageEmbedding,
    saveToMasterPartsDB,
    buildMasterPartsDatabase,
    generateTextEmbeddingsBatch,
    checkMasterDBStatus,
    checkExistingAnalysis,
    // Ìñ•ÏÉÅÎêú Ïù∏Ïãù ÏãúÏä§ÌÖú
    enhancedRecognitionPipeline: enhancedRecognition.enhancedRecognitionPipeline,
    processBatchRecognition: enhancedRecognition.processBatchRecognition,
    filterByConfidence: enhancedRecognition.filterByConfidence,
    sortByConfidence: enhancedRecognition.sortByConfidence,
    generateStatistics: enhancedRecognition.generateStatistics
  }
}
